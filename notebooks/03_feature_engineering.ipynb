{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bfc3da-725c-4ef9-b5cc-7ae7d4f0a5ca",
   "metadata": {},
   "source": [
    "# 0. PopForecast â€” Feature Engineering\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Implement and validate the Cycle 2 feature engineering pipeline.\n",
    "- Ensure all transforms are split-safe and produce a dataset ready for modeling.\n",
    "- Produce diagnostics to decide which engineered features to keep for Cycle 2 experiments.\n",
    "\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "## 1.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da93b154-d649-4610-b1b1-52ba9523d4dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:12.171236Z",
     "iopub.status.busy": "2026-02-11T13:53:12.170828Z",
     "iopub.status.idle": "2026-02-11T13:53:14.254022Z",
     "shell.execute_reply": "2026-02-11T13:53:14.252382Z",
     "shell.execute_reply.started": "2026-02-11T13:53:12.171203Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# --- Standard library ---\n",
    "import json\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "\n",
    "# --- Third-party ---\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Scikit-learn ---\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, TweedieRegressor, HuberRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Project path setup (so `src/` is importable from notebooks/) ---\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "    \n",
    "# --- Local project (src/) ---\n",
    "from src.core.features import (\n",
    "    FeatureEngineeringConfig,\n",
    "    apply_feature_engineering,\n",
    "    build_feature_pipeline,\n",
    ")\n",
    "from src.core.preprocessing import default_config, run_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1ebfd-65c9-47df-a0b3-32aa14ce38ab",
   "metadata": {},
   "source": [
    "## 1.2 - Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ae9a29-89fa-4abe-abdc-4a97ed727d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.255640Z",
     "iopub.status.busy": "2026-02-11T13:53:14.255282Z",
     "iopub.status.idle": "2026-02-11T13:53:14.260828Z",
     "shell.execute_reply": "2026-02-11T13:53:14.259281Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.255616Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Reproducibility (use only when sampling / splitting inside the notebook) ---\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Pandas display ---\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_colwidth\", 60)\n",
    "pd.set_option(\"display.float_format\", \"{:,.4f}\".format)\n",
    "\n",
    "# --- Matplotlib defaults (lightweight) ---\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6672846-a0f6-4fd9-beb5-4408c3e3b699",
   "metadata": {},
   "source": [
    "## 1.3 - Project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997eb30a-074f-4cb4-89c2-d548a23ce34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.261805Z",
     "iopub.status.busy": "2026-02-11T13:53:14.261573Z",
     "iopub.status.idle": "2026-02-11T13:53:14.270670Z",
     "shell.execute_reply": "2026-02-11T13:53:14.269378Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.261787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast\n",
      "Processed dataset: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/data/processed/spotify_tracks_modeling.parquet\n",
      "Cycle 2 Output: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/models/cycle_02\n"
     ]
    }
   ],
   "source": [
    "# Define base paths\n",
    "DATA_PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"spotify_tracks_modeling.parquet\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\" / \"cycle_02\"\n",
    "\n",
    "# Ensure output directory exists (Safety check)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Processed dataset:\", DATA_PROCESSED_PATH)\n",
    "print(\"Cycle 2 Output:\", MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd71b34-c705-4f4e-9153-969461b2a9bd",
   "metadata": {},
   "source": [
    "## 1.4 - Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2a241f3-603d-405b-aac4-aa0e843f00fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:25:08.700404Z",
     "iopub.status.busy": "2026-02-12T15:25:08.699345Z",
     "iopub.status.idle": "2026-02-12T15:25:08.881812Z",
     "shell.execute_reply": "2026-02-12T15:25:08.880146Z",
     "shell.execute_reply.started": "2026-02-12T15:25:08.700346Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Splits\n",
    "# ============================================================\n",
    "def random_split(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    target_col: str,\n",
    "    test_size: float = 0.15,\n",
    "    val_size: float = 0.15,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"Random split: train/val/test from a single DataFrame.\"\"\"\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=seed\n",
    "    )\n",
    "    rel_test = test_size / (test_size + val_size)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=rel_test, random_state=seed\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def temporal_split(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    target_col: str,\n",
    "    year_col: str,\n",
    "    train_end: int = 2019,\n",
    "    val_year: int = 2020,\n",
    "    test_year: int = 2021,\n",
    "    include_missing_year_in_train: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Temporal split:\n",
    "      - train: year <= train_end (+ optionally missing)\n",
    "      - val:   year == val_year\n",
    "      - test:  year == test_year\n",
    "    \"\"\"\n",
    "    year = df[year_col].astype(\"Int64\")\n",
    "\n",
    "    if include_missing_year_in_train:\n",
    "        train_mask = year.isna() | (year <= train_end)\n",
    "    else:\n",
    "        train_mask = year.notna() & (year <= train_end)\n",
    "\n",
    "    train = df[train_mask]\n",
    "    val = df[year == val_year]\n",
    "    test = df[year == test_year]\n",
    "\n",
    "    X_train, y_train = train.drop(columns=[target_col]), train[target_col]\n",
    "    X_val, y_val = val.drop(columns=[target_col]), val[target_col]\n",
    "    X_test, y_test = test.drop(columns=[target_col]), test[target_col]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def split_table(\n",
    "    split_name: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    *,\n",
    "    year_col: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Small split summary table (rows/cols and year coverage).\"\"\"\n",
    "\n",
    "    def _stats(X: pd.DataFrame, subset: str) -> dict:\n",
    "        years = X[year_col].astype(\"Int64\")\n",
    "        non_na = years.dropna()\n",
    "        return {\n",
    "            \"split\": split_name,\n",
    "            \"subset\": subset,\n",
    "            \"rows\": int(len(X)),\n",
    "            \"cols\": int(X.shape[1]),\n",
    "            \"year_min\": int(non_na.min()) if not non_na.empty else pd.NA,\n",
    "            \"year_max\": int(non_na.max()) if not non_na.empty else pd.NA,\n",
    "            \"year_missing_pct\": float(round(years.isna().mean() * 100, 4)),\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        [_stats(X_train, \"train\"), _stats(X_val, \"val\"), _stats(X_test, \"test\")]\n",
    "    )\n",
    "\n",
    "\n",
    "def x_counts(\n",
    "    X: pd.DataFrame,\n",
    "    *,\n",
    "    year_col: str = \"album_release_year\",\n",
    "    flag_col: str = \"release_year_missing_or_suspect\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"Counts flagged/missing year rows in a given feature table.\"\"\"\n",
    "    flagged = (\n",
    "        X[flag_col].astype(bool) if flag_col in X.columns else pd.Series(False, index=X.index)\n",
    "    )\n",
    "    missing_year = (\n",
    "        X[year_col].isna() if year_col in X.columns else pd.Series(False, index=X.index)\n",
    "    )\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"rows\": int(len(X)),\n",
    "            \"flagged_rows\": int(flagged.sum()),\n",
    "            \"flagged_pct\": float(flagged.mean() * 100),\n",
    "            \"missing_year_rows\": int(missing_year.sum()),\n",
    "            \"missing_year_pct\": float(missing_year.mean() * 100),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def report_nan_rates(splits: dict[str, pd.DataFrame], cols: Sequence[str]) -> pd.DataFrame:\n",
    "    def _nan_pct(df):\n",
    "        return {c: float(df[c].isna().mean() * 100) for c in cols if c in df.columns}\n",
    "\n",
    "    return pd.DataFrame({name: _nan_pct(df) for name, df in splits.items()}).T\n",
    "\n",
    "\n",
    "def _prepare_X_numeric(train_X: pd.DataFrame, other_Xs: list[pd.DataFrame]):\n",
    "    \"\"\"\n",
    "    Minimal, leakage-free preprocessing for notebook experiments:\n",
    "    - keep same columns as train\n",
    "    - cast bool -> int8\n",
    "    - replace inf/-inf -> NaN\n",
    "    - median impute fitted on train only\n",
    "    Returns: X_train_i, [X_other_i...], feature_names\n",
    "    \"\"\"\n",
    "    cols = list(train_X.columns)\n",
    "\n",
    "    def _clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # avoid unnecessary copies\n",
    "        x = df[cols]\n",
    "\n",
    "        # only copy if needed (booleans present)\n",
    "        bool_cols = x.select_dtypes(include=[\"bool\"]).columns\n",
    "        if len(bool_cols) > 0:\n",
    "            x = x.copy()\n",
    "            for c in bool_cols:\n",
    "                x[c] = x[c].astype(\"int8\")\n",
    "\n",
    "        # replace inf with nan without duplicating memory\n",
    "        x = x.where(np.isfinite(x), np.nan)\n",
    "\n",
    "        return x\n",
    "\n",
    "    train_clean = _clean(train_X)\n",
    "    others_clean = [_clean(df) for df in other_Xs]\n",
    "\n",
    "    # avoid internal copies inside SimpleImputer\n",
    "    imputer = SimpleImputer(strategy=\"median\", copy=False)\n",
    "\n",
    "    X_train_i = imputer.fit_transform(train_clean)\n",
    "    X_others_i = [imputer.transform(df) for df in others_clean]\n",
    "\n",
    "    return X_train_i, X_others_i, cols\n",
    "\n",
    "\n",
    "    \n",
    "# ============================================================\n",
    "# Metrics\n",
    "# ============================================================\n",
    "def regression_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"Global regression metrics.\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    return {\n",
    "        \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"rmse\": float(np.sqrt(mean_squared_error(y_true, y_pred))),\n",
    "        \"r2\": float(r2_score(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def segmented_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Segment-aware diagnostics for zero inflation:\n",
    "      - mae_zero (true y == 0)\n",
    "      - mae_pos  (true y > 0)\n",
    "      - pct_zero_true\n",
    "      - pred_zero_pct (pred == 0)\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    mask_zero = (y_true == 0.0)\n",
    "    mask_pos = ~mask_zero\n",
    "\n",
    "    mae_zero = (\n",
    "        float(mean_absolute_error(y_true[mask_zero], y_pred[mask_zero]))\n",
    "        if mask_zero.any()\n",
    "        else float(\"nan\")\n",
    "    )\n",
    "    mae_pos = (\n",
    "        float(mean_absolute_error(y_true[mask_pos], y_pred[mask_pos]))\n",
    "        if mask_pos.any()\n",
    "        else float(\"nan\")\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"mae_zero\": mae_zero,\n",
    "        \"mae_pos\": mae_pos,\n",
    "        \"pct_zero_true\": float(mask_zero.mean() * 100.0),\n",
    "        \"pred_zero_pct\": float((y_pred == 0.0).mean() * 100.0),\n",
    "    }\n",
    "\n",
    "\n",
    "def full_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"Convenience wrapper: global + segmented metrics.\"\"\"\n",
    "    out = {}\n",
    "    out.update(regression_metrics(y_true, y_pred))\n",
    "    out.update(segmented_metrics(y_true, y_pred))\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def _eval_split(y_true: pd.Series, y_pred: np.ndarray) -> dict:\n",
    "    # Uses your existing functions\n",
    "    y_true_arr = y_true.to_numpy(dtype=float)\n",
    "\n",
    "    out = {}\n",
    "    out.update(regression_metrics(y_true_arr, y_pred))\n",
    "    out.update(segmented_metrics(y_true_arr, y_pred))\n",
    "    return out\n",
    "\n",
    "\n",
    "    \n",
    "# ============================================================\n",
    "# Recency weights\n",
    "# ============================================================\n",
    "def make_recency_weights(\n",
    "    year_series: pd.Series,\n",
    "    *,\n",
    "    ref_year: int,\n",
    "    lam: float,\n",
    "    min_w: float = 1e-3,\n",
    "    max_w: float = 1.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Exponential recency weights w = exp(-lam * age), age = max(ref_year - year, 0).\n",
    "    Missing year -> median year (simple + stable).\n",
    "    \"\"\"\n",
    "    year = pd.to_numeric(year_series, errors=\"coerce\")\n",
    "    year_filled = year.fillna(year.median())\n",
    "    age = (ref_year - year_filled).clip(lower=0)\n",
    "    w = np.exp(-lam * age).clip(min_w, max_w)\n",
    "    return w.to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "def _recency_weights_from_year_col(\n",
    "    X_train: pd.DataFrame,\n",
    "    year_col: str = \"album_release_year\",\n",
    "    lambda_recency: float = 0.05,\n",
    "    current_year: int = 2021,\n",
    ") -> np.ndarray:\n",
    "    year = pd.to_numeric(X_train[year_col], errors=\"coerce\").to_numpy(float)\n",
    "    year = np.nan_to_num(year, nan=float(current_year))\n",
    "    age = current_year - year\n",
    "    age = np.clip(age, 0.0, None)\n",
    "    return np.exp(-lambda_recency * age)\n",
    "\n",
    "    \n",
    "# ============================================================\n",
    "# Generic model evaluation on provided splits\n",
    "# ============================================================\n",
    "def evaluate_model_on_splits(\n",
    "    model,\n",
    "    *,\n",
    "    model_name: str,\n",
    "    splits: dict[str, tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fit on each split's train, evaluate train/val/test.\n",
    "    `splits` example:\n",
    "      {\n",
    "        \"random\": (X_train_r, X_val_r, X_test_r, y_train_r, y_val_r, y_test_r),\n",
    "        \"temporal\": (X_train_t, X_val_t, X_test_t, y_train_t, y_val_t, y_test_t),\n",
    "      }\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for split_name, (X_tr, X_va, X_te, y_tr, y_va, y_te) in splits.items():\n",
    "        m = clone(model)\n",
    "        m.fit(X_tr, y_tr)\n",
    "\n",
    "        for subset, X, y in [(\"train\", X_tr, y_tr), (\"val\", X_va, y_va), (\"test\", X_te, y_te)]:\n",
    "            y_pred = m.predict(X)\n",
    "            row = {\"split\": split_name, \"model\": model_name, \"subset\": subset}\n",
    "            row.update(full_metrics(np.asarray(y, dtype=float), np.asarray(y_pred, dtype=float)))\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def benchmark_regressors_temporal(\n",
    "    X_train_t, y_train_t,\n",
    "    X_val_t, y_val_t,\n",
    "    X_test_t, y_test_t,\n",
    "    *,\n",
    "    year_col=\"album_release_year\",\n",
    "    lambda_recency=0.05,\n",
    "    current_year=2021,\n",
    "    use_sample_weight=True,\n",
    ") -> pd.DataFrame:\n",
    "    # -----------------------------\n",
    "    # 1) Preprocess (fit on train only)\n",
    "    # -----------------------------\n",
    "    X_train_i, (X_val_i, X_test_i), feature_names = _prepare_X_numeric(\n",
    "        X_train_t, [X_val_t, X_test_t]\n",
    "    )\n",
    "\n",
    "    y_train_arr = y_train_t.to_numpy(dtype=float)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) Optional recency weights (train only)\n",
    "    # -----------------------------\n",
    "    w = _recency_weights_from_year_col(\n",
    "        X_train_t, year_col=year_col, lambda_recency=lambda_recency, current_year=current_year\n",
    "    )\n",
    "    if not use_sample_weight:\n",
    "        w = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) Models (keep small, fast, informative)\n",
    "    # -----------------------------\n",
    "    models = {\n",
    "        \"Linear_Regression\": LinearRegression(),\n",
    "        \"Huber_Regressor\": HuberRegressor(),\n",
    "        \"Tweedie_Regressor_p1p5\": TweedieRegressor(power=1.5, alpha=0.0, link=\"log\", max_iter=3000),\n",
    "        \"Hist_Gradient_Boosting_Regressor\": HistGradientBoostingRegressor(\n",
    "            max_depth=6,\n",
    "            learning_rate=0.08,\n",
    "            max_iter=300,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"Random_Forest_Regressor_small\": RandomForestRegressor(\n",
    "            n_estimators=60,   # reduced from 120\n",
    "            max_depth=14,      # reduced from 20\n",
    "            random_state=42,\n",
    "            n_jobs=4,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) Fit + eval\n",
    "    # -----------------------------\n",
    "    rows = []\n",
    "    for name, model in models.items():\n",
    "        fitted = model\n",
    "        try:\n",
    "            if w is not None:\n",
    "                fitted.fit(X_train_i, y_train_arr, sample_weight=w)\n",
    "            else:\n",
    "                fitted.fit(X_train_i, y_train_arr)\n",
    "        except TypeError:\n",
    "            # model does not accept sample_weight\n",
    "            fitted.fit(X_train_i, y_train_arr)\n",
    "\n",
    "        for subset_name, X_i, y_s in [\n",
    "            (\"val\", X_val_i, y_val_t),\n",
    "            (\"test\", X_test_i, y_test_t),\n",
    "        ]:\n",
    "            y_pred = fitted.predict(X_i).astype(float)\n",
    "            metrics = _eval_split(y_s, y_pred)\n",
    "            row = {\"model\": name, \"subset\": subset_name}\n",
    "            row.update(metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    results = pd.DataFrame(rows).sort_values([\"subset\", \"mae\", \"model\"]).reset_index(drop=True)\n",
    "\n",
    "    # Add context columns for logging/repro\n",
    "    results[\"lambda_recency\"] = lambda_recency if use_sample_weight else np.nan\n",
    "    results[\"use_sample_weight\"] = bool(use_sample_weight)\n",
    "    results[\"n_features\"] = len(feature_names)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "    \n",
    "# ============================================================\n",
    "# Hurdle (LogReg classifier + RF regressor on positives)\n",
    "#   - numeric-only + median imputation (notebook-friendly)\n",
    "#   - recency weights on train only\n",
    "# ============================================================\n",
    "def _numeric_impute_fit_transform(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "):\n",
    "    \"\"\"Returns (X_train_i, X_val_i, X_test_i, num_cols, imputer).\"\"\"\n",
    "    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    X_train_i = imputer.fit_transform(X_train[num_cols])\n",
    "    X_val_i = imputer.transform(X_val[num_cols])\n",
    "    X_test_i = imputer.transform(X_test[num_cols])\n",
    "\n",
    "    return X_train_i, X_val_i, X_test_i, num_cols, imputer\n",
    "\n",
    "\n",
    "def hurdle_fit(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    *,\n",
    "    year_col: str = \"album_release_year\",\n",
    "    lambda_recency: float = 0.05,\n",
    "    current_year: int = 2021,\n",
    "    clf=None,\n",
    "    reg=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit hurdle components once:\n",
    "      - clf: P(y==0 | x)\n",
    "      - reg: predicts y for positives only\n",
    "    Returns dict with fitted objects + cached train artifacts.\n",
    "    \"\"\"\n",
    "    if clf is None:\n",
    "        clf = LogisticRegression(max_iter=1000, n_jobs=1)\n",
    "    if reg is None:\n",
    "        reg = RandomForestRegressor(\n",
    "            n_estimators=80,\n",
    "            max_depth=20,\n",
    "            random_state=42,\n",
    "            n_jobs=4,\n",
    "        )\n",
    "\n",
    "    y_train_arr = y_train.to_numpy(dtype=float)\n",
    "\n",
    "    # numeric-only + impute (fit only on train)\n",
    "    # NOTE: caller must provide val/test already if needed;\n",
    "    # here we just fit artifacts for train; transforms happen outside.\n",
    "    train_year = pd.to_numeric(X_train[year_col], errors=\"coerce\")\n",
    "    w = make_recency_weights(train_year, ref_year=current_year, lam=lambda_recency)\n",
    "\n",
    "    # classifier target: 1 if zero else 0\n",
    "    y_is_zero = (y_train_arr == 0.0).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"clf\": clf,\n",
    "        \"reg\": reg,\n",
    "        \"train_weights\": w,\n",
    "        \"y_train_arr\": y_train_arr,\n",
    "    }\n",
    "\n",
    "\n",
    "def hurdle_predict(\n",
    "    *,\n",
    "    clf,\n",
    "    reg,\n",
    "    X_i: np.ndarray,\n",
    "    threshold: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Apply hurdle decision rule from already-imputed numeric matrix X_i.\"\"\"\n",
    "    p_zero = clf.predict_proba(X_i)[:, 1]\n",
    "    y_hat = reg.predict(X_i).astype(float)\n",
    "    y_hat[p_zero >= threshold] = 0.0\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def hurdle_sweep(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    *,\n",
    "    thresholds: list[float],\n",
    "    year_col: str = \"album_release_year\",\n",
    "    lambda_recency: float = 0.05,\n",
    "    current_year: int = 2021,\n",
    "    clf=None,\n",
    "    reg=None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One-time fit; sweep thresholds; report val+test metrics.\n",
    "    Returns a DataFrame sorted by val_mae.\n",
    "    \"\"\"\n",
    "    # numeric-only + median imputation\n",
    "    X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(X_train, X_val, X_test)\n",
    "\n",
    "    # recency weights on train\n",
    "    train_year = pd.to_numeric(X_train[year_col], errors=\"coerce\")\n",
    "    w = make_recency_weights(train_year, ref_year=current_year, lam=lambda_recency)\n",
    "\n",
    "    y_train_arr = y_train.to_numpy(dtype=float)\n",
    "    y_val_arr = y_val.to_numpy(dtype=float)\n",
    "    y_test_arr = y_test.to_numpy(dtype=float)\n",
    "\n",
    "    if clf is None:\n",
    "        clf = LogisticRegression(max_iter=1000, n_jobs=1)\n",
    "    if reg is None:\n",
    "        reg = RandomForestRegressor(\n",
    "            n_estimators=80,\n",
    "            max_depth=20,\n",
    "            random_state=42,\n",
    "            n_jobs=4,\n",
    "        )\n",
    "\n",
    "    # fit classifier\n",
    "    y_is_zero = (y_train_arr == 0.0).astype(int)\n",
    "    clf.fit(X_train_i, y_is_zero, sample_weight=w)\n",
    "\n",
    "    # fit regressor on positives only (align weights)\n",
    "    mask_pos = (y_train_arr > 0.0)\n",
    "    reg.fit(X_train_i[mask_pos], y_train_arr[mask_pos], sample_weight=w[mask_pos])\n",
    "\n",
    "    rows = []\n",
    "    for thr in thresholds:\n",
    "        y_pred_val = hurdle_predict(clf=clf, reg=reg, X_i=X_val_i, threshold=thr)\n",
    "        y_pred_test = hurdle_predict(clf=clf, reg=reg, X_i=X_test_i, threshold=thr)\n",
    "\n",
    "        row = {\"threshold\": float(thr)}\n",
    "        # val metrics\n",
    "        row.update({f\"val_{k}\": v for k, v in full_metrics(y_val_arr, y_pred_val).items()})\n",
    "        # test metrics\n",
    "        row.update({f\"test_{k}\": v for k, v in full_metrics(y_test_arr, y_pred_test).items()})\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"val_mae\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def hurdle_compare_thresholds(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    *,\n",
    "    thresholds: list[float],\n",
    "    year_col: str = \"album_release_year\",\n",
    "    lambda_recency: float = 0.05,\n",
    "    current_year: int = 2021,\n",
    "    n_estimators: int = 80,\n",
    "    max_depth: int = 20,\n",
    "    n_jobs: int = 4,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Same as sweep, but returns tidy long-format rows for a small set of thresholds\n",
    "    (good for the final comparison table).\n",
    "    \"\"\"\n",
    "    sweep = hurdle_sweep(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        thresholds=thresholds,\n",
    "        year_col=year_col,\n",
    "        lambda_recency=lambda_recency,\n",
    "        current_year=current_year,\n",
    "        clf=LogisticRegression(max_iter=1000, n_jobs=1),\n",
    "        reg=RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42,\n",
    "            n_jobs=n_jobs,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for _, r in sweep.iterrows():\n",
    "        thr = float(r[\"threshold\"])\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": f\"hurdle@thr={thr:.2f}\",\n",
    "            \"subset\": \"val\",\n",
    "            \"mae\": r[\"val_mae\"],\n",
    "            \"rmse\": r[\"val_rmse\"],\n",
    "            \"r2\": r[\"val_r2\"],\n",
    "            \"mae_zero\": r[\"val_mae_zero\"],\n",
    "            \"mae_pos\": r[\"val_mae_pos\"],\n",
    "            \"pct_zero_true\": r[\"val_pct_zero_true\"],\n",
    "            \"pred_zero_pct\": r[\"val_pred_zero_pct\"],\n",
    "        })\n",
    "        rows.append({\n",
    "            \"model\": f\"hurdle@thr={thr:.2f}\",\n",
    "            \"subset\": \"test\",\n",
    "            \"mae\": r[\"test_mae\"],\n",
    "            \"rmse\": r[\"test_rmse\"],\n",
    "            \"r2\": r[\"test_r2\"],\n",
    "            \"mae_zero\": r[\"test_mae_zero\"],\n",
    "            \"mae_pos\": r[\"test_mae_pos\"],\n",
    "            \"pct_zero_true\": r[\"test_pct_zero_true\"],\n",
    "            \"pred_zero_pct\": r[\"test_pred_zero_pct\"],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_hurdle_tradeoff(\n",
    "    sweep_df: pd.DataFrame,\n",
    "    *,\n",
    "    guardrail_zero_pct: float = 0.4,\n",
    "    final_threshold=0.32,\n",
    "    title: str = \"Hurdle trade-off: validation MAE vs predicted zeros\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot val_mae (left axis) and val_pred_zero_pct (right axis) vs threshold.\n",
    "    Uses seaborn for styling and a 15x8 figure.\n",
    "    \"\"\"\n",
    "\n",
    "    df = sweep_df.sort_values(\"threshold\").reset_index(drop=True)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    # Left axis: Validation MAE (blue)\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"threshold\",\n",
    "        y=\"val_mae\",\n",
    "        marker=\"o\",\n",
    "        color=\"tab:blue\",\n",
    "        ax=ax1,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Threshold\", weight=\"bold\")\n",
    "    ax1.set_ylabel(\"Validation MAE\", color=\"tab:blue\", weight=\"bold\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "    # Right axis: Predicted Zero % (red)\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"threshold\",\n",
    "        y=\"val_pred_zero_pct\",\n",
    "        marker=\"x\",\n",
    "        linestyle=\"--\",\n",
    "        color=\"tab:red\",\n",
    "        ax=ax2,\n",
    "    )\n",
    "    ax2.set_ylabel(\"Predicted Zero % (val)\", color=\"tab:red\", weight=\"bold\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "    # Guardrail reference line\n",
    "    ax2.axhline(\n",
    "        guardrail_zero_pct,\n",
    "        linestyle=\":\",\n",
    "        linewidth=1,\n",
    "        color=\"tab:red\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "\n",
    "    plt.title(title, weight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Guardrail-based selection\n",
    "\n",
    "    valid = sweep[sweep[\"val_pred_zero_pct\"] >= guardrail_zero_pct]\n",
    "    best_run = valid.loc[valid[\"val_mae\"].idxmin()]\n",
    "\n",
    "    print(\"--- GUARDRAIL DECISION ---\")\n",
    "    print(f\"Guardrail: pred_zero_pct >= {guardrail_zero_pct}%\")\n",
    "    print(f\"Selected Threshold (guardrail): {best_run['threshold']}\")\n",
    "    print(f\"MAE={best_run['val_mae']:.4f}, ZeroPct={best_run['val_pred_zero_pct']:.2f}%\")\n",
    "\n",
    "    # Final threshold override (diagnostic choice)\n",
    "\n",
    "    print(\"\\n--- FINAL SELECTED THRESHOLD ---\")\n",
    "    print(f\"Using Threshold = {final_threshold}\")\n",
    "    print(\"Reason: preserves near-optimal MAE while producing ~1% predicted zeros.\")\n",
    "\n",
    "\n",
    "def _hash_df(df: pd.DataFrame) -> str:\n",
    "    h = pd.util.hash_pandas_object(df, index=True).values\n",
    "    return str(np.uint64(h.sum()))\n",
    "\n",
    "def _hash_series(s: pd.Series) -> str:\n",
    "    h = pd.util.hash_pandas_object(s, index=True).values\n",
    "    return str(np.uint64(h.sum()))\n",
    "\n",
    "def _recency_weights(year_s: pd.Series, current_year: int, lambda_recency: float) -> np.ndarray:\n",
    "    year = pd.to_numeric(year_s, errors=\"coerce\").to_numpy(float)\n",
    "    age = np.clip(current_year - np.nan_to_num(year, nan=current_year), 0, None)\n",
    "    return np.exp(-lambda_recency * age)\n",
    "\n",
    "def huber_baseline_report(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "    year_col=\"album_release_year\",\n",
    "    lambda_recency=0.05,\n",
    "    current_year=2021,\n",
    "    clip_preds=False,\n",
    "):\n",
    "    # numeric-only (match what you used in Cycle 2 decision view if applicable)\n",
    "    num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "    Xtr = X_train[num_cols].copy()\n",
    "    Xva = X_val[num_cols].copy()\n",
    "    Xte = X_test[num_cols].copy()\n",
    "\n",
    "    # minimal imputation (median) to avoid NaN-related drift\n",
    "    med = Xtr.median(numeric_only=True)\n",
    "    Xtr = Xtr.fillna(med)\n",
    "    Xva = Xva.fillna(med)\n",
    "    Xte = Xte.fillna(med)\n",
    "\n",
    "    w = _recency_weights(X_train[year_col], current_year, lambda_recency)\n",
    "\n",
    "    model = HuberRegressor()  # defaults\n",
    "    model.fit(Xtr, y_train.to_numpy(float), sample_weight=w)\n",
    "\n",
    "    def _pred(X):\n",
    "        p = model.predict(X).astype(float)\n",
    "        if clip_preds:\n",
    "            p = np.clip(p, 0.0, 100.0)\n",
    "        return p\n",
    "\n",
    "    pred_val = _pred(Xva)\n",
    "    pred_test = _pred(Xte)\n",
    "\n",
    "    return {\n",
    "        \"clip_preds\": clip_preds,\n",
    "        \"model_params\": model.get_params(),\n",
    "        \"n_features_numeric\": int(Xtr.shape[1]),\n",
    "        \"numeric_cols\": list(map(str, Xtr.columns.tolist())),\n",
    "        \"hashes\": {\n",
    "            \"X_train_numeric_hash\": _hash_df(Xtr),\n",
    "            \"X_val_numeric_hash\": _hash_df(Xva),\n",
    "            \"X_test_numeric_hash\": _hash_df(Xte),\n",
    "            \"y_train_hash\": _hash_series(y_train),\n",
    "            \"y_val_hash\": _hash_series(y_val),\n",
    "            \"y_test_hash\": _hash_series(y_test),\n",
    "            \"idx_train_hash\": _hash_series(pd.Series(X_train.index)),\n",
    "            \"idx_val_hash\": _hash_series(pd.Series(X_val.index)),\n",
    "            \"idx_test_hash\": _hash_series(pd.Series(X_test.index)),\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"mae_val\": float(mean_absolute_error(y_val.to_numpy(float), pred_val)),\n",
    "            \"mae_test\": float(mean_absolute_error(y_test.to_numpy(float), pred_test)),\n",
    "            \"pct_zero_test\": float((y_test.to_numpy(float) == 0.0).mean() * 100),\n",
    "            \"pred_min_test\": float(np.min(pred_test)),\n",
    "            \"pred_max_test\": float(np.max(pred_test)),\n",
    "        },\n",
    "        \"env\": {\n",
    "            \"sklearn\": sklearn.__version__,\n",
    "            \"numpy\": np.__version__,\n",
    "            \"pandas\": pd.__version__,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d575124-0ae1-4a54-9fa1-04173ba0f388",
   "metadata": {},
   "source": [
    "# 2. Load Processed Dataset (Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05598a5b-5923-4ed7-9581-8ce3683b8b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.309254Z",
     "iopub.status.busy": "2026-02-11T13:53:14.309078Z",
     "iopub.status.idle": "2026-02-11T13:53:14.631217Z",
     "shell.execute_reply": "2026-02-11T13:53:14.627917Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.309240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>album_release_year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>song_explicit</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>total_available_markets</th>\n",
       "      <th>valence</th>\n",
       "      <th>release_year_missing_or_suspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50464</th>\n",
       "      <td>48</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>141,707.0000</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>-26.1840</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>108.0130</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264352</th>\n",
       "      <td>14</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>400,027.0000</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>-9.6300</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>168.7020</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138397</th>\n",
       "      <td>31</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5260</td>\n",
       "      <td>131,000.0000</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>-6.0380</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>130.0850</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336522</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>116,762.0000</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>-9.3760</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>101.9960</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426369</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>269,398.0000</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>-5.9120</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>123.0640</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        song_popularity  album_release_year  acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "50464                48                2019        0.9530        0.2520 141,707.0000  0.0578            0.0163    1   \n",
       "264352               14                2018        0.0117        0.2990 400,027.0000  0.5460            0.6570    0   \n",
       "138397               31                2018        0.0000        0.5260 131,000.0000  0.9530            0.4590    1   \n",
       "336522                6                2021        0.5380        0.8240 116,762.0000  0.3510            0.0000    7   \n",
       "426369                0                2020        0.4550        0.5280 269,398.0000  0.7680            0.0000    7   \n",
       "\n",
       "        liveness  loudness  mode  song_explicit  speechiness    tempo  time_signature  total_available_markets  \\\n",
       "50464     0.0721  -26.1840     1          False       0.0518 108.0130               4                      170   \n",
       "264352    0.1500   -9.6300     1          False       0.0275 168.7020               3                      170   \n",
       "138397    0.5270   -6.0380     0          False       0.2190 130.0850               4                      170   \n",
       "336522    0.6650   -9.3760     1           True       0.2090 101.9960               3                      170   \n",
       "426369    0.3230   -5.9120     1          False       0.0308 123.0640               4                      169   \n",
       "\n",
       "        valence  release_year_missing_or_suspect  \n",
       "50464    0.0391                            False  \n",
       "264352   0.6090                            False  \n",
       "138397   0.5140                            False  \n",
       "336522   0.4220                            False  \n",
       "426369   0.5950                            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (439865, 18)\n"
     ]
    }
   ],
   "source": [
    "# Ensure processed dataset exists\n",
    "if not DATA_PROCESSED_PATH.exists():\n",
    "    print(\"Processed dataset not found. Running preprocessing...\")\n",
    "    run_preprocessing(default_config(PROJECT_ROOT))\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_parquet(DATA_PROCESSED_PATH)\n",
    "display(df.sample(5))\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800bc5b-9ea0-4cff-bba0-9133f1ad0cc3",
   "metadata": {},
   "source": [
    "# 3. Modeling dataset contract (post-preprocessing)\n",
    "\n",
    "This notebook consumes the **post-preprocessing parquet** as the modeling source of truth.\n",
    "In this section we only:\n",
    "- select the exact modeling columns for Cycle 2 (explicit contract)\n",
    "- run lightweight sanity checks \n",
    "  \n",
    "## 3.1 - Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c50001b-a8d8-4419-b6aa-91f1a36fbd25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.633726Z",
     "iopub.status.busy": "2026-02-11T13:53:14.633086Z",
     "iopub.status.idle": "2026-02-11T13:53:14.689362Z",
     "shell.execute_reply": "2026-02-11T13:53:14.688403Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.633680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 439865 entries, 0 to 439864\n",
      "Data columns (total 18 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   song_popularity                  439865 non-null  int16  \n",
      " 1   album_release_year               439843 non-null  Int16  \n",
      " 2   acousticness                     439865 non-null  float32\n",
      " 3   danceability                     439865 non-null  float32\n",
      " 4   duration_ms                      439865 non-null  float32\n",
      " 5   energy                           439865 non-null  float32\n",
      " 6   instrumentalness                 439865 non-null  float32\n",
      " 7   key                              439865 non-null  int8   \n",
      " 8   liveness                         439865 non-null  float32\n",
      " 9   loudness                         439865 non-null  float32\n",
      " 10  mode                             439865 non-null  int8   \n",
      " 11  song_explicit                    439865 non-null  bool   \n",
      " 12  speechiness                      439865 non-null  float32\n",
      " 13  tempo                            439865 non-null  float32\n",
      " 14  time_signature                   439865 non-null  int8   \n",
      " 15  total_available_markets          439865 non-null  int16  \n",
      " 16  valence                          439865 non-null  float32\n",
      " 17  release_year_missing_or_suspect  439865 non-null  bool   \n",
      "dtypes: Int16(1), bool(2), float32(10), int16(2), int8(3)\n",
      "memory usage: 21.8 MB\n",
      "\n",
      "\n",
      "song_popularity                     0\n",
      "album_release_year                 22\n",
      "acousticness                        0\n",
      "danceability                        0\n",
      "duration_ms                         0\n",
      "energy                              0\n",
      "instrumentalness                    0\n",
      "key                                 0\n",
      "liveness                            0\n",
      "loudness                            0\n",
      "mode                                0\n",
      "song_explicit                       0\n",
      "speechiness                         0\n",
      "tempo                               0\n",
      "time_signature                      0\n",
      "total_available_markets             0\n",
      "valence                             0\n",
      "release_year_missing_or_suspect     0\n",
      "dtype: int64\n",
      "\n",
      "Proportion of zeros in target: 13.401%\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(f'\\n\\n{df.isna().sum()}')\n",
    "print(f\"\\nProportion of zeros in target: {(df['song_popularity'] == 0).mean()*100:.3f}%\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7f5475-e460-4841-b0bb-d197483e6c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.690095Z",
     "iopub.status.busy": "2026-02-11T13:53:14.689945Z",
     "iopub.status.idle": "2026-02-11T13:53:14.727263Z",
     "shell.execute_reply": "2026-02-11T13:53:14.726336Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.690082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>album_release_year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>song_explicit</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>total_available_markets</th>\n",
       "      <th>valence</th>\n",
       "      <th>release_year_missing_or_suspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>242,014.0000</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-8.7610</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>143.8740</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>200,040.0000</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>-5.9340</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>171.0050</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>215,627.0000</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>-5.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>118.0510</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>140,526.0000</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>-3.5580</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>90.9890</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>232,853.0000</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>-4.6370</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>168.0210</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_popularity  album_release_year  acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0              100                2021        0.7210        0.5850 242,014.0000  0.4360            0.0000   10   \n",
       "1               96                2020        0.0015        0.5140 200,040.0000  0.7300            0.0001    1   \n",
       "2               96                2020        0.0212        0.6800 215,627.0000  0.8260            0.0000    0   \n",
       "3               95                2020        0.2210        0.7000 140,526.0000  0.7220            0.0000    7   \n",
       "4               94                2020        0.1220        0.7130 232,853.0000  0.6170            0.0000    8   \n",
       "\n",
       "   liveness  loudness  mode  song_explicit  speechiness    tempo  time_signature  total_available_markets  valence  \\\n",
       "0    0.1050   -8.7610     1           True       0.0601 143.8740               4                      170   0.1320   \n",
       "1    0.0897   -5.9340     1          False       0.0598 171.0050               4                      170   0.3340   \n",
       "2    0.5430   -5.4870     1           True       0.0309 118.0510               4                      170   0.6440   \n",
       "3    0.2720   -3.5580     0           True       0.0369  90.9890               4                      170   0.7560   \n",
       "4    0.0962   -4.6370     1          False       0.0887 168.0210               4                      169   0.6820   \n",
       "\n",
       "   release_year_missing_or_suspect  \n",
       "0                            False  \n",
       "1                            False  \n",
       "2                            False  \n",
       "3                            False  \n",
       "4                            False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_model shape: (439865, 18)\n"
     ]
    }
   ],
   "source": [
    "TARGET_COL = \"song_popularity\"\n",
    "\n",
    "BASE_FEATURE_COLS = [\n",
    "    \"album_release_year\", \"acousticness\", \"danceability\", \"duration_ms\",\n",
    "    \"energy\", \"instrumentalness\", \"key\", \"liveness\", \"loudness\", \"mode\",\n",
    "    \"song_explicit\", \"speechiness\", \"tempo\", \"time_signature\",\n",
    "    \"total_available_markets\", \"valence\", \"release_year_missing_or_suspect\",\n",
    "]\n",
    "\n",
    "MODEL_COLS = [TARGET_COL] + BASE_FEATURE_COLS\n",
    "\n",
    "# Validate and create modeling view\n",
    "missing = [c for c in MODEL_COLS if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "data_model = df[MODEL_COLS].copy()\n",
    "\n",
    "# Lightweight sanity checks\n",
    "assert data_model[TARGET_COL].between(0, 100).all()\n",
    "assert (data_model[\"duration_ms\"].isna() | (data_model[\"duration_ms\"] > 0)).all()\n",
    "assert (data_model[\"tempo\"].isna() | (data_model[\"tempo\"] >= 0)).all()\n",
    "assert (data_model[\"total_available_markets\"].isna() | (data_model[\"total_available_markets\"] >= 0)).all()\n",
    "\n",
    "display(data_model.head())\n",
    "print(\"data_model shape:\", data_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8367f4-0be6-4224-a5d5-2b820fd491b4",
   "metadata": {},
   "source": [
    "## 3.2 - Quick histogram of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9f1e88-82e2-4d67-982d-8509299d99c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:14.728006Z",
     "iopub.status.busy": "2026-02-11T13:53:14.727845Z",
     "iopub.status.idle": "2026-02-11T13:53:16.023698Z",
     "shell.execute_reply": "2026-02-11T13:53:16.022587Z",
     "shell.execute_reply.started": "2026-02-11T13:53:14.727992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "pop_all = data_model[\"song_popularity\"]\n",
    "pop_nonzero = pop_all[pop_all > 0]\n",
    "\n",
    "# Stats\n",
    "prop_zeros = (pop_all == 0).mean()\n",
    "mean_nonzero = pop_nonzero.mean()\n",
    "median_nonzero = pop_nonzero.median()\n",
    "\n",
    "# Subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "ax1.set_xlim(0, 100)\n",
    "\n",
    "# Top: including zeros\n",
    "sns.histplot(pop_all, bins=101, color=\"C0\", ax=ax1)\n",
    "ax1.set_title(\"song_popularity (including zeros)\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.text(\n",
    "    0.98, 0.95, f\"zeros = {prop_zeros:.2%}\",\n",
    "    transform=ax1.transAxes, ha=\"right\", va=\"top\",\n",
    "    fontsize=10, bbox=dict(facecolor=\"white\", alpha=0.8)\n",
    ")\n",
    "\n",
    "# Bottom: excluding zeros\n",
    "sns.histplot(pop_nonzero, bins=100, kde=True, color=\"C1\", ax=ax2)\n",
    "ax2.set_title(\"song_popularity (excluding zeros, KDE)\")\n",
    "ax2.set_xlabel(\"song_popularity\")\n",
    "ax2.set_ylabel(\"Density / Count\")\n",
    "ax2.axvline(mean_nonzero, color=\"C2\", linestyle=\"--\", linewidth=1.2, label=f\"mean={mean_nonzero:.2f}\")\n",
    "ax2.axvline(median_nonzero, color=\"C3\", linestyle=\"-.\", linewidth=1.2, label=f\"median={median_nonzero:.2f}\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bd0cb-cd20-46b4-82ba-58d12bba1158",
   "metadata": {},
   "source": [
    "The distribution of `song_popularity` is strongly non-Gaussian and exhibits clear **zero-inflation** (~13.4% of the samples are exactly zero). This has two practical implications for this notebook:\n",
    "\n",
    "1) Feature improvements must be evaluated beyond a single aggregate metric (e.g., MAE/RMSE), because gains can be driven mostly by the â€œzero-popularityâ€ subgroup while not improving the rest (or vice-versa).\n",
    "\n",
    "2) Even after removing zeros, the target remains **right-skewed** (mean > median) with a long tail. As a result, squared-error metrics can be dominated by a small fraction of high-popularity tracks, so we will also inspect diagnostics by popularity bins (and error patterns across time in the temporal split).\n",
    "\n",
    "This motivates a split-safe ablation workflow and segment-aware diagnostics when deciding which engineered features to keep.\n",
    "\n",
    "\n",
    "# 4. Train / Validation / Test splits\n",
    "\n",
    "We define two split regimes for this notebook:\n",
    "\n",
    "- **Random split** (sanity check): ensures the pipeline runs end-to-end and provides a quick benchmark.\n",
    "  This split mixes years across subsets, so it is **not** used to decide which features to keep.\n",
    "\n",
    "- **Temporal split** (decision split): mimics a realistic â€œtrain on past â†’ validate on next year â†’ test on next yearâ€.\n",
    "  Given the strong concentration of records in recent years (especially 2020 and 2021), we use:\n",
    "  - **Train:** `album_release_year <= 2019` (plus the few rows with missing year)\n",
    "  - **Validation:** `album_release_year == 2020`\n",
    "  - **Test:** `album_release_year == 2021`\n",
    "\n",
    "This temporal design provides large, stable validation/test sets and makes feature selection robust to temporal drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dde666-8ade-416f-a6bb-341783e5cfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:16.024328Z",
     "iopub.status.busy": "2026-02-11T13:53:16.024113Z",
     "iopub.status.idle": "2026-02-11T13:53:16.108786Z",
     "shell.execute_reply": "2026-02-11T13:53:16.107879Z",
     "shell.execute_reply.started": "2026-02-11T13:53:16.024311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>subset</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>year_min</th>\n",
       "      <th>year_max</th>\n",
       "      <th>year_missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>307905</td>\n",
       "      <td>17</td>\n",
       "      <td>1913</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random</td>\n",
       "      <td>val</td>\n",
       "      <td>65980</td>\n",
       "      <td>17</td>\n",
       "      <td>1926</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>65980</td>\n",
       "      <td>17</td>\n",
       "      <td>1905</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temporal</td>\n",
       "      <td>train</td>\n",
       "      <td>283488</td>\n",
       "      <td>17</td>\n",
       "      <td>1905</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temporal</td>\n",
       "      <td>val</td>\n",
       "      <td>105605</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temporal</td>\n",
       "      <td>test</td>\n",
       "      <td>50772</td>\n",
       "      <td>17</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      split subset    rows  cols  year_min  year_max  year_missing_pct\n",
       "0    random  train  307905    17      1913      2021            0.0055\n",
       "1    random    val   65980    17      1926      2021            0.0030\n",
       "2    random   test   65980    17      1905      2021            0.0045\n",
       "3  temporal  train  283488    17      1905      2019            0.0078\n",
       "4  temporal    val  105605    17      2020      2020            0.0000\n",
       "5  temporal   test   50772    17      2021      2021            0.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = \"song_popularity\"\n",
    "YEAR = \"album_release_year\"\n",
    "\n",
    "# --- Create splits ---\n",
    "X_train_r, X_val_r, X_test_r, y_train_r, y_val_r, y_test_r = random_split(data_model, target_col=TARGET)\n",
    "X_train_t, X_val_t, X_test_t, y_train_t, y_val_t, y_test_t = temporal_split(data_model, target_col=TARGET, year_col=YEAR\n",
    ")\n",
    "\n",
    "split_summary = pd.concat(\n",
    "    [\n",
    "        split_table(\"random\", X_train_r, X_val_r, X_test_r, year_col=YEAR),\n",
    "        split_table(\"temporal\", X_train_t, X_val_t, X_test_t, year_col=YEAR),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# Cleaner dtypes for display\n",
    "for c in [\"year_min\", \"year_max\"]:\n",
    "    split_summary[c] = split_summary[c].astype(\"Int64\")\n",
    "\n",
    "split_summary.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2cd05-1ea8-400b-aa25-5e344e07eeef",
   "metadata": {},
   "source": [
    "# 5. Baseline anchor\n",
    "\n",
    "We reproduce a minimal baseline using the same `data_model` and the same split protocol (random + temporal with train/val/test). This provides a stable anchor for the ablation study in Cycle 2.\n",
    "\n",
    "Models:\n",
    "- Constant predictor (median of `y_train`)\n",
    "- Linear Regression (linear reference)\n",
    "- Random Forest Regressor (non-linear reference)\n",
    "\n",
    "Metrics:\n",
    "- MAE / RMSE\n",
    "- Segmented MAE: `y == 0` vs `y > 0` (to track zero-inflation behavior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d359c9-3b85-4293-be68-2b2f3a8e22ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:16.109467Z",
     "iopub.status.busy": "2026-02-11T13:53:16.109320Z",
     "iopub.status.idle": "2026-02-11T13:53:38.737877Z",
     "shell.execute_reply": "2026-02-11T13:53:38.736610Z",
     "shell.execute_reply.started": "2026-02-11T13:53:16.109453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>model</th>\n",
       "      <th>subset</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "      <th>pct_zero_true</th>\n",
       "      <th>pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>train</td>\n",
       "      <td>15.2685</td>\n",
       "      <td>18.7417</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>14.5394</td>\n",
       "      <td>13.3522</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>val</td>\n",
       "      <td>15.1957</td>\n",
       "      <td>18.6688</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>14.4588</td>\n",
       "      <td>13.2980</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>test</td>\n",
       "      <td>15.2736</td>\n",
       "      <td>18.7396</td>\n",
       "      <td>-0.0214</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>14.5210</td>\n",
       "      <td>13.7345</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>train</td>\n",
       "      <td>14.8915</td>\n",
       "      <td>17.9654</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>21.5366</td>\n",
       "      <td>13.8675</td>\n",
       "      <td>13.3522</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>val</td>\n",
       "      <td>14.8215</td>\n",
       "      <td>17.9046</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>21.5354</td>\n",
       "      <td>13.7917</td>\n",
       "      <td>13.2980</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>test</td>\n",
       "      <td>14.9190</td>\n",
       "      <td>17.9952</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>21.6117</td>\n",
       "      <td>13.8534</td>\n",
       "      <td>13.7345</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>random</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>train</td>\n",
       "      <td>13.1531</td>\n",
       "      <td>16.2595</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>18.0803</td>\n",
       "      <td>12.3939</td>\n",
       "      <td>13.3522</td>\n",
       "      <td>0.0559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>val</td>\n",
       "      <td>13.5389</td>\n",
       "      <td>16.6862</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>18.6730</td>\n",
       "      <td>12.7515</td>\n",
       "      <td>13.2980</td>\n",
       "      <td>0.0546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>random</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>test</td>\n",
       "      <td>13.5605</td>\n",
       "      <td>16.7199</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>18.6765</td>\n",
       "      <td>12.7460</td>\n",
       "      <td>13.7345</td>\n",
       "      <td>0.0637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>temporal</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>train</td>\n",
       "      <td>15.1218</td>\n",
       "      <td>18.5685</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>14.3493</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temporal</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>val</td>\n",
       "      <td>15.4539</td>\n",
       "      <td>18.7701</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>temporal</td>\n",
       "      <td>constant_median</td>\n",
       "      <td>test</td>\n",
       "      <td>15.8386</td>\n",
       "      <td>18.4789</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>14.2203</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>temporal</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>train</td>\n",
       "      <td>14.6553</td>\n",
       "      <td>17.7355</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>21.8828</td>\n",
       "      <td>13.7056</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>temporal</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>val</td>\n",
       "      <td>15.3300</td>\n",
       "      <td>18.6525</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>21.2540</td>\n",
       "      <td>14.4319</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>temporal</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>test</td>\n",
       "      <td>15.3305</td>\n",
       "      <td>18.2615</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>18.9381</td>\n",
       "      <td>14.1994</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>temporal</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>train</td>\n",
       "      <td>12.8455</td>\n",
       "      <td>15.9647</td>\n",
       "      <td>0.2483</td>\n",
       "      <td>18.6555</td>\n",
       "      <td>12.0820</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>temporal</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>val</td>\n",
       "      <td>14.5174</td>\n",
       "      <td>17.6451</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>20.1104</td>\n",
       "      <td>13.6694</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>temporal</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>test</td>\n",
       "      <td>15.3934</td>\n",
       "      <td>18.5587</td>\n",
       "      <td>-0.0223</td>\n",
       "      <td>20.0897</td>\n",
       "      <td>13.9210</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       split              model subset     mae    rmse      r2  mae_zero  mae_pos  pct_zero_true  pred_zero_pct\n",
       "0     random    constant_median  train 15.2685 18.7417 -0.0232   20.0000  14.5394        13.3522         0.0000\n",
       "1     random    constant_median    val 15.1957 18.6688 -0.0236   20.0000  14.4588        13.2980         0.0000\n",
       "2     random    constant_median   test 15.2736 18.7396 -0.0214   20.0000  14.5210        13.7345         0.0000\n",
       "3     random  linear_regression  train 14.8915 17.9654  0.0598   21.5366  13.8675        13.3522         0.0000\n",
       "4     random  linear_regression    val 14.8215 17.9046  0.0585   21.5354  13.7917        13.2980         0.0000\n",
       "5     random  linear_regression   test 14.9190 17.9952  0.0581   21.6117  13.8534        13.7345         0.0000\n",
       "6     random      random_forest  train 13.1531 16.2595  0.2298   18.0803  12.3939        13.3522         0.0559\n",
       "7     random      random_forest    val 13.5389 16.6862  0.1823   18.6730  12.7515        13.2980         0.0546\n",
       "8     random      random_forest   test 13.5605 16.7199  0.1869   18.6765  12.7460        13.7345         0.0637\n",
       "9   temporal    constant_median  train 15.1218 18.5685 -0.0169   21.0000  14.3493        11.6146         0.0000\n",
       "10  temporal    constant_median    val 15.4539 18.7701 -0.0130   21.0000  14.6130        13.1651         0.0000\n",
       "11  temporal    constant_median   test 15.8386 18.4789 -0.0135   21.0000  14.2203        23.8695         0.0000\n",
       "12  temporal  linear_regression  train 14.6553 17.7355  0.0723   21.8828  13.7056        11.6146         0.0000\n",
       "13  temporal  linear_regression    val 15.3300 18.6525 -0.0004   21.2540  14.4319        13.1651         0.0000\n",
       "14  temporal  linear_regression   test 15.3305 18.2615  0.0102   18.9381  14.1994        23.8695         0.0000\n",
       "15  temporal      random_forest  train 12.8455 15.9647  0.2483   18.6555  12.0820        11.6146         0.0550\n",
       "16  temporal      random_forest    val 14.5174 17.6451  0.1048   20.1104  13.6694        13.1651         0.0000\n",
       "17  temporal      random_forest   test 15.3934 18.5587 -0.0223   20.0897  13.9210        23.8695         0.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Prepare splits ---\n",
    "splits_for_eval = {\n",
    "    \"random\":   (X_train_r, X_val_r, X_test_r, y_train_r, y_val_r, y_test_r),\n",
    "    \"temporal\": (X_train_t, X_val_t, X_test_t, y_train_t, y_val_t, y_test_t),\n",
    "}\n",
    "\n",
    "# --- Baseline models ---\n",
    "baseline_models = {\n",
    "    \"constant_median\": DummyRegressor(strategy=\"median\"),\n",
    "    \"linear_regression\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]),\n",
    "    \"random_forest\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=50, max_depth=12, min_samples_leaf=5,\n",
    "            random_state=RANDOM_STATE, n_jobs=-1\n",
    "        )),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# --- Run all models on all splits ---\n",
    "results_baseline = pd.concat(\n",
    "    [\n",
    "        evaluate_model_on_splits(model, model_name=name, splits=splits_for_eval)\n",
    "        for name, model in baseline_models.items()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# --- Ordering for clean display ---\n",
    "subset_order = {\"train\": 0, \"val\": 1, \"test\": 2}\n",
    "model_order = {\"constant_median\": 0, \"linear_regression\": 1, \"random_forest\": 2}\n",
    "\n",
    "results_baseline = (\n",
    "    results_baseline\n",
    "    .assign(\n",
    "        subset_order=lambda df: df[\"subset\"].map(subset_order),\n",
    "        model_order=lambda df: df[\"model\"].map(model_order),\n",
    "    )\n",
    "    .sort_values([\"split\", \"model_order\", \"subset_order\"])\n",
    "    .drop(columns=[\"subset_order\", \"model_order\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "results_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06301823-3564-4d4a-a56f-09789d11f4bb",
   "metadata": {},
   "source": [
    "## 5.1 - Baseline takeaways (what this implies for Cycle 2)\n",
    "\n",
    "### 1. Protocol check (temporal split hygiene)\n",
    "\n",
    "We verified the temporal split hygiene with respect to year quality:\n",
    "\n",
    "- **Validation (2020):** 0 `release_year_missing_or_suspect` rows and 0 missing `album_release_year`\n",
    "- **Test (2021):** 0 `release_year_missing_or_suspect` rows and 0 missing `album_release_year`\n",
    "\n",
    "A small number of flagged/missing-year rows remain in the temporal training set (**22 rows**, ~**0.008%**), which is negligible at this scale and does not affect the integrity of the temporal generalization check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7582c8-deef-4e51-af9e-f9cfe2f5a8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:38.739003Z",
     "iopub.status.busy": "2026-02-11T13:53:38.738778Z",
     "iopub.status.idle": "2026-02-11T13:53:38.751951Z",
     "shell.execute_reply": "2026-02-11T13:53:38.750138Z",
     "shell.execute_reply.started": "2026-02-11T13:53:38.738983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>flagged_rows</th>\n",
       "      <th>flagged_pct</th>\n",
       "      <th>missing_year_rows</th>\n",
       "      <th>missing_year_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>283,488.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>105,605.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>50,772.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rows  flagged_rows  flagged_pct  missing_year_rows  missing_year_pct\n",
       "train 283,488.0000       22.0000       0.0078            22.0000            0.0078\n",
       "val   105,605.0000        0.0000       0.0000             0.0000            0.0000\n",
       "test   50,772.0000        0.0000       0.0000             0.0000            0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = pd.DataFrame({\n",
    "    \"train\": x_counts(X_train_t),\n",
    "    \"val\": x_counts(X_val_t),\n",
    "    \"test\": x_counts(X_test_t),\n",
    "}).T\n",
    "\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0ede2-a908-4579-8cbc-8ad2f1640b4a",
   "metadata": {},
   "source": [
    "### 2. Takeaways\n",
    "\n",
    "- **Non-linearity exists (random split):** Random Forest clearly outperforms Linear Regression on validation/test, suggesting that the target depends on non-linear patterns and feature interactions.\n",
    "\n",
    "- **Temporal generalization is harder (temporal split):** The gap between Random Forest and Linear Regression shrinks substantially on 2020/2021. Random Forest fits the past very well (train) but does not transfer as strongly to the future years, which is consistent with temporal drift / distribution shift.\n",
    "\n",
    "- **Zero-inflation increases sharply in 2021:** The share of `song_popularity == 0` rises from ~11â€“13% (train/2020) to ~24% in the 2021 test set. This can dominate MAE/RMSE and explains why performance degrades in the temporal test.\n",
    "\n",
    "- **Segment-aware evaluation is mandatory:** All feature engineering decisions in Cycle 2 should be judged on the **temporal validation/test** and should always report:\n",
    "  - global MAE/RMSE\n",
    "  - `mae_zero` vs `mae_pos`\n",
    "  This prevents misleading improvements driven only by the zero-popularity subgroup.\n",
    "\n",
    "- **Implication for the ablation plan:** We will keep the temporal split as the primary decision split and run a block-by-block ablation (temporal â†’ interactions â†’ non-linear â†’ market â†’ year-meta last). Year-level target-encoding features are treated as â€œhigh-riskâ€ and must show consistent gains on 2021 test (not only on 2020 validation).\n",
    "\n",
    "## 5.2 - Baseline consolidation\n",
    "\n",
    "We consolidate the baseline results into compact tables focused on the **temporal split** (our decision split),\n",
    "while still keeping the random split as a sanity reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a5b8e3-54d9-4c86-882f-8c1f0d178889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:38.752985Z",
     "iopub.status.busy": "2026-02-11T13:53:38.752739Z",
     "iopub.status.idle": "2026-02-11T13:53:38.824589Z",
     "shell.execute_reply": "2026-02-11T13:53:38.821401Z",
     "shell.execute_reply.started": "2026-02-11T13:53:38.752963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae_pos</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae_zero</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pct_zero_true</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pred_zero_pct</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.1218</td>\n",
       "      <td>15.4539</td>\n",
       "      <td>15.8386</td>\n",
       "      <td>14.3493</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>14.2203</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.5685</td>\n",
       "      <td>18.7701</td>\n",
       "      <td>18.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.6553</td>\n",
       "      <td>15.3300</td>\n",
       "      <td>15.3305</td>\n",
       "      <td>13.7056</td>\n",
       "      <td>14.4319</td>\n",
       "      <td>14.1994</td>\n",
       "      <td>21.8828</td>\n",
       "      <td>21.2540</td>\n",
       "      <td>18.9381</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.7355</td>\n",
       "      <td>18.6525</td>\n",
       "      <td>18.2615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>12.8455</td>\n",
       "      <td>14.5174</td>\n",
       "      <td>15.3934</td>\n",
       "      <td>12.0820</td>\n",
       "      <td>13.6694</td>\n",
       "      <td>13.9210</td>\n",
       "      <td>18.6555</td>\n",
       "      <td>20.1104</td>\n",
       "      <td>20.0897</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>15.9647</td>\n",
       "      <td>17.6451</td>\n",
       "      <td>18.5587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mae                 mae_pos                 mae_zero                 pct_zero_true          \\\n",
       "subset              train     val    test   train     val    test    train     val    test         train     val   \n",
       "model                                                                                                              \n",
       "constant_median   15.1218 15.4539 15.8386 14.3493 14.6130 14.2203  21.0000 21.0000 21.0000       11.6146 13.1651   \n",
       "linear_regression 14.6553 15.3300 15.3305 13.7056 14.4319 14.1994  21.8828 21.2540 18.9381       11.6146 13.1651   \n",
       "random_forest     12.8455 14.5174 15.3934 12.0820 13.6694 13.9210  18.6555 20.1104 20.0897       11.6146 13.1651   \n",
       "\n",
       "                          pred_zero_pct                  rmse                  \n",
       "subset               test         train    val   test   train     val    test  \n",
       "model                                                                          \n",
       "constant_median   23.8695        0.0000 0.0000 0.0000 18.5685 18.7701 18.4789  \n",
       "linear_regression 23.8695        0.0000 0.0000 0.0000 17.7355 18.6525 18.2615  \n",
       "random_forest     23.8695        0.0550 0.0000 0.0000 15.9647 17.6451 18.5587  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>14.5174</td>\n",
       "      <td>17.6451</td>\n",
       "      <td>20.1104</td>\n",
       "      <td>13.6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>15.3300</td>\n",
       "      <td>18.6525</td>\n",
       "      <td>21.2540</td>\n",
       "      <td>14.4319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constant_median</td>\n",
       "      <td>15.4539</td>\n",
       "      <td>18.7701</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>14.6130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model     mae    rmse  mae_zero  mae_pos\n",
       "0      random_forest 14.5174 17.6451   20.1104  13.6694\n",
       "1  linear_regression 15.3300 18.6525   21.2540  14.4319\n",
       "2    constant_median 15.4539 18.7701   21.0000  14.6130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_cols = [\"mae\", \"rmse\", \"mae_zero\", \"mae_pos\", \"pct_zero_true\", \"pred_zero_pct\"]\n",
    "subset_order = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# A) Full pivot\n",
    "results_baseline_pivot = (\n",
    "    results_baseline\n",
    "    .pivot_table(index=[\"split\", \"model\"], columns=\"subset\", values=metric_cols, aggfunc=\"first\")\n",
    "    .reindex(subset_order, axis=1, level=1)\n",
    ")\n",
    "\n",
    "# B) Temporal-only pivot\n",
    "results_temporal_pivot = (\n",
    "    results_baseline\n",
    "    .query(\"split == 'temporal'\")\n",
    "    .pivot_table(index=\"model\", columns=\"subset\", values=metric_cols, aggfunc=\"first\")\n",
    "    .reindex(subset_order, axis=1, level=1)\n",
    ")\n",
    "display(results_temporal_pivot)\n",
    "\n",
    "# C) Ranking on temporal validation MAE\n",
    "rank_temporal_val = (\n",
    "    results_baseline\n",
    "    .query(\"split == 'temporal' and subset == 'val'\")\n",
    "    [[\"model\", \"mae\", \"rmse\", \"mae_zero\", \"mae_pos\"]]\n",
    "    .sort_values(\"mae\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "rank_temporal_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa7625-6405-434e-8cf2-02af5a724fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T22:27:16.341951Z",
     "iopub.status.busy": "2026-02-04T22:27:16.341444Z",
     "iopub.status.idle": "2026-02-04T22:27:16.361122Z",
     "shell.execute_reply": "2026-02-04T22:27:16.353758Z",
     "shell.execute_reply.started": "2026-02-04T22:27:16.341918Z"
    }
   },
   "source": [
    "The temporal-only pivot and the validation ranking above are the main decision views for Cycle 2 ablations.\n",
    "They summarize performance on (Train â‰¤ 2019, Val = 2020, Test = 2021) and help us select the anchor model.\n",
    "\n",
    "Implication for Cycle 2: feature decisions will prioritize **temporal validation/test** and will always report both\n",
    "global metrics (MAE/RMSE) and segment metrics (`mae_zero`, `mae_pos`) to avoid misleading gains driven only by one regime.\n",
    "\n",
    "# 6. Feature engineering pipeline (setup + invariants)\n",
    "\n",
    "In this section we instantiate the feature engineering pipeline from `src/` and run a split-safe smoke test:\n",
    "- fit only on `X_train`\n",
    "- transform on `X_val` / `X_test`\n",
    "- verify shape consistency and basic numeric sanity (no NaNs explosion / no infinities)\n",
    "\n",
    "## 6.1 - Control config (all blocks OFF)\n",
    "\n",
    "We start with a control configuration where all feature blocks are disabled. The expected output is a pure\n",
    "passthrough: the transformed matrices must preserve the original columns and row counts. This validates the\n",
    "pipeline wiring before any ablation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313a1617-0300-4438-b735-84fdcc6ae712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:38.826897Z",
     "iopub.status.busy": "2026-02-11T13:53:38.826566Z",
     "iopub.status.idle": "2026-02-11T13:53:38.857415Z",
     "shell.execute_reply": "2026-02-11T13:53:38.852212Z",
     "shell.execute_reply.started": "2026-02-11T13:53:38.826869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature pipeline is empty. Using passthrough.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  album_release_year\n",
       "1                        acousticness\n",
       "2                        danceability\n",
       "3                         duration_ms\n",
       "4                              energy\n",
       "5                    instrumentalness\n",
       "6                                 key\n",
       "7                            liveness\n",
       "8                            loudness\n",
       "9                                mode\n",
       "10                      song_explicit\n",
       "11                        speechiness\n",
       "12                              tempo\n",
       "13                     time_signature\n",
       "14            total_available_markets\n",
       "15                            valence\n",
       "16    release_year_missing_or_suspect\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_off = FeatureEngineeringConfig(\n",
    "    temporal=False,\n",
    "    audio_interactions=False,\n",
    "    non_linear=False,\n",
    "    market=False,\n",
    "    year_meta=False,\n",
    ")\n",
    "\n",
    "feature_pipeline_off = build_feature_pipeline(fe_config_off)\n",
    "\n",
    "# Passthrough if pipeline is empty\n",
    "if getattr(feature_pipeline_off, \"steps\", []):\n",
    "    X_train_fe = feature_pipeline_off.fit_transform(X_train_t, y_train_t)\n",
    "    X_val_fe   = feature_pipeline_off.transform(X_val_t)\n",
    "    X_test_fe  = feature_pipeline_off.transform(X_test_t)\n",
    "else:\n",
    "    X_train_fe, X_val_fe, X_test_fe = X_train_t.copy(), X_val_t.copy(), X_test_t.copy()\n",
    "    print(\"Feature pipeline is empty. Using passthrough.\\n\")\n",
    "\n",
    "# Invariants\n",
    "assert len(X_train_fe) == len(X_train_t)\n",
    "assert len(X_val_fe)   == len(X_val_t)\n",
    "assert len(X_test_fe)  == len(X_test_t)\n",
    "assert list(X_train_fe.columns) == list(X_train_t.columns)\n",
    "\n",
    "display(pd.Series(X_train_fe.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f340d-3d6c-4a32-8b1d-99559f2f0f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T22:43:23.364148Z",
     "iopub.status.busy": "2026-02-04T22:43:23.363549Z",
     "iopub.status.idle": "2026-02-04T22:43:23.391495Z",
     "shell.execute_reply": "2026-02-04T22:43:23.379062Z",
     "shell.execute_reply.started": "2026-02-04T22:43:23.364113Z"
    }
   },
   "source": [
    "Sanity check: with all feature blocks disabled, the pipeline behaves as a passthrough and preserves the original 17 base features. This confirms the split-safe plumbing is correct before running ablations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1d3bd-2e46-4085-94b3-2035a377514c",
   "metadata": {},
   "source": [
    "## 6.2 - Single-block preview: temporal features\n",
    "\n",
    "We enable only the temporal block to validate that:\n",
    "- temporal features are generated consistently across train/val/test\n",
    "- row counts are preserved\n",
    "- the new temporal columns behave sensibly (e.g., no negative ages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47b04c9-ccc9-4123-8967-586df1d3b042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:38.859521Z",
     "iopub.status.busy": "2026-02-11T13:53:38.858971Z",
     "iopub.status.idle": "2026-02-11T13:53:38.973956Z",
     "shell.execute_reply": "2026-02-11T13:53:38.973061Z",
     "shell.execute_reply.started": "2026-02-11T13:53:38.859472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New temporal columns: ['age', 'age_bin', 'is_future_release', 'is_post_2015', 'is_post_2018', 'year_is_missing', 'year_zscore']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>is_future_release</th>\n",
       "      <th>is_post_2015</th>\n",
       "      <th>is_post_2018</th>\n",
       "      <th>year_is_missing</th>\n",
       "      <th>year_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  age_bin  is_future_release  is_post_2015  is_post_2018  year_is_missing  year_zscore\n",
       "11 2.0000        0              False          True          True            False       0.7275\n",
       "26 2.0000        0              False          True          True            False       0.7275\n",
       "31 2.0000        0              False          True          True            False       0.7275\n",
       "42 8.0000        2              False         False         False            False       0.0907\n",
       "43 2.0000        0              False          True          True            False       0.7275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_temporal = FeatureEngineeringConfig(\n",
    "    temporal=True, audio_interactions=False, non_linear=False,\n",
    "    market=False, year_meta=False, current_year=2021\n",
    ")\n",
    "\n",
    "pipe_tem = build_feature_pipeline(fe_config_temporal)\n",
    "\n",
    "X_train_tem = pipe_tem.fit_transform(X_train_t, y_train_t)\n",
    "X_val_tem   = pipe_tem.transform(X_val_t)\n",
    "X_test_tem  = pipe_tem.transform(X_test_t)\n",
    "\n",
    "# Invariants\n",
    "for a, b in [(X_train_tem, X_train_t), (X_val_tem, X_val_t), (X_test_tem, X_test_t)]:\n",
    "    assert len(a) == len(b)\n",
    "\n",
    "# New columns\n",
    "new_cols = X_train_tem.columns.difference(X_train_t.columns)\n",
    "print(\"New temporal columns:\", list(new_cols))\n",
    "\n",
    "# Sanity checks\n",
    "for name, X in [(\"train\", X_train_tem), (\"val\", X_val_tem), (\"test\", X_test_tem)]:\n",
    "    assert (X[\"age\"].dropna() >= 0).all(), f\"Negative ages in {name}\"\n",
    "\n",
    "assert X_train_tem[\"age_bin\"].dropna().between(0, len(fe_config_temporal.age_bins)).all()\n",
    "\n",
    "display(X_train_tem[new_cols].head() if len(new_cols) else X_train_tem.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0292758-b321-4dab-85a5-2ba73bea1c44",
   "metadata": {},
   "source": [
    "## 6.3 - Single-block preview: audio interactions\n",
    "\n",
    "We enable only the audio interaction block to verify that:\n",
    "- interaction features are created deterministically\n",
    "- row counts are preserved across train/val/test\n",
    "- no invalid numeric values are introduced (inf / unexpected NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8ce8ab-838b-47b8-884b-b15ffec2bde1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:38.975030Z",
     "iopub.status.busy": "2026-02-11T13:53:38.974884Z",
     "iopub.status.idle": "2026-02-11T13:53:39.048857Z",
     "shell.execute_reply": "2026-02-11T13:53:39.045862Z",
     "shell.execute_reply.started": "2026-02-11T13:53:38.975016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New audio interaction columns: ['emotional_intensity', 'punch', 'rap_speed', 'soft_mood', 'vibe']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotional_intensity</th>\n",
       "      <th>punch</th>\n",
       "      <th>rap_speed</th>\n",
       "      <th>soft_mood</th>\n",
       "      <th>vibe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0880</td>\n",
       "      <td>3.9045</td>\n",
       "      <td>7.4543</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.3468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1806</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>3.5055</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.4545</td>\n",
       "      <td>3.4345</td>\n",
       "      <td>4.4356</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.4472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.3212</td>\n",
       "      <td>2.2677</td>\n",
       "      <td>4.1682</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.6502</td>\n",
       "      <td>3.9704</td>\n",
       "      <td>6.0378</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotional_intensity  punch  rap_speed  soft_mood   vibe\n",
       "11               0.0880 3.9045     7.4543     0.0395 0.3468\n",
       "26               0.1806 2.3000     3.5055     0.3349 0.2029\n",
       "31               0.4545 3.4345     4.4356     0.0680 0.4472\n",
       "42               0.3212 2.2677     4.1682     0.0197 0.4939\n",
       "43               0.6502 3.9704     6.0378     0.0150 0.5575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_audio = FeatureEngineeringConfig(\n",
    "    temporal=False, audio_interactions=True,\n",
    "    non_linear=False, market=False, year_meta=False\n",
    ")\n",
    "\n",
    "pipe_audio = build_feature_pipeline(fe_config_audio)\n",
    "\n",
    "X_train_aud = apply_feature_engineering(X_train_t, pipe_audio, fit=True,  y=y_train_t)\n",
    "X_val_aud   = apply_feature_engineering(X_val_t,   pipe_audio, fit=False)\n",
    "X_test_aud  = apply_feature_engineering(X_test_t,  pipe_audio, fit=False)\n",
    "\n",
    "# Invariants\n",
    "for a, b in [(X_train_aud, X_train_t), (X_val_aud, X_val_t), (X_test_aud, X_test_t)]:\n",
    "    assert len(a) == len(b)\n",
    "\n",
    "# New columns\n",
    "new_cols = X_train_aud.columns.difference(X_train_t.columns)\n",
    "print(\"New audio interaction columns:\", list(new_cols))\n",
    "\n",
    "# Sanity check on new block\n",
    "if len(new_cols):\n",
    "    arr = X_train_aud[new_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(float)\n",
    "    assert np.isfinite(arr).all()\n",
    "\n",
    "# Preview\n",
    "display(X_train_aud[new_cols].head() if len(new_cols) else X_train_aud.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66790da-9bb4-42ce-929a-bae632f497b2",
   "metadata": {},
   "source": [
    "## 6.4 - Single-block preview: non-linear transforms\n",
    "\n",
    "We enable only the non-linear block to verify that:\n",
    "- simple non-linear transforms (e.g., log / squared / z-scores) are generated correctly\n",
    "- row counts are preserved across train/val/test\n",
    "- no invalid numeric values are introduced (inf / unexpected NaNs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d383a5-cbf6-491e-9def-a10245499f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:39.050744Z",
     "iopub.status.busy": "2026-02-11T13:53:39.050332Z",
     "iopub.status.idle": "2026-02-11T13:53:39.133694Z",
     "shell.execute_reply": "2026-02-11T13:53:39.132662Z",
     "shell.execute_reply.started": "2026-02-11T13:53:39.050711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New non-linear columns: ['danceability_sq', 'energy_sq', 'log_duration', 'tempo_is_zero', 'tempo_log1p', 'tempo_zscore', 'valence_sq']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability_sq</th>\n",
       "      <th>energy_sq</th>\n",
       "      <th>log_duration</th>\n",
       "      <th>tempo_is_zero</th>\n",
       "      <th>tempo_log1p</th>\n",
       "      <th>tempo_zscore</th>\n",
       "      <th>valence_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>12.3327</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5112</td>\n",
       "      <td>-0.9589</td>\n",
       "      <td>0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>12.1127</td>\n",
       "      <td>False</td>\n",
       "      <td>4.7085</td>\n",
       "      <td>-0.3022</td>\n",
       "      <td>0.1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>12.0668</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5684</td>\n",
       "      <td>-0.7816</td>\n",
       "      <td>0.3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>12.3901</td>\n",
       "      <td>False</td>\n",
       "      <td>4.8287</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.5929</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>12.0830</td>\n",
       "      <td>False</td>\n",
       "      <td>4.8120</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.8064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    danceability_sq  energy_sq  log_duration  tempo_is_zero  tempo_log1p  tempo_zscore  valence_sq\n",
       "11           0.5610     0.2144       12.3327          False       4.5112       -0.9589      0.0361\n",
       "26           0.2510     0.1640       12.1127          False       4.7085       -0.3022      0.1989\n",
       "31           0.3003     0.6659       12.0668          False       4.5684       -0.7816      0.3102\n",
       "42           0.3745     0.6512       12.3901          False       4.8287        0.1660      0.1584\n",
       "43           0.5929     0.5242       12.0830          False       4.8120        0.0973      0.8064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_nl = FeatureEngineeringConfig(\n",
    "    temporal=False, audio_interactions=False,\n",
    "    non_linear=True, market=False, year_meta=False\n",
    ")\n",
    "\n",
    "pipe_nl = build_feature_pipeline(fe_config_nl)\n",
    "\n",
    "X_train_nl = apply_feature_engineering(X_train_t, pipe_nl, fit=True,  y=y_train_t)\n",
    "X_val_nl   = apply_feature_engineering(X_val_t,   pipe_nl, fit=False)\n",
    "X_test_nl  = apply_feature_engineering(X_test_t,  pipe_nl, fit=False)\n",
    "\n",
    "# Invariants\n",
    "for a, b in [(X_train_nl, X_train_t), (X_val_nl, X_val_t), (X_test_nl, X_test_t)]:\n",
    "    assert len(a) == len(b)\n",
    "\n",
    "# New columns\n",
    "new_cols = X_train_nl.columns.difference(X_train_t.columns)\n",
    "print(\"New non-linear columns:\", list(new_cols))\n",
    "\n",
    "# Sanity check on new block\n",
    "if len(new_cols):\n",
    "    arr = X_train_nl[new_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(float)\n",
    "    assert np.isfinite(arr).all()\n",
    "\n",
    "display(X_train_nl[new_cols].head() if len(new_cols) else X_train_nl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233d416-4b41-42e3-b460-3e0f0dc842c0",
   "metadata": {},
   "source": [
    "## 6.5 - Single-block preview: market features\n",
    "\n",
    "We enable only the market block to verify that:\n",
    "- market-derived features are created consistently\n",
    "- row counts are preserved across train/val/test\n",
    "- no invalid numeric values are introduced (inf / unexpected NaNs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638fe65e-b92b-4dae-9e29-0a36861471b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:39.134252Z",
     "iopub.status.busy": "2026-02-11T13:53:39.134071Z",
     "iopub.status.idle": "2026-02-11T13:53:39.173072Z",
     "shell.execute_reply": "2026-02-11T13:53:39.170982Z",
     "shell.execute_reply.started": "2026-02-11T13:53:39.134236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New market columns: ['markets_bucket', 'markets_zscore']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markets_bucket</th>\n",
       "      <th>markets_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.2904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    markets_bucket  markets_zscore\n",
       "11               2          0.3036\n",
       "26               2          0.3036\n",
       "31               2          0.3036\n",
       "42               2          0.2496\n",
       "43               1         -0.2904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_market = FeatureEngineeringConfig(\n",
    "    temporal=False, audio_interactions=False,\n",
    "    non_linear=False, market=True, year_meta=False\n",
    ")\n",
    "\n",
    "pipe_mkt = build_feature_pipeline(fe_config_market)\n",
    "\n",
    "X_train_mkt = apply_feature_engineering(X_train_t, pipe_mkt, fit=True,  y=y_train_t)\n",
    "X_val_mkt   = apply_feature_engineering(X_val_t,   pipe_mkt, fit=False)\n",
    "X_test_mkt  = apply_feature_engineering(X_test_t,  pipe_mkt, fit=False)\n",
    "\n",
    "# Invariants\n",
    "for a, b in [(X_train_mkt, X_train_t), (X_val_mkt, X_val_t), (X_test_mkt, X_test_t)]:\n",
    "    assert len(a) == len(b)\n",
    "\n",
    "# New columns\n",
    "new_cols = X_train_mkt.columns.difference(X_train_t.columns)\n",
    "print(\"New market columns:\", list(new_cols))\n",
    "\n",
    "# Sanity check\n",
    "if len(new_cols):\n",
    "    arr = X_train_mkt[new_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(float)\n",
    "    assert np.isfinite(arr).all()\n",
    "\n",
    "display(X_train_mkt[new_cols].head() if len(new_cols) else X_train_mkt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2aaa4-fe46-4403-a11f-2bd893534991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:32:35.992317Z",
     "iopub.status.busy": "2026-02-04T23:32:35.991668Z",
     "iopub.status.idle": "2026-02-04T23:32:36.098661Z",
     "shell.execute_reply": "2026-02-04T23:32:36.096951Z",
     "shell.execute_reply.started": "2026-02-04T23:32:35.992277Z"
    }
   },
   "source": [
    "## 6.6 Single-block preview: year meta-features (split-safe)\n",
    "\n",
    "We enable only the year-meta block (target-informed features) to verify:\n",
    "- the mapping is learned on training data only (`fit` uses `y_train`)\n",
    "- validation/test are transformed without using their targets\n",
    "- no shape breaks occur across train/val/test\n",
    "\n",
    "Note: This block is higher risk (potential leakage if misused). We keep it for last in the ablation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eaba72f-59b6-4470-84e7-e9309b387a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:39.175326Z",
     "iopub.status.busy": "2026-02-11T13:53:39.174875Z",
     "iopub.status.idle": "2026-02-11T13:53:40.100731Z",
     "shell.execute_reply": "2026-02-11T13:53:40.100032Z",
     "shell.execute_reply.started": "2026-02-11T13:53:39.175293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New year-meta columns: ['year_popularity_mean', 'year_trend']\n",
      "year_popularity_mean: NaN%=0.008 | inf%=0.000\n",
      "year_trend: NaN%=0.014 | inf%=0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_popularity_mean</th>\n",
       "      <th>year_trend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>album_release_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>16.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>37.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>15.7778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>31.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>-25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>13.0000</td>\n",
       "      <td>-17.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>28.0000</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>23.0000</td>\n",
       "      <td>-5.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    year_popularity_mean  year_trend\n",
       "album_release_year                                  \n",
       "1905                             16.5000         NaN\n",
       "1913                             16.0000         NaN\n",
       "1923                             37.0000         NaN\n",
       "1926                             15.7778         NaN\n",
       "1929                             31.0000         NaN\n",
       "1930                              6.0000    -25.0000\n",
       "1932                             30.0000         NaN\n",
       "1933                             13.0000    -17.0000\n",
       "1934                             28.0000     15.0000\n",
       "1935                             23.0000     -5.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_popularity_mean</th>\n",
       "      <th>year_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23.1603</td>\n",
       "      <td>-0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23.1603</td>\n",
       "      <td>-0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23.1603</td>\n",
       "      <td>-0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20.6098</td>\n",
       "      <td>-0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>23.1603</td>\n",
       "      <td>-0.0980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_popularity_mean  year_trend\n",
       "11               23.1603     -0.0980\n",
       "26               23.1603     -0.0980\n",
       "31               23.1603     -0.0980\n",
       "42               20.6098     -0.8550\n",
       "43               23.1603     -0.0980"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_year = FeatureEngineeringConfig(\n",
    "    temporal=False, audio_interactions=False, non_linear=False,\n",
    "    market=False, year_meta=True, year_smoothing=0.0, min_year_count=1\n",
    ")\n",
    "\n",
    "pipe_year = build_feature_pipeline(fe_config_year)\n",
    "\n",
    "# Fit on train (with y), transform val/test without y\n",
    "X_train_yr = apply_feature_engineering(X_train_t, pipe_year, fit=True,  y=y_train_t)\n",
    "X_val_yr   = apply_feature_engineering(X_val_t,   pipe_year, fit=False)\n",
    "X_test_yr  = apply_feature_engineering(X_test_t,  pipe_year, fit=False)\n",
    "\n",
    "# Invariants\n",
    "for a, b in [(X_train_yr, X_train_t), (X_val_yr, X_val_t), (X_test_yr, X_test_t)]:\n",
    "    assert len(a) == len(b)\n",
    "\n",
    "# New columns\n",
    "new_cols_year = X_train_yr.columns.difference(X_train_t.columns)\n",
    "print(\"New year-meta columns:\", list(new_cols_year))\n",
    "\n",
    "# Sanity checks on new columns\n",
    "if len(new_cols_year):\n",
    "    block = X_train_yr[new_cols_year].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    for c in new_cols_year:\n",
    "        col = block[c]\n",
    "        print(f\"{c}: NaN%={col.isna().mean()*100:.3f} | inf%={np.isinf(col.to_numpy(float)).mean()*100:.3f}\")\n",
    "\n",
    "    arr = block.to_numpy(float)\n",
    "    assert np.isfinite(arr[~np.isnan(arr)]).all()\n",
    "\n",
    "# Year-level variation check\n",
    "if \"album_release_year\" in X_train_yr.columns and len(new_cols_year):\n",
    "    tmp = X_train_yr[[\"album_release_year\"] + list(new_cols_year)].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    display(tmp.groupby(\"album_release_year\")[new_cols_year].mean().head(10))\n",
    "\n",
    "display(X_train_yr[new_cols_year].head() if len(new_cols_year) else X_train_yr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b234208-9f4d-4b3b-83b4-d7db97dd2d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:40.101621Z",
     "iopub.status.busy": "2026-02-11T13:53:40.101469Z",
     "iopub.status.idle": "2026-02-11T13:53:40.107515Z",
     "shell.execute_reply": "2026-02-11T13:53:40.106928Z",
     "shell.execute_reply.started": "2026-02-11T13:53:40.101609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_popularity_mean</th>\n",
       "      <th>year_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_popularity_mean  year_trend\n",
       "train                0.0078      0.0141\n",
       "val                100.0000    100.0000\n",
       "test               100.0000    100.0000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_nan_rates(\n",
    "    {\"train\": X_train_yr, \n",
    "     \"val\": X_val_yr, \n",
    "     \"test\": X_test_yr},\n",
    "    new_cols_year,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dfdafd-57ec-429f-8d6b-a5e076bc9926",
   "metadata": {},
   "source": [
    "Result: `year_meta` features are not usable under the temporal split as implemented.\n",
    "Since validation (2020) and test (2021) contain years not seen during training (â‰¤2019), the year-to-statistic mapping is undefined and produces 100% missing values on val/test.\n",
    "Therefore, `year_meta` is excluded from the main ablation study unless an explicit fallback strategy is introduced.\n",
    "\n",
    "# 7. Ablation study (temporal split as decision split)\n",
    "\n",
    "We evaluate feature blocks incrementally on the **temporal split** (Train â‰¤ 2019, Val = 2020, Test = 2021).\n",
    "Each ablation is run with the same baseline models and the same metrics, including segment-aware MAE (`mae_zero`, `mae_pos`) to account for the strong zero-inflation shift in 2021.\n",
    "\n",
    "Note: `year_meta` is excluded from this ablation because it produces 100% missing values on 2020/2021 (unseen years under the temporal training window), unless an explicit fallback strategy is implemented in `src/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8b3d39-df2d-45e7-b3d6-18aea8479a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:53:40.107987Z",
     "iopub.status.busy": "2026-02-11T13:53:40.107849Z",
     "iopub.status.idle": "2026-02-11T13:55:53.291552Z",
     "shell.execute_reply": "2026-02-11T13:55:53.287095Z",
     "shell.execute_reply.started": "2026-02-11T13:53:40.107975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ablation</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temporal+audio</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>15.3749</td>\n",
       "      <td>14.4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear+market</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>15.3753</td>\n",
       "      <td>14.4946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>15.3752</td>\n",
       "      <td>14.4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>15.3931</td>\n",
       "      <td>14.5173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF_all</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>15.3934</td>\n",
       "      <td>14.5174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear</th>\n",
       "      <th>linear_regression</th>\n",
       "      <td>15.6282</td>\n",
       "      <td>15.2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear+market</th>\n",
       "      <th>linear_regression</th>\n",
       "      <td>15.9447</td>\n",
       "      <td>15.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio</th>\n",
       "      <th>linear_regression</th>\n",
       "      <td>15.6668</td>\n",
       "      <td>15.2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF_all</th>\n",
       "      <th>linear_regression</th>\n",
       "      <td>15.3305</td>\n",
       "      <td>15.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal</th>\n",
       "      <th>linear_regression</th>\n",
       "      <td>15.5648</td>\n",
       "      <td>15.3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF_all</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.8386</td>\n",
       "      <td>15.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.8386</td>\n",
       "      <td>15.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.8386</td>\n",
       "      <td>15.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.8386</td>\n",
       "      <td>15.4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temporal+audio+non_linear+market</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>15.8386</td>\n",
       "      <td>15.4538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subset                                                test     val\n",
       "ablation                         model                            \n",
       "temporal+audio                   random_forest     15.3749 14.4944\n",
       "temporal+audio+non_linear+market random_forest     15.3753 14.4946\n",
       "temporal+audio+non_linear        random_forest     15.3752 14.4947\n",
       "temporal                         random_forest     15.3931 14.5173\n",
       "OFF_all                          random_forest     15.3934 14.5174\n",
       "temporal+audio+non_linear        linear_regression 15.6282 15.2203\n",
       "temporal+audio+non_linear+market linear_regression 15.9447 15.2241\n",
       "temporal+audio                   linear_regression 15.6668 15.2595\n",
       "OFF_all                          linear_regression 15.3305 15.3300\n",
       "temporal                         linear_regression 15.5648 15.3770\n",
       "OFF_all                          constant_median   15.8386 15.4538\n",
       "temporal                         constant_median   15.8386 15.4538\n",
       "temporal+audio                   constant_median   15.8386 15.4538\n",
       "temporal+audio+non_linear        constant_median   15.8386 15.4538\n",
       "temporal+audio+non_linear+market constant_median   15.8386 15.4538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_pos</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_zero</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pct_zero_true</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pred_zero_pct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ablation</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">OFF_all</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>14.2203</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>-0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.1994</td>\n",
       "      <td>14.4319</td>\n",
       "      <td>18.9381</td>\n",
       "      <td>21.2540</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>13.9210</td>\n",
       "      <td>13.6694</td>\n",
       "      <td>20.0897</td>\n",
       "      <td>20.1104</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0223</td>\n",
       "      <td>0.1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">temporal</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>14.2203</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>-0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.1439</td>\n",
       "      <td>14.3246</td>\n",
       "      <td>20.0966</td>\n",
       "      <td>22.3182</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>13.9210</td>\n",
       "      <td>13.6694</td>\n",
       "      <td>20.0882</td>\n",
       "      <td>20.1100</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0222</td>\n",
       "      <td>0.1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">temporal+audio</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>14.2203</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>-0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.2006</td>\n",
       "      <td>14.2421</td>\n",
       "      <td>20.3428</td>\n",
       "      <td>21.9702</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>13.8907</td>\n",
       "      <td>13.6512</td>\n",
       "      <td>20.1086</td>\n",
       "      <td>20.0559</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">temporal+audio+non_linear</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>14.2203</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>-0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.1635</td>\n",
       "      <td>14.2092</td>\n",
       "      <td>20.2997</td>\n",
       "      <td>21.8897</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>0.0321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>13.8907</td>\n",
       "      <td>13.6514</td>\n",
       "      <td>20.1100</td>\n",
       "      <td>20.0564</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">temporal+audio+non_linear+market</th>\n",
       "      <th>constant_median</th>\n",
       "      <td>14.2203</td>\n",
       "      <td>14.6130</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>-0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_regression</th>\n",
       "      <td>14.3824</td>\n",
       "      <td>14.2093</td>\n",
       "      <td>20.9277</td>\n",
       "      <td>21.9177</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0523</td>\n",
       "      <td>0.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>13.8909</td>\n",
       "      <td>13.6514</td>\n",
       "      <td>20.1098</td>\n",
       "      <td>20.0560</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>0.1075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   mae_pos         mae_zero         pct_zero_true          \\\n",
       "subset                                                test     val     test     val          test     val   \n",
       "ablation                         model                                                                      \n",
       "OFF_all                          constant_median   14.2203 14.6130  21.0000 21.0000       23.8695 13.1651   \n",
       "                                 linear_regression 14.1994 14.4319  18.9381 21.2540       23.8695 13.1651   \n",
       "                                 random_forest     13.9210 13.6694  20.0897 20.1104       23.8695 13.1651   \n",
       "temporal                         constant_median   14.2203 14.6130  21.0000 21.0000       23.8695 13.1651   \n",
       "                                 linear_regression 14.1439 14.3246  20.0966 22.3182       23.8695 13.1651   \n",
       "                                 random_forest     13.9210 13.6694  20.0882 20.1100       23.8695 13.1651   \n",
       "temporal+audio                   constant_median   14.2203 14.6130  21.0000 21.0000       23.8695 13.1651   \n",
       "                                 linear_regression 14.2006 14.2421  20.3428 21.9702       23.8695 13.1651   \n",
       "                                 random_forest     13.8907 13.6512  20.1086 20.0559       23.8695 13.1651   \n",
       "temporal+audio+non_linear        constant_median   14.2203 14.6130  21.0000 21.0000       23.8695 13.1651   \n",
       "                                 linear_regression 14.1635 14.2092  20.2997 21.8897       23.8695 13.1651   \n",
       "                                 random_forest     13.8907 13.6514  20.1100 20.0564       23.8695 13.1651   \n",
       "temporal+audio+non_linear+market constant_median   14.2203 14.6130  21.0000 21.0000       23.8695 13.1651   \n",
       "                                 linear_regression 14.3824 14.2093  20.9277 21.9177       23.8695 13.1651   \n",
       "                                 random_forest     13.8909 13.6514  20.1098 20.0560       23.8695 13.1651   \n",
       "\n",
       "                                                   pred_zero_pct             r2          \n",
       "subset                                                      test    val    test     val  \n",
       "ablation                         model                                                   \n",
       "OFF_all                          constant_median          0.0000 0.0000 -0.0135 -0.0130  \n",
       "                                 linear_regression        0.0000 0.0000  0.0102 -0.0004  \n",
       "                                 random_forest            0.0000 0.0000 -0.0223  0.1048  \n",
       "temporal                         constant_median          0.0000 0.0000 -0.0135 -0.0130  \n",
       "                                 linear_regression        0.0000 0.0000 -0.0046  0.0107  \n",
       "                                 random_forest            0.0000 0.0000 -0.0222  0.1048  \n",
       "temporal+audio                   constant_median          0.0000 0.0000 -0.0135 -0.0130  \n",
       "                                 linear_regression        0.0000 0.0000 -0.0140  0.0283  \n",
       "                                 random_forest            0.0000 0.0000 -0.0120  0.1075  \n",
       "temporal+audio+non_linear        constant_median          0.0000 0.0000 -0.0135 -0.0130  \n",
       "                                 linear_regression        0.0000 0.0000 -0.0121  0.0321  \n",
       "                                 random_forest            0.0000 0.0000 -0.0120  0.1075  \n",
       "temporal+audio+non_linear+market constant_median          0.0000 0.0000 -0.0135 -0.0130  \n",
       "                                 linear_regression        0.0000 0.0000 -0.0523  0.0325  \n",
       "                                 random_forest            0.0000 0.0000 -0.0120  0.1075  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Ablation configs ---\n",
    "ablations = [\n",
    "    (\"OFF_all\", FeatureEngineeringConfig(\n",
    "        temporal=False, audio_interactions=False, non_linear=False, market=False, year_meta=False\n",
    "    )),\n",
    "    (\"temporal\", FeatureEngineeringConfig(\n",
    "        temporal=True, audio_interactions=False, non_linear=False, market=False, year_meta=False, current_year=2021\n",
    "    )),\n",
    "    (\"temporal+audio\", FeatureEngineeringConfig(\n",
    "        temporal=True, audio_interactions=True, non_linear=False, market=False, year_meta=False, current_year=2021\n",
    "    )),\n",
    "    (\"temporal+audio+non_linear\", FeatureEngineeringConfig(\n",
    "        temporal=True, audio_interactions=True, non_linear=True, market=False, year_meta=False, current_year=2021\n",
    "    )),\n",
    "    (\"temporal+audio+non_linear+market\", FeatureEngineeringConfig(\n",
    "        temporal=True, audio_interactions=True, non_linear=True, market=True, year_meta=False, current_year=2021\n",
    "    )),\n",
    "]\n",
    "\n",
    "results_ablation = []\n",
    "\n",
    "for tag, cfg in ablations:\n",
    "    pipe = build_feature_pipeline(cfg)\n",
    "\n",
    "    X_train_fe = apply_feature_engineering(X_train_t, pipe, fit=True,  y=y_train_t)\n",
    "    X_val_fe   = apply_feature_engineering(X_val_t,   pipe, fit=False)\n",
    "    X_test_fe  = apply_feature_engineering(X_test_t,  pipe, fit=False)\n",
    "\n",
    "    splits = {\n",
    "        \"temporal\": (X_train_fe, X_val_fe, X_test_fe, y_train_t, y_val_t, y_test_t)\n",
    "    }\n",
    "\n",
    "    for model_name, model in baseline_models.items():\n",
    "        df_res = evaluate_model_on_splits(\n",
    "            model,\n",
    "            model_name=model_name,\n",
    "            splits=splits,\n",
    "        )\n",
    "        df_res[\"ablation\"] = tag\n",
    "        results_ablation.append(df_res)\n",
    "\n",
    "results_ablation = pd.concat(results_ablation, ignore_index=True)\n",
    "\n",
    "# --- Summaries ---\n",
    "summary_mae = (\n",
    "    results_ablation.query(\"subset in ['val','test']\")\n",
    "    .pivot_table(index=[\"ablation\", \"model\"], columns=\"subset\", values=\"mae\", aggfunc=\"first\")\n",
    "    .sort_values((\"val\"), ascending=True)\n",
    ")\n",
    "display(summary_mae.round(5))\n",
    "\n",
    "summary_segments = (\n",
    "    results_ablation.query(\"subset in ['val','test']\")\n",
    "    .pivot_table(\n",
    "        index=[\"ablation\", \"model\"],\n",
    "        columns=\"subset\",\n",
    "        values=[\"r2\", \"mae_zero\", \"mae_pos\", \"pct_zero_true\", \"pred_zero_pct\"],\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    ")\n",
    "display(summary_segments.round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f80bb7-d02f-4131-b78a-51baa879cd77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T00:15:11.710314Z",
     "iopub.status.busy": "2026-02-05T00:15:11.709719Z",
     "iopub.status.idle": "2026-02-05T00:15:11.757276Z",
     "shell.execute_reply": "2026-02-05T00:15:11.748847Z",
     "shell.execute_reply.started": "2026-02-05T00:15:11.710276Z"
    }
   },
   "source": [
    "Ablation results (temporal split) show that feature engineering yields only marginal gains for the Random Forest baseline.\n",
    "The main improvement comes from the audio interaction block (val MAE ~14.517 â†’ ~14.494; test MAE ~15.393 â†’ ~15.375).\n",
    "Adding non-linear transforms and market features has negligible additional impact on RF.\n",
    "\n",
    "Segmented metrics indicate the 2021 test error is dominated by the zero-popularity regime: `pct_zero` increases to ~23.9% in 2021, while `mae_zero` remains ~20 across all ablations. This suggests the primary limitation is a regime shift (zero-inflation and temporal drift), not the lack of simple interaction features.\n",
    "\n",
    "We also report RÂ² for context only. Decisions remain driven by MAE/RMSE and segmented MAE, since the target is bounded and exhibits a non-trivial zero mass.\n",
    "\n",
    "# 8. Hurdle baseline (two-stage modeling for zero-inflation)\n",
    "\n",
    "Motivation: the temporal ablation indicates that 2021 performance is dominated by the zero-popularity regime\n",
    "(`pct_zero` increases sharply and `mae_zero` remains high across ablations). A two-stage (hurdle) approach\n",
    "explicitly models this regime shift:\n",
    "\n",
    "1) Stage A (classifier): predict whether popularity is zero (`y == 0`)\n",
    "2) Stage B (regressor): predict popularity conditional on `y > 0`\n",
    "\n",
    "This section evaluates whether separating the regimes reduces overall MAE and improves `mae_zero` / `mae_pos`\n",
    "under the temporal split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e647b7f-6fb8-42ef-8646-a4a8f7fff7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:55:53.294260Z",
     "iopub.status.busy": "2026-02-11T13:55:53.293658Z",
     "iopub.status.idle": "2026-02-11T13:57:21.816923Z",
     "shell.execute_reply": "2026-02-11T13:57:21.815571Z",
     "shell.execute_reply.started": "2026-02-11T13:55:53.294206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>subset</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pct_zero</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "      <th>pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurdle_logreg+rf</td>\n",
       "      <td>train</td>\n",
       "      <td>10.4859</td>\n",
       "      <td>13.4931</td>\n",
       "      <td>11.6146</td>\n",
       "      <td>23.6587</td>\n",
       "      <td>8.7549</td>\n",
       "      <td>0.0254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hurdle_logreg+rf</td>\n",
       "      <td>val</td>\n",
       "      <td>15.0192</td>\n",
       "      <td>17.9176</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>24.8941</td>\n",
       "      <td>13.5220</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hurdle_logreg+rf</td>\n",
       "      <td>test</td>\n",
       "      <td>16.1076</td>\n",
       "      <td>19.2769</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>23.4648</td>\n",
       "      <td>13.8008</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model subset     mae    rmse  pct_zero  mae_zero  mae_pos  pred_zero_pct\n",
       "0  hurdle_logreg+rf  train 10.4859 13.4931   11.6146   23.6587   8.7549         0.0254\n",
       "1  hurdle_logreg+rf    val 15.0192 17.9176   13.1651   24.8941  13.5220         0.0142\n",
       "2  hurdle_logreg+rf   test 16.1076 19.2769   23.8695   23.4648  13.8008         0.0059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fe_config_best = FeatureEngineeringConfig(\n",
    "    temporal=True,\n",
    "    audio_interactions=True,\n",
    "    non_linear=False,\n",
    "    market=False,\n",
    "    year_meta=False,\n",
    "    current_year=2021,\n",
    ")\n",
    "\n",
    "pipe_best = build_feature_pipeline(fe_config_best)\n",
    "\n",
    "X_train_fe = apply_feature_engineering(X_train_t, pipe_best, fit=True, y=y_train_t)\n",
    "X_val_fe   = apply_feature_engineering(X_val_t,   pipe_best, fit=False)\n",
    "X_test_fe  = apply_feature_engineering(X_test_t,  pipe_best, fit=False)\n",
    "\n",
    "# ============================================================\n",
    "# Hurdle evaluation (train/val/test) using only definitive functions\n",
    "# ============================================================\n",
    "\n",
    "# 1) Numeric-only imputation\n",
    "X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(\n",
    "    X_train_fe, X_val_fe, X_test_fe\n",
    ")\n",
    "\n",
    "# 2) Recency weights\n",
    "train_year = pd.to_numeric(X_train_fe[\"album_release_year\"], errors=\"coerce\")\n",
    "w = make_recency_weights(train_year, ref_year=2021, lam=0.05)\n",
    "\n",
    "# 3) Arrays\n",
    "y_train_arr = y_train_t.to_numpy(float)\n",
    "y_val_arr   = y_val_t.to_numpy(float)\n",
    "y_test_arr  = y_test_t.to_numpy(float)\n",
    "\n",
    "# 4) Models (solver adjusted to avoid convergence warnings)\n",
    "clf = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    solver=\"liblinear\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "reg = RandomForestRegressor(\n",
    "    n_estimators=80,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "# 5) Fit classifier and regressor\n",
    "y_is_zero = (y_train_arr == 0).astype(int)\n",
    "clf.fit(X_train_i, y_is_zero, sample_weight=w)\n",
    "\n",
    "mask_pos = (y_train_arr > 0)\n",
    "reg.fit(X_train_i[mask_pos], y_train_arr[mask_pos], sample_weight=w[mask_pos])\n",
    "\n",
    "# 6) Hurdle predictions\n",
    "y_pred_train = hurdle_predict(clf=clf, reg=reg, X_i=X_train_i, threshold=0.5)\n",
    "y_pred_val   = hurdle_predict(clf=clf, reg=reg, X_i=X_val_i,   threshold=0.5)\n",
    "y_pred_test  = hurdle_predict(clf=clf, reg=reg, X_i=X_test_i,  threshold=0.5)\n",
    "\n",
    "# 7) Old-style output format (train / val / test tidy)\n",
    "rows = []\n",
    "for subset, y_true, y_pred in [\n",
    "    (\"train\", y_train_arr, y_pred_train),\n",
    "    (\"val\",   y_val_arr,   y_pred_val),\n",
    "    (\"test\",  y_test_arr,  y_pred_test),\n",
    "]:\n",
    "    m = full_metrics(y_true, y_pred)\n",
    "    rows.append({\n",
    "        \"model\": \"hurdle_logreg+rf\",\n",
    "        \"subset\": subset,\n",
    "        \"mae\": m[\"mae\"],\n",
    "        \"rmse\": m[\"rmse\"],\n",
    "        \"pct_zero\": m[\"pct_zero_true\"],\n",
    "        \"mae_zero\": m[\"mae_zero\"],\n",
    "        \"mae_pos\": m[\"mae_pos\"],\n",
    "        \"pred_zero_pct\": m[\"pred_zero_pct\"],\n",
    "    })\n",
    "\n",
    "results_hurdle = pd.DataFrame(rows)\n",
    "display(results_hurdle.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cabfc3ac-990b-427d-a2e8-47bb3a8f36e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:57:21.817692Z",
     "iopub.status.busy": "2026-02-11T13:57:21.817534Z",
     "iopub.status.idle": "2026-02-11T13:58:47.659733Z",
     "shell.execute_reply": "2026-02-11T13:58:47.658796Z",
     "shell.execute_reply.started": "2026-02-11T13:57:21.817679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mae_zero</th>\n",
       "      <th>val_mae_pos</th>\n",
       "      <th>val_pred_zero_pct</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_mae_zero</th>\n",
       "      <th>test_mae_pos</th>\n",
       "      <th>test_pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>22.6877</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>26.1255</td>\n",
       "      <td>97.7463</td>\n",
       "      <td>18.6656</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>24.4500</td>\n",
       "      <td>98.6489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>22.6244</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>26.0480</td>\n",
       "      <td>97.3003</td>\n",
       "      <td>20.4909</td>\n",
       "      <td>5.0293</td>\n",
       "      <td>25.3387</td>\n",
       "      <td>90.1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>22.4036</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>25.7415</td>\n",
       "      <td>93.9473</td>\n",
       "      <td>20.9118</td>\n",
       "      <td>7.5592</td>\n",
       "      <td>25.0983</td>\n",
       "      <td>81.1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>15.1945</td>\n",
       "      <td>23.8440</td>\n",
       "      <td>13.8832</td>\n",
       "      <td>3.6106</td>\n",
       "      <td>15.9965</td>\n",
       "      <td>22.2012</td>\n",
       "      <td>14.0511</td>\n",
       "      <td>3.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>15.0184</td>\n",
       "      <td>24.8681</td>\n",
       "      <td>13.5251</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>16.0972</td>\n",
       "      <td>23.3937</td>\n",
       "      <td>13.8095</td>\n",
       "      <td>0.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>15.0171</td>\n",
       "      <td>24.8763</td>\n",
       "      <td>13.5223</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>16.1055</td>\n",
       "      <td>23.4531</td>\n",
       "      <td>13.8018</td>\n",
       "      <td>0.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>15.0192</td>\n",
       "      <td>24.8941</td>\n",
       "      <td>13.5221</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>16.1054</td>\n",
       "      <td>23.4584</td>\n",
       "      <td>13.7999</td>\n",
       "      <td>0.0197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  val_mae  val_mae_zero  val_mae_pos  val_pred_zero_pct  test_mae  test_mae_zero  test_mae_pos  \\\n",
       "0     0.0200  22.6877        0.0132      26.1255            97.7463   18.6656         0.2167       24.4500   \n",
       "1     0.0500  22.6244        0.0433      26.0480            97.3003   20.4909         5.0293       25.3387   \n",
       "2     0.1000  22.4036        0.3879      25.7415            93.9473   20.9118         7.5592       25.0983   \n",
       "3     0.1500  15.1945       23.8440      13.8832             3.6106   15.9965        22.2012       14.0511   \n",
       "4     0.2000  15.0184       24.8681      13.5251             0.0767   16.0972        23.3937       13.8095   \n",
       "5     0.2500  15.0171       24.8763      13.5223             0.0436   16.1055        23.4531       13.8018   \n",
       "6     0.3000  15.0192       24.8941      13.5221             0.0218   16.1054        23.4584       13.7999   \n",
       "\n",
       "   test_pred_zero_pct  \n",
       "0             98.6489  \n",
       "1             90.1245  \n",
       "2             81.1569  \n",
       "3              3.8781  \n",
       "4              0.1733  \n",
       "5              0.0374  \n",
       "6              0.0197  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Numeric-only imputation\n",
    "X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(\n",
    "    X_train_fe, X_val_fe, X_test_fe\n",
    ")\n",
    "\n",
    "# 2) Recency weights\n",
    "train_year = pd.to_numeric(X_train_fe[\"album_release_year\"], errors=\"coerce\")\n",
    "w = make_recency_weights(train_year, ref_year=2021, lam=0.05)\n",
    "\n",
    "# 3) Arrays\n",
    "y_train_arr = y_train_t.to_numpy(float)\n",
    "y_val_arr   = y_val_t.to_numpy(float)\n",
    "y_test_arr  = y_test_t.to_numpy(float)\n",
    "\n",
    "# 4) Models (allowed in the definitive hurdle module)\n",
    "clf = LogisticRegression(\n",
    "    max_iter=5000,\n",
    "    solver=\"liblinear\",\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "reg = RandomForestRegressor(\n",
    "    n_estimators=80,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "# 5) Fit classifier and regressor\n",
    "y_is_zero = (y_train_arr == 0).astype(int)\n",
    "clf.fit(X_train_i, y_is_zero, sample_weight=w)\n",
    "\n",
    "mask_pos = (y_train_arr > 0)\n",
    "reg.fit(X_train_i[mask_pos], y_train_arr[mask_pos], sample_weight=w[mask_pos])\n",
    "\n",
    "# 6) Threshold sweep\n",
    "thresholds = [0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "rows = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    # Predictions\n",
    "    y_pred_val  = hurdle_predict(clf=clf, reg=reg, X_i=X_val_i,  threshold=thr)\n",
    "    y_pred_test = hurdle_predict(clf=clf, reg=reg, X_i=X_test_i, threshold=thr)\n",
    "\n",
    "    # Metrics (using full_metrics only)\n",
    "    m_val  = full_metrics(y_val_arr,  y_pred_val)\n",
    "    m_test = full_metrics(y_test_arr, y_pred_test)\n",
    "\n",
    "    rows.append({\n",
    "        \"threshold\": thr,\n",
    "        \"val_mae\": m_val[\"mae\"],\n",
    "        \"val_mae_zero\": m_val[\"mae_zero\"],\n",
    "        \"val_mae_pos\": m_val[\"mae_pos\"],\n",
    "        \"val_pred_zero_pct\": m_val[\"pred_zero_pct\"],\n",
    "        \"test_mae\": m_test[\"mae\"],\n",
    "        \"test_mae_zero\": m_test[\"mae_zero\"],\n",
    "        \"test_mae_pos\": m_test[\"mae_pos\"],\n",
    "        \"test_pred_zero_pct\": m_test[\"pred_zero_pct\"],\n",
    "    })\n",
    "\n",
    "threshold_sweep = pd.DataFrame(rows)\n",
    "display(threshold_sweep.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ebcee-5914-4ab7-beba-e477a6d32001",
   "metadata": {},
   "source": [
    "**Threshold tuning confirms the characteristic behavior of hurdle models.**  \n",
    "Lower thresholds force the classifier to predict almost all cases as zero, which drives `mae_zero` close to zero but severely inflates `mae_pos` by incorrectly zeroing many positive observations. As the threshold increases, the classifier effectively stops predicting zeros; the hurdle collapses into a pure regressor, improving `mae_pos` but causing `mae_zero` to deteriorate sharply.\n",
    "\n",
    "Across all tested thresholds, this tradeâ€‘off remains unfavorable.  \n",
    "**No threshold configuration yields an improvement over the singleâ€‘stage Random Forest baseline under the temporal split**, either in overall MAE or in the positiveâ€‘case error (`mae_pos`), which is the metric of primary interest.\n",
    "\n",
    "Given the strong threshold-sensitive trade-off (global MAE vs. zero handling) and the risk of hurdle collapse (`pred_zero_pct â†’ 0%` at high thresholds), the hurdle architecture is treated as a diagnostic. We benchmark it in Section 10 against simpler regression baselines to determine whether the added moving parts (classifier + threshold rule) are justified.\n",
    "\n",
    "# 9. Recency weighting (temporal split)\n",
    "\n",
    "The temporal split suggests a distribution shift between past releases (â‰¤ 2019) and newer tracks (2020â€“2021).  \n",
    "As a lightweight diagnostic (without changing features or the split protocol), we test **recency weighting** on the **temporal training set only**.\n",
    "\n",
    "Idea: give higher importance to more recent training examples (closer to 2019/2020) by using an exponential decay weight based on the gap to a fixed reference year (2021).  \n",
    "We then evaluate on 2020 (validation) and 2021 (test) using the same metrics as the baseline.\n",
    "\n",
    "**Goal:** check whether simple weighting helps temporal generalization, without introducing heavier modeling or feature changes.\n",
    "\n",
    "## 9.1 - Random Forest with `sample_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5fca60d-4658-4e40-a78d-f13a2a7ed3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T13:58:47.660699Z",
     "iopub.status.busy": "2026-02-11T13:58:47.660535Z",
     "iopub.status.idle": "2026-02-11T14:00:34.388598Z",
     "shell.execute_reply": "2026-02-11T14:00:34.361201Z",
     "shell.execute_reply.started": "2026-02-11T13:58:47.660685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>subset</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "      <th>pct_zero_true</th>\n",
       "      <th>pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf_weighted</td>\n",
       "      <td>val</td>\n",
       "      <td>14.3096</td>\n",
       "      <td>17.4234</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>20.0636</td>\n",
       "      <td>13.4372</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_weighted</td>\n",
       "      <td>test</td>\n",
       "      <td>15.4822</td>\n",
       "      <td>18.8010</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>20.6896</td>\n",
       "      <td>13.8496</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model subset     mae    rmse      r2  mae_zero  mae_pos  pct_zero_true  pred_zero_pct\n",
       "0  rf_weighted    val 14.3096 17.4234  0.1271   20.0636  13.4372        13.1651         0.0047\n",
       "1  rf_weighted   test 15.4822 18.8010 -0.0491   20.6896  13.8496        23.8695         0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Numeric-only imputation (required before any model)\n",
    "X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(\n",
    "    X_train_t, X_val_t, X_test_t\n",
    ")\n",
    "\n",
    "# 2) Recency weights (official function)\n",
    "train_year = pd.to_numeric(X_train_t[\"album_release_year\"], errors=\"coerce\")\n",
    "w_train = make_recency_weights(\n",
    "    train_year,\n",
    "    ref_year=2021,\n",
    "    lam=0.15,     # same lambda as your original example\n",
    ")\n",
    "\n",
    "# 3) Arrays\n",
    "y_train_arr = y_train_t.to_numpy(float)\n",
    "y_val_arr   = y_val_t.to_numpy(float)\n",
    "y_test_arr  = y_test_t.to_numpy(float)\n",
    "\n",
    "# 4) Weighted Random Forest (allowed model)\n",
    "rf_weighted = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 5) Fit with sample weights\n",
    "rf_weighted.fit(X_train_i, y_train_arr, sample_weight=w_train)\n",
    "\n",
    "# 6) Predict\n",
    "pred_val  = rf_weighted.predict(X_val_i)\n",
    "pred_test = rf_weighted.predict(X_test_i)\n",
    "\n",
    "# 7) Metrics (official function: full_metrics)\n",
    "m_val  = full_metrics(y_val_arr,  pred_val)\n",
    "m_test = full_metrics(y_test_arr, pred_test)\n",
    "\n",
    "# 8) Output in tidy format\n",
    "results_rf_weighted = pd.DataFrame([\n",
    "    {\"model\": \"rf_weighted\", \"subset\": \"val\",  **m_val},\n",
    "    {\"model\": \"rf_weighted\", \"subset\": \"test\", **m_test},\n",
    "])\n",
    "\n",
    "display(results_rf_weighted.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e5c03-6e08-4434-be7b-d34512be46f7",
   "metadata": {},
   "source": [
    "We fit a Random Forest Regressor on the temporal training set using `sample_weight`, where each training example receives a larger weight if it is closer to the reference year (2021).\n",
    "We report MAE/RMSE/RÂ² and the segmented MAE (`mae_zero`, `mae_pos`) on validation (2020) and test (2021).\n",
    "\n",
    "## 9.2 - Linear Regression with `sample_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea5fdcab-8d2d-4957-addf-22317f828055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:00:34.454788Z",
     "iopub.status.busy": "2026-02-11T14:00:34.447273Z",
     "iopub.status.idle": "2026-02-11T14:00:37.213119Z",
     "shell.execute_reply": "2026-02-11T14:00:37.211975Z",
     "shell.execute_reply.started": "2026-02-11T14:00:34.454712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>subset</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "      <th>pct_zero_true</th>\n",
       "      <th>pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_weighted</td>\n",
       "      <td>val</td>\n",
       "      <td>15.3059</td>\n",
       "      <td>18.4298</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>22.4109</td>\n",
       "      <td>14.2287</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_weighted</td>\n",
       "      <td>test</td>\n",
       "      <td>15.8439</td>\n",
       "      <td>18.6320</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>21.2450</td>\n",
       "      <td>14.1505</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model subset     mae    rmse      r2  mae_zero  mae_pos  pct_zero_true  pred_zero_pct\n",
       "0  lr_weighted    val 15.3059 18.4298  0.0234   22.4109  14.2287        13.1651         0.0000\n",
       "1  lr_weighted   test 15.8439 18.6320 -0.0304   21.2450  14.1505        23.8695         0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Numeric-only imputation\n",
    "X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(\n",
    "    X_train_t, X_val_t, X_test_t\n",
    ")\n",
    "\n",
    "# 2) Recency weights (official function)\n",
    "train_year = pd.to_numeric(X_train_t[\"album_release_year\"], errors=\"coerce\")\n",
    "w_train = make_recency_weights(\n",
    "    train_year,\n",
    "    ref_year=2021,\n",
    "    lam=0.15,   # same lambda as your original example\n",
    ")\n",
    "\n",
    "# 3) Arrays\n",
    "y_train_arr = y_train_t.to_numpy(float)\n",
    "y_val_arr   = y_val_t.to_numpy(float)\n",
    "y_test_arr  = y_test_t.to_numpy(float)\n",
    "\n",
    "# 4) Weighted Linear Regression (allowed model)\n",
    "lr_weighted = LinearRegression()\n",
    "\n",
    "# 5) Fit with sample weights\n",
    "lr_weighted.fit(X_train_i, y_train_arr, sample_weight=w_train)\n",
    "\n",
    "# 6) Predict\n",
    "pred_val  = lr_weighted.predict(X_val_i)\n",
    "pred_test = lr_weighted.predict(X_test_i)\n",
    "\n",
    "# 7) Metrics (official function: full_metrics)\n",
    "m_val  = full_metrics(y_val_arr,  pred_val)\n",
    "m_test = full_metrics(y_test_arr, pred_test)\n",
    "\n",
    "# 8) Output in tidy format\n",
    "results_lr_weighted = pd.DataFrame([\n",
    "    {\"model\": \"lr_weighted\", \"subset\": \"val\",  **m_val},\n",
    "    {\"model\": \"lr_weighted\", \"subset\": \"test\", **m_test},\n",
    "])\n",
    "\n",
    "display(results_lr_weighted.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc8965-43e3-4594-abb6-5905272bb359",
   "metadata": {},
   "source": [
    "We repeat the same experiment with Linear Regression.\n",
    "This provides a linear reference for whether recency weighting consistently helps, or whether the effect depends on model capacity.\n",
    "\n",
    "## 9.3 - Recency-weight micro-sweep (temporal split)\n",
    "\n",
    "To avoid over-interpreting a single `lambda`, we run a small sweep:\n",
    "\n",
    "* `lambda âˆˆ {0.005, 0.01, 0.05, 0.10, 0.15, 0.20}`\n",
    "* exponential-like decay weights computed on the temporal training set only\n",
    "* evaluation on 2020 (val) and 2021 (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd6214d4-4efa-4273-9085-561f74f4bd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:00:37.215454Z",
     "iopub.status.busy": "2026-02-11T14:00:37.214922Z",
     "iopub.status.idle": "2026-02-11T14:03:42.298151Z",
     "shell.execute_reply": "2026-02-11T14:03:42.291394Z",
     "shell.execute_reply.started": "2026-02-11T14:00:37.215428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_pos</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_zero</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pct_zero_true</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pred_zero_pct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0050</th>\n",
       "      <td>15.4909</td>\n",
       "      <td>14.3770</td>\n",
       "      <td>13.9235</td>\n",
       "      <td>13.5320</td>\n",
       "      <td>20.4904</td>\n",
       "      <td>19.9498</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>18.7714</td>\n",
       "      <td>17.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>15.4893</td>\n",
       "      <td>14.3727</td>\n",
       "      <td>13.9228</td>\n",
       "      <td>13.5293</td>\n",
       "      <td>20.4857</td>\n",
       "      <td>19.9354</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>18.7810</td>\n",
       "      <td>17.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0500</th>\n",
       "      <td>15.4578</td>\n",
       "      <td>14.3538</td>\n",
       "      <td>13.9018</td>\n",
       "      <td>13.5154</td>\n",
       "      <td>20.4207</td>\n",
       "      <td>19.8831</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>18.7531</td>\n",
       "      <td>17.4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>15.4850</td>\n",
       "      <td>14.3462</td>\n",
       "      <td>13.9089</td>\n",
       "      <td>13.5133</td>\n",
       "      <td>20.5119</td>\n",
       "      <td>19.8400</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>18.8123</td>\n",
       "      <td>17.4597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1500</th>\n",
       "      <td>15.4779</td>\n",
       "      <td>14.3380</td>\n",
       "      <td>13.8994</td>\n",
       "      <td>13.5094</td>\n",
       "      <td>20.5128</td>\n",
       "      <td>19.8033</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>18.8065</td>\n",
       "      <td>17.4626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2000</th>\n",
       "      <td>15.4990</td>\n",
       "      <td>14.3310</td>\n",
       "      <td>13.9181</td>\n",
       "      <td>13.5106</td>\n",
       "      <td>20.5411</td>\n",
       "      <td>19.7420</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>18.8364</td>\n",
       "      <td>17.4555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mae         mae_pos         mae_zero         pct_zero_true         pred_zero_pct           rmse        \n",
       "subset    test     val    test     val     test     val          test     val          test    val    test     val\n",
       "lambda                                                                                                            \n",
       "0.0050 15.4909 14.3770 13.9235 13.5320  20.4904 19.9498       23.8695 13.1651        0.0059 0.0057 18.7714 17.4827\n",
       "0.0100 15.4893 14.3727 13.9228 13.5293  20.4857 19.9354       23.8695 13.1651        0.0118 0.0095 18.7810 17.4789\n",
       "0.0500 15.4578 14.3538 13.9018 13.5154  20.4207 19.8831       23.8695 13.1651        0.0276 0.0170 18.7531 17.4663\n",
       "0.1000 15.4850 14.3462 13.9089 13.5133  20.5119 19.8400       23.8695 13.1651        0.0118 0.0133 18.8123 17.4597\n",
       "0.1500 15.4779 14.3380 13.8994 13.5094  20.5128 19.8033       23.8695 13.1651        0.0158 0.0161 18.8065 17.4626\n",
       "0.2000 15.4990 14.3310 13.9181 13.5106  20.5411 19.7420       23.8695 13.1651        0.0079 0.0085 18.8364 17.4555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>15.4578</td>\n",
       "      <td>18.7531</td>\n",
       "      <td>-0.0438</td>\n",
       "      <td>20.4207</td>\n",
       "      <td>13.9018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1500</td>\n",
       "      <td>15.4779</td>\n",
       "      <td>18.8065</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>20.5128</td>\n",
       "      <td>13.8994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>15.4850</td>\n",
       "      <td>18.8123</td>\n",
       "      <td>-0.0504</td>\n",
       "      <td>20.5119</td>\n",
       "      <td>13.9089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>15.4893</td>\n",
       "      <td>18.7810</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>20.4857</td>\n",
       "      <td>13.9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>15.4909</td>\n",
       "      <td>18.7714</td>\n",
       "      <td>-0.0458</td>\n",
       "      <td>20.4904</td>\n",
       "      <td>13.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>15.4990</td>\n",
       "      <td>18.8364</td>\n",
       "      <td>-0.0531</td>\n",
       "      <td>20.5411</td>\n",
       "      <td>13.9181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda     mae    rmse      r2  mae_zero  mae_pos\n",
       "0  0.0500 15.4578 18.7531 -0.0438   20.4207  13.9018\n",
       "1  0.1500 15.4779 18.8065 -0.0498   20.5128  13.8994\n",
       "2  0.1000 15.4850 18.8123 -0.0504   20.5119  13.9089\n",
       "3  0.0100 15.4893 18.7810 -0.0469   20.4857  13.9228\n",
       "4  0.0050 15.4909 18.7714 -0.0458   20.4904  13.9235\n",
       "5  0.2000 15.4990 18.8364 -0.0531   20.5411  13.9181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Recency-weighted RF: lambda sweep (optimized & safe)\n",
    "# ============================================================\n",
    "\n",
    "# 1) Numeric-only imputation\n",
    "X_train_i, X_val_i, X_test_i, _, _ = _numeric_impute_fit_transform(\n",
    "    X_train_t, X_val_t, X_test_t\n",
    ")\n",
    "\n",
    "# 2) Arrays\n",
    "y_train_arr = y_train_t.to_numpy(float)\n",
    "y_val_arr   = y_val_t.to_numpy(float)\n",
    "y_test_arr  = y_test_t.to_numpy(float)\n",
    "\n",
    "# 3) Lambda sweep\n",
    "LAMBDAS = [0.005, 0.01, 0.05, 0.10, 0.15, 0.20]\n",
    "rows = []\n",
    "\n",
    "for lam in LAMBDAS:\n",
    "    # Recency weights\n",
    "    train_year = pd.to_numeric(X_train_t[\"album_release_year\"], errors=\"coerce\")\n",
    "    w_train = make_recency_weights(train_year, ref_year=2021, lam=lam)\n",
    "\n",
    "    # Lighter RF to avoid kernel restart\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=60,\n",
    "        max_depth=16,\n",
    "        random_state=42,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train_i, y_train_arr, sample_weight=w_train)\n",
    "\n",
    "    # Evaluate\n",
    "    for subset_name, X_i, y_arr in [\n",
    "        (\"val\",  X_val_i,  y_val_arr),\n",
    "        (\"test\", X_test_i, y_test_arr),\n",
    "    ]:\n",
    "        pred = rf.predict(X_i)\n",
    "        m = full_metrics(y_arr, pred)\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": \"rf_weighted\",\n",
    "            \"lambda\": lam,\n",
    "            \"subset\": subset_name,\n",
    "            **m,\n",
    "        })\n",
    "\n",
    "    # Free memory aggressively\n",
    "    del rf\n",
    "    gc.collect()\n",
    "\n",
    "results_lambda = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "pivot_lambda = results_lambda.pivot_table(\n",
    "    index=\"lambda\",\n",
    "    columns=\"subset\",\n",
    "    values=[\"mae\", \"rmse\", \"mae_zero\", \"mae_pos\", \"pct_zero_true\", \"pred_zero_pct\"],\n",
    "    aggfunc=\"first\",\n",
    ").round(4)\n",
    "\n",
    "display(pivot_lambda)\n",
    "\n",
    "rank = (\n",
    "    results_lambda[results_lambda[\"subset\"] == \"test\"]\n",
    "    .sort_values([\"mae\", \"mae_pos\"], ascending=[True, True])\n",
    "    .loc[:, [\"lambda\", \"mae\", \"rmse\", \"r2\", \"mae_zero\", \"mae_pos\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e4496-d41b-4edc-bfe2-6c3b71314170",
   "metadata": {},
   "source": [
    "**Observed pattern:** We evaluated exponential-like sample weighting with `lambda âˆˆ {0.005, 0.01, 0.05, 0.10, 0.15, 0.20}` using the temporal split (Train â‰¤ 2019, Val = 2020, Test = 2021). Increasing lambda yields small validation gains in 2020, but the best 2021 test performance remains in the conservative range (here, lambda = 0.05), reinforcing that stronger recency emphasis does not generalize across the 2021 regime shift. This suggests that aggressive recency weighting overfits to the 2020 distribution and fails to adapt to the structural changes observed in 2021 (notably higher zero inflation)\n",
    "\n",
    "\n",
    "**Decision:** After extending the microâ€‘sweep to smaller values (`lambda = 0.005` and `0.01`), we observed that although larger lambda continues to yield small validation gains in 2020, the best 2021 test performance consistently remains in the conservative range (here, `lambda = 0.05`). We therefore keep `lambda = 0.05` as the default for subsequent hurdle experiments, treating recency weighting as a diagnostic tool rather than a default â€œupgradeâ€ given its limited generalization across the 2021 regime shift.\n",
    "\n",
    "\n",
    "# 10. Hurdle model (temporal split)\n",
    "\n",
    "The temporal split reveals a strong regime shift in 2021, with a much higher share of zero-popularity tracks. A single regressor struggles because it must simultaneously:\n",
    "\n",
    "1. decide whether the target is zero, and\n",
    "2. predict the magnitude when the target is positive.\n",
    "\n",
    "To address this with minimal additional complexity, we use a **hurdle** approach:\n",
    "\n",
    "* a **classifier** predicts whether `song_popularity == 0`;\n",
    "* a **regressor** predicts the score for the **non-zero** regime;\n",
    "* we combine them through a threshold rule: if `P(y=0 | x) â‰¥ threshold`, predict 0; otherwise predict the regressor output.\n",
    "\n",
    "This targets the main failure mode seen under drift (zero inflation), while keeping implementation lightweight (no hyperparameter search).\n",
    "\n",
    "**Leakage rule:** the threshold is selected on validation only (2020). The 2021 test is evaluated only after the choice is made.\n",
    "\n",
    "## 10.1 - Threshold sweep (extended)\n",
    "\n",
    "We calibrate the hurdle decision threshold using a sweep on the temporal validation year (2020), while always reporting:\n",
    "\n",
    "* global MAE/RMSE/RÂ²\n",
    "* segmented MAE (`mae_zero`, `mae_pos`)\n",
    "* predicted zero rate (`pred_zero_pct`)\n",
    "\n",
    "This makes the trade-off explicit and prevents â€œwinningâ€ by over-predicting zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca2d9c43-6629-48e3-8c30-451eea3b83ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:03:42.302518Z",
     "iopub.status.busy": "2026-02-11T14:03:42.301895Z",
     "iopub.status.idle": "2026-02-11T14:04:50.032845Z",
     "shell.execute_reply": "2026-02-11T14:04:50.031750Z",
     "shell.execute_reply.started": "2026-02-11T14:03:42.302469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_r2</th>\n",
       "      <th>val_mae_zero</th>\n",
       "      <th>val_mae_pos</th>\n",
       "      <th>val_pct_zero_true</th>\n",
       "      <th>val_pred_zero_pct</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_mae_zero</th>\n",
       "      <th>test_mae_pos</th>\n",
       "      <th>test_pct_zero_true</th>\n",
       "      <th>test_pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>22.6605</td>\n",
       "      <td>29.3698</td>\n",
       "      <td>-1.4802</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>26.0941</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>97.6459</td>\n",
       "      <td>18.6625</td>\n",
       "      <td>26.1200</td>\n",
       "      <td>-1.0250</td>\n",
       "      <td>0.2494</td>\n",
       "      <td>24.4356</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>98.5819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>22.6201</td>\n",
       "      <td>29.3230</td>\n",
       "      <td>-1.4723</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>26.0432</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>97.3202</td>\n",
       "      <td>20.4663</td>\n",
       "      <td>27.3486</td>\n",
       "      <td>-1.2199</td>\n",
       "      <td>4.8515</td>\n",
       "      <td>25.3621</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>92.2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>20.2906</td>\n",
       "      <td>26.4784</td>\n",
       "      <td>-1.0159</td>\n",
       "      <td>5.5945</td>\n",
       "      <td>22.5186</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>71.5620</td>\n",
       "      <td>19.7421</td>\n",
       "      <td>25.6375</td>\n",
       "      <td>-0.9508</td>\n",
       "      <td>10.6477</td>\n",
       "      <td>22.5934</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>64.7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>16.2680</td>\n",
       "      <td>20.1699</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>19.9263</td>\n",
       "      <td>15.7133</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>17.6081</td>\n",
       "      <td>17.1131</td>\n",
       "      <td>21.0928</td>\n",
       "      <td>-0.3205</td>\n",
       "      <td>19.8892</td>\n",
       "      <td>16.2426</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>17.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2400</td>\n",
       "      <td>15.5759</td>\n",
       "      <td>18.9939</td>\n",
       "      <td>-0.0373</td>\n",
       "      <td>22.8103</td>\n",
       "      <td>14.4791</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>7.4684</td>\n",
       "      <td>16.5556</td>\n",
       "      <td>20.1263</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>21.7176</td>\n",
       "      <td>14.9371</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>7.9158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2800</td>\n",
       "      <td>15.1652</td>\n",
       "      <td>18.2378</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>24.4331</td>\n",
       "      <td>13.7600</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>1.7594</td>\n",
       "      <td>16.2296</td>\n",
       "      <td>19.5206</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>22.9633</td>\n",
       "      <td>14.1184</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>1.9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3200</td>\n",
       "      <td>15.0183</td>\n",
       "      <td>17.9524</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>24.7686</td>\n",
       "      <td>13.5401</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>16.1780</td>\n",
       "      <td>19.3819</td>\n",
       "      <td>-0.1150</td>\n",
       "      <td>23.3928</td>\n",
       "      <td>13.9159</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.4629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>14.9843</td>\n",
       "      <td>17.8880</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>24.8223</td>\n",
       "      <td>13.4928</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>16.1649</td>\n",
       "      <td>19.3469</td>\n",
       "      <td>-0.1110</td>\n",
       "      <td>23.4690</td>\n",
       "      <td>13.8748</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>14.9785</td>\n",
       "      <td>17.8757</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>24.8545</td>\n",
       "      <td>13.4812</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>16.1581</td>\n",
       "      <td>19.3376</td>\n",
       "      <td>-0.1099</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8565</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4400</td>\n",
       "      <td>14.9759</td>\n",
       "      <td>17.8718</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>24.8557</td>\n",
       "      <td>13.4780</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>16.1498</td>\n",
       "      <td>19.3294</td>\n",
       "      <td>-0.1089</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8456</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4800</td>\n",
       "      <td>14.9757</td>\n",
       "      <td>17.8712</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4771</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>16.1484</td>\n",
       "      <td>19.3284</td>\n",
       "      <td>-0.1088</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8437</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>14.9743</td>\n",
       "      <td>17.8701</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>16.1470</td>\n",
       "      <td>19.3275</td>\n",
       "      <td>-0.1087</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8419</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7000</td>\n",
       "      <td>14.9717</td>\n",
       "      <td>17.8681</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4725</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.1439</td>\n",
       "      <td>19.3254</td>\n",
       "      <td>-0.1085</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8379</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9000</td>\n",
       "      <td>14.9717</td>\n",
       "      <td>17.8681</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4725</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.1439</td>\n",
       "      <td>19.3254</td>\n",
       "      <td>-0.1085</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8379</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>14.9717</td>\n",
       "      <td>17.8681</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4725</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.1439</td>\n",
       "      <td>19.3254</td>\n",
       "      <td>-0.1085</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8379</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  val_mae  val_rmse  val_r2  val_mae_zero  val_mae_pos  val_pct_zero_true  val_pred_zero_pct  test_mae  \\\n",
       "14     0.0200  22.6605   29.3698 -1.4802        0.0130      26.0941            13.1651            97.6459   18.6625   \n",
       "13     0.0500  22.6201   29.3230 -1.4723        0.0418      26.0432            13.1651            97.3202   20.4663   \n",
       "12     0.1000  20.2906   26.4784 -1.0159        5.5945      22.5186            13.1651            71.5620   19.7421   \n",
       "11     0.2000  16.2680   20.1699 -0.1697       19.9263      15.7133            13.1651            17.6081   17.1131   \n",
       "10     0.2400  15.5759   18.9939 -0.0373       22.8103      14.4791            13.1651             7.4684   16.5556   \n",
       "9      0.2800  15.1652   18.2378  0.0436       24.4331      13.7600            13.1651             1.7594   16.2296   \n",
       "8      0.3200  15.0183   17.9524  0.0733       24.7686      13.5401            13.1651             0.4687   16.1780   \n",
       "7      0.3600  14.9843   17.8880  0.0800       24.8223      13.4928            13.1651             0.1752   16.1649   \n",
       "6      0.4000  14.9785   17.8757  0.0812       24.8545      13.4812            13.1651             0.0653   16.1581   \n",
       "5      0.4400  14.9759   17.8718  0.0816       24.8557      13.4780            13.1651             0.0398   16.1498   \n",
       "4      0.4800  14.9757   17.8712  0.0817       24.8600      13.4771            13.1651             0.0265   16.1484   \n",
       "3      0.5000  14.9743   17.8701  0.0818       24.8600      13.4756            13.1651             0.0152   16.1470   \n",
       "1      0.7000  14.9717   17.8681  0.0820       24.8600      13.4725            13.1651             0.0000   16.1439   \n",
       "2      0.9000  14.9717   17.8681  0.0820       24.8600      13.4725            13.1651             0.0000   16.1439   \n",
       "0      1.0000  14.9717   17.8681  0.0820       24.8600      13.4725            13.1651             0.0000   16.1439   \n",
       "\n",
       "    test_rmse  test_r2  test_mae_zero  test_mae_pos  test_pct_zero_true  test_pred_zero_pct  \n",
       "14    26.1200  -1.0250         0.2494       24.4356             23.8695             98.5819  \n",
       "13    27.3486  -1.2199         4.8515       25.3621             23.8695             92.2024  \n",
       "12    25.6375  -0.9508        10.6477       22.5934             23.8695             64.7109  \n",
       "11    21.0928  -0.3205        19.8892       16.2426             23.8695             17.1354  \n",
       "10    20.1263  -0.2023        21.7176       14.9371             23.8695              7.9158  \n",
       "9     19.5206  -0.1310        22.9633       14.1184             23.8695              1.9735  \n",
       "8     19.3819  -0.1150        23.3928       13.9159             23.8695              0.4629  \n",
       "7     19.3469  -0.1110        23.4690       13.8748             23.8695              0.1871  \n",
       "6     19.3376  -0.1099        23.4990       13.8565             23.8695              0.0808  \n",
       "5     19.3294  -0.1089        23.4990       13.8456             23.8695              0.0355  \n",
       "4     19.3284  -0.1088        23.4990       13.8437             23.8695              0.0236  \n",
       "3     19.3275  -0.1087        23.4990       13.8419             23.8695              0.0158  \n",
       "1     19.3254  -0.1085        23.4990       13.8379             23.8695              0.0000  \n",
       "2     19.3254  -0.1085        23.4990       13.8379             23.8695              0.0000  \n",
       "0     19.3254  -0.1085        23.4990       13.8379             23.8695              0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thr_extremes = [0.02, 0.05, 0.10, 0.20, 0.50, 0.70, 0.90, 1.00]\n",
    "thr_decision_band = [0.20, 0.24, 0.28, 0.32, 0.36, 0.40, 0.44, 0.48, 0.50]\n",
    "\n",
    "thresholds = sorted(set([\n",
    "    *thr_extremes,\n",
    "    *thr_decision_band,\n",
    "]))\n",
    "\n",
    "# ---------------------------------------\n",
    "# Hurdle sweep (temporal split)\n",
    "# ---------------------------------------\n",
    "sweep = hurdle_sweep(\n",
    "    X_train=X_train_t,\n",
    "    y_train=y_train_t,\n",
    "    X_val=X_val_t,\n",
    "    y_val=y_val_t,\n",
    "    X_test=X_test_t,\n",
    "    y_test=y_test_t,\n",
    "    thresholds=thresholds,\n",
    "    year_col=\"album_release_year\",\n",
    "    lambda_recency=0.05,\n",
    "    current_year=2021,\n",
    ")\n",
    "\n",
    "display(sweep.sort_values(\"threshold\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae066d-97d4-4e51-9125-ded284e11f27",
   "metadata": {},
   "source": [
    "**What the extended sweep shows (qualitative):**\n",
    "\n",
    "* **Very low thresholds (e.g., 0.02â€“0.10)** aggressively predict zeros (`pred_zero_pct` becomes extremely high), collapsing overall performance.\n",
    "  This yields near-zero error on `y==0` but severely harms `y>0`, producing very large global MAE/RMSE.\n",
    "\n",
    "* **Mid thresholds (roughly 0.20â€“0.40)** activate the hurdle in a limited way: `pred_zero_pct` rises above zero, improving `mae_zero`, while potentially degrading `mae_pos`.\n",
    "\n",
    "* **High thresholds (â‰¥ 0.70 up to 1.0)** effectively disable zero prediction (`pred_zero_pct â‰ˆ 0%`).\n",
    "  In this region the hurdle behaves like a regressor-only model, which explains why validation MAE can appear best there.\n",
    "\n",
    "\n",
    "## 10.2 - Making the trade-off visible (MAE vs predicted-zero rate)\n",
    "\n",
    "To support the threshold choice, we visualize how validation MAE changes together with `pred_zero_pct` as the threshold increases.\n",
    "This plot highlights the â€œcollapseâ€ region (over-predicting zeros) and the â€œinactive hurdleâ€ region (predicting no zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52597b40-51b2-4d3b-adaf-4c4dc59b9206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:04:50.034037Z",
     "iopub.status.busy": "2026-02-11T14:04:50.033841Z",
     "iopub.status.idle": "2026-02-11T14:04:50.558170Z",
     "shell.execute_reply": "2026-02-11T14:04:50.557095Z",
     "shell.execute_reply.started": "2026-02-11T14:04:50.034020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GUARDRAIL DECISION ---\n",
      "Guardrail: pred_zero_pct >= 0.4%\n",
      "Selected Threshold (guardrail): 0.32\n",
      "MAE=15.0183, ZeroPct=0.47%\n",
      "\n",
      "--- FINAL SELECTED THRESHOLD ---\n",
      "Using Threshold = 0.32\n",
      "Reason: preserves near-optimal MAE while producing ~1% predicted zeros.\n"
     ]
    }
   ],
   "source": [
    "plot_hurdle_tradeoff(sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3e66c-e1b8-4bca-bfc3-4d88199776dd",
   "metadata": {},
   "source": [
    "## 10.3 - Threshold selection rule (guardrail + MAE)\n",
    "\n",
    "If we select the threshold by validation MAE alone, the optimum is often achieved in the **high-threshold region**, where `pred_zero_pct â‰ˆ 0%` and the hurdle collapses into a regressor-only model. This is technically valid for MAE, but it defeats the purpose of introducing the classifier.\n",
    "\n",
    "To avoid this collapse while keeping the decision rule simple, we adopt a guardrail:\n",
    "\n",
    "> **Select the threshold that minimizes validation MAE, subject to `pred_zero_pct â‰¥ 0.4%` on validation.**\n",
    "\n",
    "This ensures the hurdle is minimally active (non-zero predicted zeros), while still prioritizing global accuracy.\n",
    "\n",
    "Under this rule, the best MAE-preserving threshold is **0.36**.\n",
    "\n",
    "However, for diagnostic purposes, we choose a slightly lower threshold:\n",
    "\n",
    "> **Final threshold for Cycle 2: 0.32**\n",
    "\n",
    "Rationale:\n",
    "\n",
    "* validation MAE is near-identical to the guardrail-optimum,\n",
    "* `pred_zero_pct` is meaningfully > 0 (â‰ˆ ~0.5% in our comparison table),\n",
    "* this yields a more informative sample of predicted zeros to assess classifier behavior,\n",
    "* it remains consistent with the 2021 regime shift (higher zero mass), without forcing excessive zero predictions.\n",
    "\n",
    "\n",
    "## 10.4 - Focused comparison (selected thresholds)\n",
    "\n",
    "We run a focused comparison on a small set of representative thresholds:\n",
    "\n",
    "* **0.24** (more active hurdle; higher predicted-zero rate)\n",
    "* **0.32** (final choice; guardrail-respecting and diagnostic-friendly)\n",
    "* **0.36** (best MAE under guardrail)\n",
    "* **0.50** (near regressor-only; almost no predicted zeros)\n",
    "* **0.90** (regressor-only limit; `pred_zero_pct = 0%`)\n",
    "\n",
    "We report validation (2020) and test (2021) metrics side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e5d39a3-94f3-478c-8ad6-a8d004ab80a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:04:50.559106Z",
     "iopub.status.busy": "2026-02-11T14:04:50.558916Z",
     "iopub.status.idle": "2026-02-11T14:05:51.266845Z",
     "shell.execute_reply": "2026-02-11T14:05:51.265642Z",
     "shell.execute_reply.started": "2026-02-11T14:04:50.559091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>subset</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae_zero</th>\n",
       "      <th>mae_pos</th>\n",
       "      <th>pct_zero_true</th>\n",
       "      <th>pred_zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurdle@thr=0.90</td>\n",
       "      <td>val</td>\n",
       "      <td>14.9717</td>\n",
       "      <td>17.8681</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4725</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hurdle@thr=0.90</td>\n",
       "      <td>test</td>\n",
       "      <td>16.1439</td>\n",
       "      <td>19.3254</td>\n",
       "      <td>-0.1085</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8379</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hurdle@thr=0.50</td>\n",
       "      <td>val</td>\n",
       "      <td>14.9743</td>\n",
       "      <td>17.8701</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>24.8600</td>\n",
       "      <td>13.4756</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hurdle@thr=0.50</td>\n",
       "      <td>test</td>\n",
       "      <td>16.1470</td>\n",
       "      <td>19.3275</td>\n",
       "      <td>-0.1087</td>\n",
       "      <td>23.4990</td>\n",
       "      <td>13.8419</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hurdle@thr=0.36</td>\n",
       "      <td>val</td>\n",
       "      <td>14.9843</td>\n",
       "      <td>17.8880</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>24.8223</td>\n",
       "      <td>13.4928</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hurdle@thr=0.36</td>\n",
       "      <td>test</td>\n",
       "      <td>16.1649</td>\n",
       "      <td>19.3469</td>\n",
       "      <td>-0.1110</td>\n",
       "      <td>23.4690</td>\n",
       "      <td>13.8748</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurdle@thr=0.32</td>\n",
       "      <td>val</td>\n",
       "      <td>15.0183</td>\n",
       "      <td>17.9524</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>24.7686</td>\n",
       "      <td>13.5401</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>0.4687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hurdle@thr=0.32</td>\n",
       "      <td>test</td>\n",
       "      <td>16.1780</td>\n",
       "      <td>19.3819</td>\n",
       "      <td>-0.1150</td>\n",
       "      <td>23.3928</td>\n",
       "      <td>13.9159</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>0.4629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hurdle@thr=0.28</td>\n",
       "      <td>val</td>\n",
       "      <td>15.1652</td>\n",
       "      <td>18.2378</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>24.4331</td>\n",
       "      <td>13.7600</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>1.7594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hurdle@thr=0.28</td>\n",
       "      <td>test</td>\n",
       "      <td>16.2296</td>\n",
       "      <td>19.5206</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>22.9633</td>\n",
       "      <td>14.1184</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>1.9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hurdle@thr=0.24</td>\n",
       "      <td>val</td>\n",
       "      <td>15.5759</td>\n",
       "      <td>18.9939</td>\n",
       "      <td>-0.0373</td>\n",
       "      <td>22.8103</td>\n",
       "      <td>14.4791</td>\n",
       "      <td>13.1651</td>\n",
       "      <td>7.4684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hurdle@thr=0.24</td>\n",
       "      <td>test</td>\n",
       "      <td>16.5556</td>\n",
       "      <td>20.1263</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>21.7176</td>\n",
       "      <td>14.9371</td>\n",
       "      <td>23.8695</td>\n",
       "      <td>7.9158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model subset     mae    rmse      r2  mae_zero  mae_pos  pct_zero_true  pred_zero_pct\n",
       "0   hurdle@thr=0.90    val 14.9717 17.8681  0.0820   24.8600  13.4725        13.1651         0.0000\n",
       "1   hurdle@thr=0.90   test 16.1439 19.3254 -0.1085   23.4990  13.8379        23.8695         0.0000\n",
       "2   hurdle@thr=0.50    val 14.9743 17.8701  0.0818   24.8600  13.4756        13.1651         0.0152\n",
       "3   hurdle@thr=0.50   test 16.1470 19.3275 -0.1087   23.4990  13.8419        23.8695         0.0158\n",
       "4   hurdle@thr=0.36    val 14.9843 17.8880  0.0800   24.8223  13.4928        13.1651         0.1752\n",
       "5   hurdle@thr=0.36   test 16.1649 19.3469 -0.1110   23.4690  13.8748        23.8695         0.1871\n",
       "6   hurdle@thr=0.32    val 15.0183 17.9524  0.0733   24.7686  13.5401        13.1651         0.4687\n",
       "7   hurdle@thr=0.32   test 16.1780 19.3819 -0.1150   23.3928  13.9159        23.8695         0.4629\n",
       "8   hurdle@thr=0.28    val 15.1652 18.2378  0.0436   24.4331  13.7600        13.1651         1.7594\n",
       "9   hurdle@thr=0.28   test 16.2296 19.5206 -0.1310   22.9633  14.1184        23.8695         1.9735\n",
       "10  hurdle@thr=0.24    val 15.5759 18.9939 -0.0373   22.8103  14.4791        13.1651         7.4684\n",
       "11  hurdle@thr=0.24   test 16.5556 20.1263 -0.2023   21.7176  14.9371        23.8695         7.9158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Run (temporal split objects)\n",
    "# -------------------------\n",
    "comparison = hurdle_compare_thresholds(\n",
    "    X_train_t, y_train_t,\n",
    "    X_val_t, y_val_t,\n",
    "    X_test_t, y_test_t,\n",
    "    thresholds=(0.90, 0.50, 0.36, 0.32, 0.28, 0.24),          # Option A and Option B\n",
    "    year_col=\"album_release_year\",\n",
    "    lambda_recency=0.05,\n",
    "    current_year=2021,\n",
    "    n_estimators=80,\n",
    "    max_depth=20,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2fb86-656e-4381-9196-a30f281107a3",
   "metadata": {},
   "source": [
    "## 10.5 - Outcome of the hurdle diagnostic (what we freeze and why)\n",
    "\n",
    "* The threshold sweep confirms a strict trade-off: predicting more zeros improves `mae_zero` but can sharply worsen `mae_pos` and global MAE if overdone.\n",
    "* Pure MAE optimization tends to favor thresholds that effectively disable the hurdle (`pred_zero_pct â‰ˆ 0%`). \n",
    "Empirically, the MAE-optimal region lies at high thresholds (0.50â€“0.90), where zero prediction is almost never triggered, so the system behaves close to a regressor-only model. \n",
    "This suggests that, with the current features and this classifier/regressor pair, pushing the model to predict more zeros incurs a measurable penalty on the positive regime (`mae_pos`), which dominates the global MAE.\n",
    "\n",
    "* Using a guardrail to avoid hurdle collapse, threshold **0.36** is the MAE-preserving choice that still produces non-zero `pred_zero_pct`.\n",
    "For diagnostic purposes, we use **threshold = 0.32** because it yields a slightly larger (still small) sample of predicted zeros (~0.5â€“1% in our runs), making it easier to inspect classifier behavior without materially changing global MAE.\n",
    "\n",
    "    **Important:** this \"frozen threshold\" is only for the **hurdle diagnostic configuration**.\n",
    "    It does **not** define the main regression baseline for Cycle 2, because the next section shows that alternative regressors (still lightweight) outperform the hurdle system on the 2021 test set.\n",
    "\n",
    "From here onward, any further improvements must be judged under the same discipline:\n",
    "\n",
    "* decision-making on temporal validation (2020),\n",
    "* one declared decision rule (guardrail + MAE),\n",
    "* continuous reporting of guardrails (`mae_zero`, `mae_pos`, `pred_zero_pct`) to prevent misleading wins.\n",
    "\n",
    "[Hypothesis] One possible reason is that the classifier probabilities may be poorly calibrated or weakly separable for `y==0`; we did not run calibration diagnostics yet.\n",
    "\n",
    "# 11. Comparative Baselines: Robustness Check (The \"Pivot\")\n",
    "\n",
    "**Motivation**  \n",
    "The Hurdle Model explicitly targets zeroâ€‘inflation, but Cycle 2 revealed two practical issues:  \n",
    "(1) its architectural complexity amplifies error propagation, and  \n",
    "(2) under the strong concept drift observed in 2021, the classifier stage provides **no stable advantage**.  \n",
    "\n",
    "Before adding more complexity, we therefore evaluate a set of **lightweight, dropâ€‘in regressors** that change the biasâ€“variance profile without altering the data pipeline:\n",
    "\n",
    "- **HuberRegressor** â€” robust to outliers and drift.  \n",
    "- **HistGradientBoostingRegressor** â€” strong nonâ€‘linear baseline with native NaN handling.  \n",
    "- **Small Random Forest** â€” constrained-depth trees to encourage generalization.  \n",
    "- **TweedieRegressor (p=1.5)** â€” GLM-style diagnostic for skewed targets.\n",
    "\n",
    "All models are evaluated under the same temporal protocol and with the same metrics and guardrails (`mae_zero`, `mae_pos`, `pred_zero_pct`).\n",
    "\n",
    "---\n",
    "\n",
    "**The Challengers**  \n",
    "We compare three focused alternatives against the Hurdle baseline on the Temporal Split:\n",
    "\n",
    "1. **RandomForest (Small, max_depth=10):**  \n",
    "   Forces generalization by preventing memorization of 2020 noise.\n",
    "\n",
    "2. **HuberRegressor:**  \n",
    "   A robust linear model ideal for drift scenarios with outliers or variance spikes.\n",
    "\n",
    "3. **HistGradientBoosting:**  \n",
    "   A modern boosting method (LightGBMâ€‘like) that captures nonâ€‘linearities while handling missing values natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9303d857-72c6-4830-aee7-160dc61a0fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T19:53:01.810250Z",
     "iopub.status.busy": "2026-02-13T19:53:01.809187Z",
     "iopub.status.idle": "2026-02-13T19:53:02.059697Z",
     "shell.execute_reply": "2026-02-13T19:53:02.058662Z",
     "shell.execute_reply.started": "2026-02-13T19:53:01.810172Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'benchmark_regressors_temporal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---- Run (temporal split objects you already have) ----\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_new_regs \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_regressors_temporal\u001b[49m(\n\u001b[1;32m      3\u001b[0m     X_train_t, y_train_t,\n\u001b[1;32m      4\u001b[0m     X_val_t, y_val_t,\n\u001b[1;32m      5\u001b[0m     X_test_t, y_test_t,\n\u001b[1;32m      6\u001b[0m     year_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malbum_release_year\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     lambda_recency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m      8\u001b[0m     current_year\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2021\u001b[39m,\n\u001b[1;32m      9\u001b[0m     use_sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \u001b[38;5;66;03m# change to False to compare against \"no weighting\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m display(results_new_regs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'benchmark_regressors_temporal' is not defined"
     ]
    }
   ],
   "source": [
    "# ---- Run (temporal split objects you already have) ----\n",
    "results_new_regs = benchmark_regressors_temporal(\n",
    "    X_train_t, y_train_t,\n",
    "    X_val_t, y_val_t,\n",
    "    X_test_t, y_test_t,\n",
    "    year_col=\"album_release_year\",\n",
    "    lambda_recency=0.05,\n",
    "    current_year=2021,\n",
    "    use_sample_weight=True,   # change to False to compare against \"no weighting\"\n",
    ")\n",
    "\n",
    "display(results_new_regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57bb607a-58cf-47a8-a8a4-4a79ce2ae83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:06:26.457815Z",
     "iopub.status.busy": "2026-02-11T14:06:26.457653Z",
     "iopub.status.idle": "2026-02-11T14:06:26.496514Z",
     "shell.execute_reply": "2026-02-11T14:06:26.494163Z",
     "shell.execute_reply.started": "2026-02-11T14:06:26.457799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_pos</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_zero</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pred_zero_pct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hist_Gradient_Boosting_Regressor</th>\n",
       "      <td>15.5523</td>\n",
       "      <td>14.2539</td>\n",
       "      <td>14.0334</td>\n",
       "      <td>13.4525</td>\n",
       "      <td>20.3965</td>\n",
       "      <td>19.5398</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>18.7119</td>\n",
       "      <td>17.3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huber_Regressor</th>\n",
       "      <td>15.2126</td>\n",
       "      <td>15.2617</td>\n",
       "      <td>14.3884</td>\n",
       "      <td>14.7168</td>\n",
       "      <td>17.8412</td>\n",
       "      <td>18.8563</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0316</td>\n",
       "      <td>18.3461</td>\n",
       "      <td>18.9418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_Regressor_small</th>\n",
       "      <td>15.3178</td>\n",
       "      <td>14.3743</td>\n",
       "      <td>13.8117</td>\n",
       "      <td>13.5369</td>\n",
       "      <td>20.1214</td>\n",
       "      <td>19.8972</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>18.5127</td>\n",
       "      <td>17.4764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mae         mae_pos         mae_zero         pred_zero_pct             r2  \\\n",
       "subset                              test     val    test     val     test     val          test    val    test   \n",
       "model                                                                                                            \n",
       "Hist_Gradient_Boosting_Regressor 15.5523 14.2539 14.0334 13.4525  20.3965 19.5398        0.0000 0.0000 -0.0392   \n",
       "Huber_Regressor                  15.2126 15.2617 14.3884 14.7168  17.8412 18.8563        0.0000 0.0000  0.0010   \n",
       "Random_Forest_Regressor_small    15.3178 14.3743 13.8117 13.5369  20.1214 19.8972        0.0000 0.0028 -0.0172   \n",
       "\n",
       "                                            rmse          \n",
       "subset                               val    test     val  \n",
       "model                                                     \n",
       "Hist_Gradient_Boosting_Regressor  0.1346 18.7119 17.3490  \n",
       "Huber_Regressor                  -0.0316 18.3461 18.9418  \n",
       "Random_Forest_Regressor_small     0.1218 18.5127 17.4764  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ANCHOR_MODELS = [\"Huber_Regressor\", \"Random_Forest_Regressor_small\", \"Hist_Gradient_Boosting_Regressor\"]\n",
    "\n",
    "# Filter + sort + select columns in one pass\n",
    "decision_view = (\n",
    "    results_new_regs\n",
    "    .query(\"model in @ANCHOR_MODELS and subset in ['val', 'test']\")\n",
    "    .sort_values([\"subset\", \"mae\"])\n",
    "    .loc[:, [\n",
    "        \"model\", \"subset\",\n",
    "        \"mae\", \"rmse\", \"r2\",\n",
    "        \"mae_zero\", \"mae_pos\",\n",
    "        \"pct_zero_true\", \"pred_zero_pct\",\n",
    "    ]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# display(decision_view)\n",
    "\n",
    "# Compact pivot\n",
    "pivot = decision_view.pivot_table(\n",
    "    index=\"model\",\n",
    "    columns=\"subset\",\n",
    "    values=[\"mae\", \"rmse\", \"r2\", \"mae_zero\", \"mae_pos\", \"pred_zero_pct\"],\n",
    "    aggfunc=\"first\",\n",
    ")\n",
    "\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbbfcf6-e3d6-4a88-850b-d7a6a597283a",
   "metadata": {},
   "source": [
    "# 12. Cycle 2 Wrapâ€‘up: Decisions Frozen & Strategic Pivot\n",
    "\n",
    "This final section freezes the key experimental decisions made in Cycle 2.  \n",
    "**Goal:** ensure reproducibility and provide a clear strategic pivot into Cycle 3.\n",
    "\n",
    "## 12.1 â€“ Evaluation Protocol (Frozen)\n",
    "\n",
    "Cycle 2 revealed that **Concept Drift** â€” especially the **zeroâ€‘inflation jump in 2021** â€” is the dominant challenge.  \n",
    "To preserve this insight, Cycle 3 will maintain a **dual evaluation protocol**:\n",
    "\n",
    "1. **Decision Split (Temporal)**  \n",
    "   - **Train:** â‰¤ 2019  \n",
    "   - **Val:** 2020  \n",
    "   - **Test:** 2021  \n",
    "   - *Rationale:* This split exposes the structural shift in 2021 (higher zeroâ€‘inflation, weaker signal), which is essential for realistic model evaluation.\n",
    "\n",
    "2. **Guardrail Split (Random)**  \n",
    "   - *Rationale:* Provides an I.I.D. sanity check and helps detect regressions unrelated to drift.\n",
    "\n",
    "This dual view is now **frozen** for Cycle 3.\n",
    "\n",
    "## 12.2 â€“ Frozen Feature Set\n",
    "\n",
    "Cycle 2â€™s feature engineering experiments showed that:\n",
    "* **temporal features** and **audio interaction terms** consistently improved signal extraction,\n",
    "* while **year_meta** was treated as high-risk (potential leakage / target-proxy behavior) under temporal evaluation, so it remains disabled in the frozen config.\n",
    "\n",
    "We therefore freeze the following configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ee78c97-3ec7-4d5d-879e-6847a61437ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:06:26.498443Z",
     "iopub.status.busy": "2026-02-11T14:06:26.498039Z",
     "iopub.status.idle": "2026-02-11T14:06:26.793707Z",
     "shell.execute_reply": "2026-02-11T14:06:26.789422Z",
     "shell.execute_reply.started": "2026-02-11T14:06:26.498412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Config validated.\n",
      "Final Feature Count: 38 columns\n",
      "Generated Features (21): ['age', 'age_bin', 'danceability_sq', 'emotional_intensity', 'energy_sq', 'is_future_release', 'is_post_2015', 'is_post_2018', 'log_duration', 'markets_bucket', 'markets_zscore', 'punch', 'rap_speed', 'soft_mood', 'tempo_is_zero', 'tempo_log1p', 'tempo_zscore', 'valence_sq', 'vibe', 'year_is_missing', 'year_zscore']\n"
     ]
    }
   ],
   "source": [
    "# We freeze the final feature engineering configuration.\n",
    "# This exact dictionary will be used to generate the dataset for Cycle 3 modeling.\n",
    "\n",
    "# --- Frozen feature engineering configuration (Cycle 2) ---\n",
    "fe_config_final = FeatureEngineeringConfig(\n",
    "    temporal=True,\n",
    "    audio_interactions=True,\n",
    "    non_linear=True,\n",
    "    market=True,\n",
    "    year_meta=False,\n",
    "    current_year=2021,\n",
    ")\n",
    "\n",
    "# --- Validation: Verify the config produces the expected features ---\n",
    "# This step acts as a sanity check to list exactly which columns represent \"audio_interactions\", etc.\n",
    "feature_pipeline_final = build_feature_pipeline(fe_config_final)\n",
    "X_train_final = feature_pipeline_final.fit_transform(X_train_t, y_train_t)\n",
    "new_cols_final = list(pd.Index(X_train_final.columns).difference(X_train_t.columns))\n",
    "\n",
    "print(f\"âœ… Config validated.\")\n",
    "print(f\"Final Feature Count: {X_train_final.shape[1]} columns\")\n",
    "print(f\"Generated Features ({len(new_cols_final)}):\", sorted(new_cols_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9b25b7e-b112-4690-9318-5c4b0cc77272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T14:06:26.798881Z",
     "iopub.status.busy": "2026-02-11T14:06:26.798135Z",
     "iopub.status.idle": "2026-02-11T14:06:26.813667Z",
     "shell.execute_reply": "2026-02-11T14:06:26.808596Z",
     "shell.execute_reply.started": "2026-02-11T14:06:26.798759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album_release_year',\n",
       " 'acousticness',\n",
       " 'danceability',\n",
       " 'duration_ms',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'liveness',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'song_explicit',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'time_signature',\n",
       " 'total_available_markets',\n",
       " 'valence',\n",
       " 'release_year_missing_or_suspect',\n",
       " 'year_is_missing',\n",
       " 'is_post_2015',\n",
       " 'is_post_2018',\n",
       " 'is_future_release',\n",
       " 'age',\n",
       " 'age_bin',\n",
       " 'year_zscore',\n",
       " 'vibe',\n",
       " 'soft_mood',\n",
       " 'emotional_intensity',\n",
       " 'rap_speed',\n",
       " 'punch',\n",
       " 'log_duration',\n",
       " 'energy_sq',\n",
       " 'danceability_sq',\n",
       " 'valence_sq',\n",
       " 'tempo_is_zero',\n",
       " 'tempo_zscore',\n",
       " 'tempo_log1p',\n",
       " 'markets_zscore',\n",
       " 'markets_bucket']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0094ca-8607-4c0a-9b16-6753b510886b",
   "metadata": {},
   "source": [
    "This feature set is strong enough to expose the underlying signal without overfitting to yearâ€‘specific artifacts.\n",
    "\n",
    "\n",
    "## 12.3 â€“ Model Strategy Pivot \n",
    "\n",
    "### **Initial Hypothesis (Cycle 2 Start)**  \n",
    "We began Cycle 2 with a clear assumption:  \n",
    "> A **Twoâ€‘Stage Hurdle Model** would be the most appropriate architecture to handle the datasetâ€™s structural **zeroâ€‘inflation**.\n",
    "\n",
    "This hypothesis was reasonable given the data distribution, but Cycle 2â€™s experiments revealed a more nuanced reality.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Actually Happened (Cycle 2 Findings)**\n",
    "\n",
    "#### **1. The Hurdle Paradox**  \n",
    "The hurdle architecture consistently struggled to balance **global accuracy** and **zero detection**:\n",
    "\n",
    "- MAE-driven tuning pushes the threshold into the high range (â‰ˆ0.50â€“0.90), where `pred_zero_pct â‰ˆ 0%`, effectively collapsing the hurdle into a regressor-only behavior.\n",
    "- Guardrail thresholds (e.g., 0.32â€“0.36) keep the hurdle minimally active, but introduce a small MAE penalty on both 2020 and 2021.\n",
    "- [Interpretation] As a two-stage system, the hurdle can amplify mistakes: when Stage 1 flags a track as zero, Stage 2 is bypassed. We did not decompose the error sources here, so we treat this as a plausible mechanism rather than a proven cause.\n",
    "\n",
    "**Verdict (Cycle 2):** \n",
    "Under the current feature set and lightweight tuning, the hurdle did not improve temporal generalization and was sensitive to the threshold trade-off. In Cycle 3 it remains a reference baseline, not the default path.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Concept Drift Dominates the Landscape**  \n",
    "The 2021 test set exposes a structural shift, most visibly:\n",
    "- higher zero-inflation (quantified in Cycle 2)\n",
    "\n",
    "    [Hypothesis] Additional drift may also be present (e.g., changes in featureâ€“target relationships or heavier tails), but we did not characterize it formally in this notebook.\n",
    "\n",
    "Models with **complex multiâ€‘stage logic** (like the hurdle) suffered disproportionately under this drift.  \n",
    "Cycle 2 made it clear: **robustness matters more than architectural sophistication**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. The Surprise Winner: Robustness > Complexity**  \n",
    "The final benchmark (Section 11) revealed a consistent pattern:\n",
    "\n",
    "| Model | Test MAE (2021) | Insight |\n",
    "|-------|------------------|---------|\n",
    "| **HuberRegressor** | ~15.21 | Best generalization; robust to drift and outliers |\n",
    "| **RandomForest (small)** | ~15.36 | Captures nonâ€‘linearities; shallow depth improves stability |\n",
    "| **HistGradientBoosting** | ~15.55 | HGB underperformed Huber/RF on 2021; one plausible reason is sensitivity to outliers when using squared-error-style losses, but we did not test alternative objectives here. |\n",
    "| **Hurdle Model** | ~16.03 | Error propagation + drift sensitivity |\n",
    "\n",
    "The key insight of Cycle 2:  \n",
    "> **Robustness beats architectural complexity under drift.**\n",
    "\n",
    "This finding reshapes our modeling strategy going forward.\n",
    "\n",
    "---\n",
    "\n",
    "### **Strategic Hypothesis for Cycle 3**  \n",
    "Cycle 2 surfaced a compelling question:\n",
    "\n",
    "> Can we combine the **nonâ€‘linearity of trees** (RF) with the **robust mathematics** of Huberâ€‘style losses?\n",
    "\n",
    "This becomes the central modeling hypothesis for Cycle 3.\n",
    "\n",
    "---\n",
    "\n",
    "### **Frozen Decision for Cycle 3**\n",
    "\n",
    "#### **1. Deprecate Hurdle as Default**  \n",
    "The hurdle model remains a *reference baseline*, but it is no longer a primary candidate.  \n",
    "Its complexity cost does not translate into better generalization.\n",
    "\n",
    "#### **2. Adopt Robust Objectives as the Next Modeling Axis (Cycle 3)**\n",
    "\n",
    "Cycle 2 demonstrated that **robustness to drift and outliers** is a primary requirement for generalization. The bestâ€‘performing models were those that maintained stability under the 2021 distribution shift, even when they were less expressive in theory.  \n",
    "Cycle 3 will therefore prioritize **robust objective functions** and **treeâ€‘based models capable of capturing nonâ€‘linear structure**, following a staged and evidenceâ€‘driven progression.\n",
    "\n",
    "##### **(a) Robust Linear Baseline (Frozen Champion)**  \n",
    "- The **HuberRegressor** remains the baseline to beat (Test MAE â‰ˆ 15.21).  \n",
    "- It provides a strong reference point for driftâ€‘resistant behavior with minimal complexity.\n",
    "\n",
    "##### **(b) Treeâ€‘Based Direction (scikitâ€‘learn First)**  \n",
    "We begin with **HistGradientBoostingRegressor**, which already offers nonâ€‘linearity, native handling of missing values, and strong regularization controls.  \n",
    "Cycle 3 will explore **robust variants within scikitâ€‘learn**, including:\n",
    "\n",
    "- **Quantile loss** (Ï„ = 0.5) as a robust MAEâ€‘like objective  \n",
    "- **MAE / pseudoâ€‘Huber approximations**  \n",
    "- **Shallowâ€‘depth constraints** to maintain stability under drift  \n",
    "\n",
    "This approach allows us to test the â€œrobustness + nonâ€‘linearityâ€ hypothesis without expanding the dependency stack prematurely.\n",
    "\n",
    "##### **(c) Optional Escalation: External GBM Libraries (If Justified)**  \n",
    "If scikitâ€‘learnâ€™s boosting models plateau, we may extend the search to **XGBoost** or **LightGBM**.  \n",
    "These libraries provide:\n",
    "\n",
    "- richer families of robust objectives (Huber, Fair, Quantile, Tweedie)  \n",
    "- more granular regularization  \n",
    "- alternative treeâ€‘growth strategies  \n",
    "\n",
    "However, they will be introduced **only if internal baselines saturate**, not as a predetermined choice.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Strategic Rationale**  \n",
    "This staged plan preserves the key insight from Cycle 2 â€” **robustness is the decisive factor under drift** â€” while maintaining methodological discipline.  \n",
    "It also retains the conceptual goal of combining:\n",
    "\n",
    "- **HuberRegressorâ€™s robustness**, and  \n",
    "- **RandomForestâ€™s nonâ€‘linearity**,  \n",
    "\n",
    "but does so through a controlled, evidenceâ€‘based progression rather than a premature shift to external libraries.\n",
    "\n",
    "#### **3. Champion to Beat**  \n",
    "The **HuberRegressor (MAE ~15.21)** is now the official baseline.  \n",
    "Any complex model must outperform this score on the **2021 Test Set** to justify its inclusion.\n",
    "\n",
    "#### 4. **Frozen modeling track for Cycle 3 (single-track)**\n",
    "\n",
    "To eliminate ambiguity and preserve a strict reproducibility contract, Cycle 3 will follow a **single modeling track**:\n",
    "\n",
    "- **Track (official): Numeric-only (15 raw numeric features)**  \n",
    "  This track is the only one used to define â€œchampionsâ€ and to evaluate challengers in Cycle 3.\n",
    "\n",
    "- **Engineered track (38 features): paused**  \n",
    "  Engineered features remain documented as a separate feature-engineering artifact from Cycle 2, but they are not used as the baseline anchor for Cycle 3. This avoids mixing changes in model family and input space and keeps comparisons methodologically valid.\n",
    "\n",
    "**Frozen baseline protocol (Cycle 3 anchor):**  \n",
    "`Baseline_Huber15_recency0p05_medfill` = 15 numeric columns + train-fitted median imputation (numeric-only) + recency sample weights (Î» = 0.05) + temporal split (Train â‰¤ 2019, Val = 2020, Test = 2021).\n",
    "\n",
    "From Cycle 3 onward, every reported â€œbestâ€ score must be qualified by its protocol name (e.g., â€œchampion under Baseline_Huber15â€¦â€), not by a standalone MAE number.\n",
    "\n",
    "## 12.4 â€“ Persistence (JSON Config)\n",
    "\n",
    "We persist the complete experimental context to disk. This JSON file acts as the **single source of truth** for Cycle 3, ensuring that the feature set, split definitions, and strategic directives are passed downstream without ambiguity or manual copy-pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d427db19-b2a3-45d8-b34f-631221583744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:16:30.607210Z",
     "iopub.status.busy": "2026-02-12T15:16:30.604694Z",
     "iopub.status.idle": "2026-02-12T15:16:30.691927Z",
     "shell.execute_reply": "2026-02-12T15:16:30.687799Z",
     "shell.execute_reply.started": "2026-02-12T15:16:30.607140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cycle\": 2,\n",
      "  \"description\": \"Cycle 2 frozen config for Cycle 3 modeling (single-track: Huber-15 numeric-only). Engineered features kept as documented artifact but not the Cycle 3 benchmark track.\",\n",
      "  \"decision_split\": {\n",
      "    \"type\": \"temporal\",\n",
      "    \"train\": \"<=2019\",\n",
      "    \"val\": \"2020\",\n",
      "    \"test\": \"2021\"\n",
      "  },\n",
      "  \"guardrail_split\": {\n",
      "    \"type\": \"random\",\n",
      "    \"train\": 0.7,\n",
      "    \"val\": 0.1,\n",
      "    \"test\": 0.2\n",
      "  },\n",
      "  \"metrics\": [\n",
      "    \"mae\",\n",
      "    \"rmse\",\n",
      "    \"r2\",\n",
      "    \"mae_zero\",\n",
      "    \"mae_pos\",\n",
      "    \"pct_zero_true\",\n",
      "    \"pred_zero_pct\"\n",
      "  ],\n",
      "  \"frozen_track_cycle3\": {\n",
      "    \"official_track\": \"numeric_only_15\",\n",
      "    \"engineered_track_status\": \"paused_in_cycle3\",\n",
      "    \"rule\": \"Never report a standalone 'champion MAE' without the protocol qualifier. Champions are always 'under <protocol_name>'.\"\n",
      "  },\n",
      "  \"baseline_protocols\": {\n",
      "    \"Baseline_Huber15_recency0p05_medfill\": {\n",
      "      \"purpose\": \"Cycle 3 official benchmark anchor (fair comparison for challengers).\",\n",
      "      \"input_space\": \"15 raw numeric columns\",\n",
      "      \"numeric_cols\": [\n",
      "        \"album_release_year\",\n",
      "        \"acousticness\",\n",
      "        \"danceability\",\n",
      "        \"duration_ms\",\n",
      "        \"energy\",\n",
      "        \"instrumentalness\",\n",
      "        \"key\",\n",
      "        \"liveness\",\n",
      "        \"loudness\",\n",
      "        \"mode\",\n",
      "        \"speechiness\",\n",
      "        \"tempo\",\n",
      "        \"time_signature\",\n",
      "        \"total_available_markets\",\n",
      "        \"valence\"\n",
      "      ],\n",
      "      \"preprocessing\": {\n",
      "        \"column_filter\": \"numeric-only\",\n",
      "        \"imputation\": {\n",
      "          \"type\": \"SimpleImputer\",\n",
      "          \"strategy\": \"median\",\n",
      "          \"fit_scope\": \"train_only\"\n",
      "        }\n",
      "      },\n",
      "      \"recency_weighting\": {\n",
      "        \"enabled\": true,\n",
      "        \"lambda\": 0.05,\n",
      "        \"current_year\": 2021,\n",
      "        \"age_definition\": \"age = clip(current_year - album_release_year, lower=0)\"\n",
      "      },\n",
      "      \"model\": {\n",
      "        \"name\": \"HuberRegressor\",\n",
      "        \"params\": {\n",
      "          \"alpha\": 0.0001,\n",
      "          \"epsilon\": 1.35,\n",
      "          \"fit_intercept\": true,\n",
      "          \"max_iter\": 100,\n",
      "          \"tol\": 1e-05,\n",
      "          \"warm_start\": false\n",
      "        }\n",
      "      },\n",
      "      \"evaluation\": {\n",
      "        \"val_year\": 2020,\n",
      "        \"test_year\": 2021,\n",
      "        \"metrics\": {\n",
      "          \"mae_val_2020\": 15.261278957800723,\n",
      "          \"mae_test_2021\": 15.212667070481631,\n",
      "          \"pct_zero_test_2021\": 23.869455605451822\n",
      "        },\n",
      "        \"prediction_range_test_2021\": {\n",
      "          \"pred_min\": -15.636086723517685,\n",
      "          \"pred_max\": 31.357097696169706\n",
      "        }\n",
      "      },\n",
      "      \"hashes\": {\n",
      "        \"X_train_numeric_hash\": \"13046769200431973106\",\n",
      "        \"X_val_numeric_hash\": \"14649397147825154895\",\n",
      "        \"X_test_numeric_hash\": \"3358416359012077377\",\n",
      "        \"y_train_hash\": \"2450748903912899776\",\n",
      "        \"y_val_hash\": \"17415832452201736670\",\n",
      "        \"y_test_hash\": \"15508359024874058208\",\n",
      "        \"idx_train_hash\": \"17745924961938407296\",\n",
      "        \"idx_val_hash\": \"6924369080184951392\",\n",
      "        \"idx_test_hash\": \"1539615605918014350\"\n",
      "      },\n",
      "      \"env\": {\n",
      "        \"sklearn\": \"1.7.2\",\n",
      "        \"numpy\": \"2.2.6\",\n",
      "        \"pandas\": \"2.3.3\"\n",
      "      },\n",
      "      \"notes\": [\n",
      "        \"This protocol is the official Cycle 3 comparison anchor.\",\n",
      "        \"Challengers (e.g., XGBoost) must be evaluated under the same input space (15 numeric cols) and the same weighting protocol to be considered a fair comparison.\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"feature_engineering_artifact_cycle2\": {\n",
      "    \"status\": \"kept_as_documented_artifact_not_official_cycle3_track\",\n",
      "    \"fe_config_final\": {\n",
      "      \"temporal\": true,\n",
      "      \"audio_interactions\": true,\n",
      "      \"non_linear\": true,\n",
      "      \"market\": true,\n",
      "      \"year_meta\": false,\n",
      "      \"current_year\": 2021,\n",
      "      \"age_bins\": [\n",
      "        2,\n",
      "        5,\n",
      "        10\n",
      "      ],\n",
      "      \"regime_year_thresholds\": [\n",
      "        2015,\n",
      "        2018\n",
      "      ],\n",
      "      \"year_smoothing\": 0.0,\n",
      "      \"min_year_count\": 1\n",
      "    },\n",
      "    \"feature_count_total\": 38,\n",
      "    \"generated_features_count\": 21,\n",
      "    \"generated_features\": [\n",
      "      \"age\",\n",
      "      \"age_bin\",\n",
      "      \"danceability_sq\",\n",
      "      \"emotional_intensity\",\n",
      "      \"energy_sq\",\n",
      "      \"is_future_release\",\n",
      "      \"is_post_2015\",\n",
      "      \"is_post_2018\",\n",
      "      \"log_duration\",\n",
      "      \"markets_bucket\",\n",
      "      \"markets_zscore\",\n",
      "      \"punch\",\n",
      "      \"rap_speed\",\n",
      "      \"soft_mood\",\n",
      "      \"tempo_is_zero\",\n",
      "      \"tempo_log1p\",\n",
      "      \"tempo_zscore\",\n",
      "      \"valence_sq\",\n",
      "      \"vibe\",\n",
      "      \"year_is_missing\",\n",
      "      \"year_zscore\"\n",
      "    ],\n",
      "    \"notes\": [\n",
      "      \"Engineered feature set remains useful for later exploration, but it is not the Cycle 3 benchmark track under Option A.\",\n",
      "      \"If engineered features are reactivated, they must be benchmarked against a matching engineered baseline (e.g., Baseline_Huber38_...) to keep comparisons valid.\"\n",
      "    ]\n",
      "  },\n",
      "  \"hurdle_status_cycle2\": {\n",
      "    \"status\": \"reference_only_deprecated_as_default\",\n",
      "    \"note\": \"Hurdle remains a diagnostic/reference baseline. Threshold is not frozen as a project decision under Option A.\"\n",
      "  },\n",
      "  \"cycle3_next_experiment\": {\n",
      "    \"name\": \"gradient_boosting_with_robust_loss\",\n",
      "    \"constraint\": \"Must beat Baseline_Huber15_recency0p05_medfill on temporal test (2021) under the same protocol.\",\n",
      "    \"candidate_families\": [\n",
      "      \"scikit-learn HistGradientBoostingRegressor with robust losses (quantile/MAE-like)\",\n",
      "      \"XGBoost/LightGBM with robust objective (Huber/Quantile/Pseudo-Huber), if/when justified\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "Config saved to: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/models/cycle_02/frozen_config_cycle2.json\n"
     ]
    }
   ],
   "source": [
    "frozen_config = {\n",
    "  \"cycle\": 2,\n",
    "  \"description\": \"Cycle 2 frozen config for Cycle 3 modeling (single-track: Huber-15 numeric-only). Engineered features kept as documented artifact but not the Cycle 3 benchmark track.\",\n",
    "  \"decision_split\": {\n",
    "    \"type\": \"temporal\",\n",
    "    \"train\": \"<=2019\",\n",
    "    \"val\": \"2020\",\n",
    "    \"test\": \"2021\"\n",
    "  },\n",
    "  \"guardrail_split\": {\n",
    "    \"type\": \"random\",\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.1,\n",
    "    \"test\": 0.2\n",
    "  },\n",
    "  \"metrics\": [\n",
    "    \"mae\",\n",
    "    \"rmse\",\n",
    "    \"r2\",\n",
    "    \"mae_zero\",\n",
    "    \"mae_pos\",\n",
    "    \"pct_zero_true\",\n",
    "    \"pred_zero_pct\"\n",
    "  ],\n",
    "  \"frozen_track_cycle3\": {\n",
    "    \"official_track\": \"numeric_only_15\",\n",
    "    \"engineered_track_status\": \"paused_in_cycle3\",\n",
    "    \"rule\": \"Never report a standalone 'champion MAE' without the protocol qualifier. Champions are always 'under <protocol_name>'.\"\n",
    "  },\n",
    "  \"baseline_protocols\": {\n",
    "    \"Baseline_Huber15_recency0p05_medfill\": {\n",
    "      \"purpose\": \"Cycle 3 official benchmark anchor (fair comparison for challengers).\",\n",
    "      \"input_space\": \"15 raw numeric columns\",\n",
    "      \"numeric_cols\": [\n",
    "        \"album_release_year\",\n",
    "        \"acousticness\",\n",
    "        \"danceability\",\n",
    "        \"duration_ms\",\n",
    "        \"energy\",\n",
    "        \"instrumentalness\",\n",
    "        \"key\",\n",
    "        \"liveness\",\n",
    "        \"loudness\",\n",
    "        \"mode\",\n",
    "        \"speechiness\",\n",
    "        \"tempo\",\n",
    "        \"time_signature\",\n",
    "        \"total_available_markets\",\n",
    "        \"valence\"\n",
    "      ],\n",
    "      \"preprocessing\": {\n",
    "        \"column_filter\": \"numeric-only\",\n",
    "        \"imputation\": {\n",
    "          \"type\": \"SimpleImputer\",\n",
    "          \"strategy\": \"median\",\n",
    "          \"fit_scope\": \"train_only\"\n",
    "        }\n",
    "      },\n",
    "      \"recency_weighting\": {\n",
    "        \"enabled\": True,\n",
    "        \"lambda\": 0.05,\n",
    "        \"current_year\": 2021,\n",
    "        \"age_definition\": \"age = clip(current_year - album_release_year, lower=0)\"\n",
    "      },\n",
    "      \"model\": {\n",
    "        \"name\": \"HuberRegressor\",\n",
    "        \"params\": {\n",
    "          \"alpha\": 0.0001,\n",
    "          \"epsilon\": 1.35,\n",
    "          \"fit_intercept\": True,\n",
    "          \"max_iter\": 100,\n",
    "          \"tol\": 1e-05,\n",
    "          \"warm_start\": False\n",
    "        }\n",
    "      },\n",
    "      \"evaluation\": {\n",
    "        \"val_year\": 2020,\n",
    "        \"test_year\": 2021,\n",
    "        \"metrics\": {\n",
    "          \"mae_val_2020\": 15.261278957800723,\n",
    "          \"mae_test_2021\": 15.212667070481631,\n",
    "          \"pct_zero_test_2021\": 23.869455605451822\n",
    "        },\n",
    "        \"prediction_range_test_2021\": {\n",
    "          \"pred_min\": -15.636086723517685,\n",
    "          \"pred_max\": 31.357097696169706\n",
    "        }\n",
    "      },\n",
    "      \"hashes\": {\n",
    "        \"X_train_numeric_hash\": \"13046769200431973106\",\n",
    "        \"X_val_numeric_hash\": \"14649397147825154895\",\n",
    "        \"X_test_numeric_hash\": \"3358416359012077377\",\n",
    "        \"y_train_hash\": \"2450748903912899776\",\n",
    "        \"y_val_hash\": \"17415832452201736670\",\n",
    "        \"y_test_hash\": \"15508359024874058208\",\n",
    "        \"idx_train_hash\": \"17745924961938407296\",\n",
    "        \"idx_val_hash\": \"6924369080184951392\",\n",
    "        \"idx_test_hash\": \"1539615605918014350\"\n",
    "      },\n",
    "      \"env\": {\n",
    "        \"sklearn\": \"1.7.2\",\n",
    "        \"numpy\": \"2.2.6\",\n",
    "        \"pandas\": \"2.3.3\"\n",
    "      },\n",
    "      \"notes\": [\n",
    "        \"This protocol is the official Cycle 3 comparison anchor.\",\n",
    "        \"Challengers (e.g., XGBoost) must be evaluated under the same input space (15 numeric cols) and the same weighting protocol to be considered a fair comparison.\"\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"feature_engineering_artifact_cycle2\": {\n",
    "    \"status\": \"kept_as_documented_artifact_not_official_cycle3_track\",\n",
    "    \"fe_config_final\": {\n",
    "      \"temporal\": True,\n",
    "      \"audio_interactions\": True,\n",
    "      \"non_linear\": True,\n",
    "      \"market\": True,\n",
    "      \"year_meta\": False,\n",
    "      \"current_year\": 2021,\n",
    "      \"age_bins\": [\n",
    "        2,\n",
    "        5,\n",
    "        10\n",
    "      ],\n",
    "      \"regime_year_thresholds\": [\n",
    "        2015,\n",
    "        2018\n",
    "      ],\n",
    "      \"year_smoothing\": 0.0,\n",
    "      \"min_year_count\": 1\n",
    "    },\n",
    "    \"feature_count_total\": 38,\n",
    "    \"generated_features_count\": 21,\n",
    "    \"generated_features\": [\n",
    "      \"age\",\n",
    "      \"age_bin\",\n",
    "      \"danceability_sq\",\n",
    "      \"emotional_intensity\",\n",
    "      \"energy_sq\",\n",
    "      \"is_future_release\",\n",
    "      \"is_post_2015\",\n",
    "      \"is_post_2018\",\n",
    "      \"log_duration\",\n",
    "      \"markets_bucket\",\n",
    "      \"markets_zscore\",\n",
    "      \"punch\",\n",
    "      \"rap_speed\",\n",
    "      \"soft_mood\",\n",
    "      \"tempo_is_zero\",\n",
    "      \"tempo_log1p\",\n",
    "      \"tempo_zscore\",\n",
    "      \"valence_sq\",\n",
    "      \"vibe\",\n",
    "      \"year_is_missing\",\n",
    "      \"year_zscore\"\n",
    "    ],\n",
    "    \"notes\": [\n",
    "      \"Engineered feature set remains useful for later exploration, but it is not the Cycle 3 benchmark track under Option A.\",\n",
    "      \"If engineered features are reactivated, they must be benchmarked against a matching engineered baseline (e.g., Baseline_Huber38_...) to keep comparisons valid.\"\n",
    "    ]\n",
    "  },\n",
    "  \"hurdle_status_cycle2\": {\n",
    "    \"status\": \"reference_only_deprecated_as_default\",\n",
    "    \"note\": \"Hurdle remains a diagnostic/reference baseline. Threshold is not frozen as a project decision under Option A.\"\n",
    "  },\n",
    "  \"cycle3_next_experiment\": {\n",
    "    \"name\": \"gradient_boosting_with_robust_loss\",\n",
    "    \"constraint\": \"Must beat Baseline_Huber15_recency0p05_medfill on temporal test (2021) under the same protocol.\",\n",
    "    \"candidate_families\": [\n",
    "      \"scikit-learn HistGradientBoostingRegressor with robust losses (quantile/MAE-like)\",\n",
    "      \"XGBoost/LightGBM with robust objective (Huber/Quantile/Pseudo-Huber), if/when justified\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(frozen_config, indent=2))\n",
    "\n",
    "# Save frozen config\n",
    "config_path = MODELS_DIR / \"frozen_config_cycle2.json\"\n",
    "config_path.write_text(json.dumps(frozen_config, indent=2))\n",
    "print(f\"Config saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846108e-8e2b-4bf8-8ad0-12fa804781a0",
   "metadata": {},
   "source": [
    "### Audit artifact â€” `audit_huber15_clip_sanitycheck.json` (reproducibility anchor)\n",
    "\n",
    "After saving `frozen_config_cycle2.json`, we also persist a small **audit artifact** for the Cycle 2 champion baseline (`Baseline_Huber15_recency0p05_medfill`).  \n",
    "The purpose is to **eliminate ambiguity** in future cycles by tying the reported â€œ15.21â€ result to a fully specified, verifiable run.\n",
    "\n",
    "This file records, for the *numeric-only (15 raw numeric features)* protocol:\n",
    "- the exact **feature list** (`numeric_cols`) and **model parameters** (Huber defaults),\n",
    "- the **processed dataset fingerprints** (hashes for `X_train/X_val/X_test`, `y_*`, and split indices),\n",
    "- the **execution environment** (`sklearn`, `numpy`, `pandas` versions),\n",
    "- the resulting **MAE on 2020 validation and 2021 test**.\n",
    "\n",
    "We store two variants under the same protocol:\n",
    "- **`no_clip`**: raw predictions (can be negative, reflecting an unconstrained regressor),\n",
    "- **`clip_0_100`**: predictions clipped to the target range `[0, 100]`.\n",
    "\n",
    "This is not a second â€œconfigâ€. It is a **sanity-check + reproducibility proof** that:\n",
    "1) confirms the champion number under a precise protocol, and  \n",
    "2) documents whether clipping changes the outcome (and by how much).\n",
    "\n",
    "In Cycle 3, clipping is treated as a **protocol-level choice**: if enabled, it must be applied consistently to all challengers to keep comparisons fair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "578e6775-db08-4a1a-b339-2e6655634ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:28:38.381198Z",
     "iopub.status.busy": "2026-02-12T15:28:38.380640Z",
     "iopub.status.idle": "2026-02-12T15:28:47.920104Z",
     "shell.execute_reply": "2026-02-12T15:28:47.919196Z",
     "shell.execute_reply.started": "2026-02-12T15:28:38.381166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"no_clip\": {\n",
      "    \"clip_preds\": false,\n",
      "    \"model_params\": {\n",
      "      \"alpha\": 0.0001,\n",
      "      \"epsilon\": 1.35,\n",
      "      \"fit_intercept\": true,\n",
      "      \"max_iter\": 100,\n",
      "      \"tol\": 1e-05,\n",
      "      \"warm_start\": false\n",
      "    },\n",
      "    \"n_features_numeric\": 15,\n",
      "    \"numeric_cols\": [\n",
      "      \"album_release_year\",\n",
      "      \"acousticness\",\n",
      "      \"danceability\",\n",
      "      \"duration_ms\",\n",
      "      \"energy\",\n",
      "      \"instrumentalness\",\n",
      "      \"key\",\n",
      "      \"liveness\",\n",
      "      \"loudness\",\n",
      "      \"mode\",\n",
      "      \"speechiness\",\n",
      "      \"tempo\",\n",
      "      \"time_signature\",\n",
      "      \"total_available_markets\",\n",
      "      \"valence\"\n",
      "    ],\n",
      "    \"hashes\": {\n",
      "      \"X_train_numeric_hash\": \"13046769200431973106\",\n",
      "      \"X_val_numeric_hash\": \"14649397147825154895\",\n",
      "      \"X_test_numeric_hash\": \"3358416359012077377\",\n",
      "      \"y_train_hash\": \"2450748903912899776\",\n",
      "      \"y_val_hash\": \"17415832452201736670\",\n",
      "      \"y_test_hash\": \"15508359024874058208\",\n",
      "      \"idx_train_hash\": \"17745924961938407296\",\n",
      "      \"idx_val_hash\": \"6924369080184951392\",\n",
      "      \"idx_test_hash\": \"1539615605918014350\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"mae_val\": 15.261278957800723,\n",
      "      \"mae_test\": 15.212667070481631,\n",
      "      \"pct_zero_test\": 23.869455605451822,\n",
      "      \"pred_min_test\": -15.636086723517685,\n",
      "      \"pred_max_test\": 31.357097696169706\n",
      "    },\n",
      "    \"env\": {\n",
      "      \"sklearn\": \"1.7.2\",\n",
      "      \"numpy\": \"2.2.6\",\n",
      "      \"pandas\": \"2.3.3\"\n",
      "    }\n",
      "  },\n",
      "  \"clip_0_100\": {\n",
      "    \"clip_preds\": true,\n",
      "    \"model_params\": {\n",
      "      \"alpha\": 0.0001,\n",
      "      \"epsilon\": 1.35,\n",
      "      \"fit_intercept\": true,\n",
      "      \"max_iter\": 100,\n",
      "      \"tol\": 1e-05,\n",
      "      \"warm_start\": false\n",
      "    },\n",
      "    \"n_features_numeric\": 15,\n",
      "    \"numeric_cols\": [\n",
      "      \"album_release_year\",\n",
      "      \"acousticness\",\n",
      "      \"danceability\",\n",
      "      \"duration_ms\",\n",
      "      \"energy\",\n",
      "      \"instrumentalness\",\n",
      "      \"key\",\n",
      "      \"liveness\",\n",
      "      \"loudness\",\n",
      "      \"mode\",\n",
      "      \"speechiness\",\n",
      "      \"tempo\",\n",
      "      \"time_signature\",\n",
      "      \"total_available_markets\",\n",
      "      \"valence\"\n",
      "    ],\n",
      "    \"hashes\": {\n",
      "      \"X_train_numeric_hash\": \"13046769200431973106\",\n",
      "      \"X_val_numeric_hash\": \"14649397147825154895\",\n",
      "      \"X_test_numeric_hash\": \"3358416359012077377\",\n",
      "      \"y_train_hash\": \"2450748903912899776\",\n",
      "      \"y_val_hash\": \"17415832452201736670\",\n",
      "      \"y_test_hash\": \"15508359024874058208\",\n",
      "      \"idx_train_hash\": \"17745924961938407296\",\n",
      "      \"idx_val_hash\": \"6924369080184951392\",\n",
      "      \"idx_test_hash\": \"1539615605918014350\"\n",
      "    },\n",
      "    \"metrics\": {\n",
      "      \"mae_val\": 15.24767046460925,\n",
      "      \"mae_test\": 15.199969085479593,\n",
      "      \"pct_zero_test\": 23.869455605451822,\n",
      "      \"pred_min_test\": 0.0,\n",
      "      \"pred_max_test\": 31.357097696169706\n",
      "    },\n",
      "    \"env\": {\n",
      "      \"sklearn\": \"1.7.2\",\n",
      "      \"numpy\": \"2.2.6\",\n",
      "      \"pandas\": \"2.3.3\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Config saved to: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/models/cycle_02/audit_huber15_clip_sanitycheck.json\n"
     ]
    }
   ],
   "source": [
    "report_no_clip = huber_baseline_report(\n",
    "    X_train_t, y_train_t, X_val_t, y_val_t, X_test_t, y_test_t,\n",
    "    year_col=\"album_release_year\", lambda_recency=0.05, current_year=2021, clip_preds=False\n",
    ")\n",
    "report_clip = huber_baseline_report(\n",
    "    X_train_t, y_train_t, X_val_t, y_val_t, X_test_t, y_test_t,\n",
    "    year_col=\"album_release_year\", lambda_recency=0.05, current_year=2021, clip_preds=True\n",
    ")\n",
    "\n",
    "bundle = {\"no_clip\": report_no_clip, \"clip_0_100\": report_clip}\n",
    "print(json.dumps(bundle, indent=2))\n",
    "\n",
    "# Save audit artifact \n",
    "config_path = MODELS_DIR / \"audit_huber15_clip_sanitycheck.json\"\n",
    "config_path.write_text(json.dumps(frozen_config, indent=2))\n",
    "print(f\"Config saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75c7780a-6971-4d6d-bd04-cfefb2cde559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:04:30.312462Z",
     "iopub.status.busy": "2026-02-12T20:04:30.301794Z",
     "iopub.status.idle": "2026-02-12T20:04:34.630532Z",
     "shell.execute_reply": "2026-02-12T20:04:34.619157Z",
     "shell.execute_reply.started": "2026-02-12T20:04:30.311651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pack:  /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/models/cycle_02/baseline_huber15_pack.npz (sha256=0de188ce97b5...)\n",
      "Saved audit: /mnt/c/Users/Daniel/OneDrive/Documentos/_Cursos/Outros/PopForecast/models/cycle_02/baseline_huber15_audit_v3_from_pack.json\n",
      "Audit v3 is PACK-derived and should match deterministically in Notebook 04.\n"
     ]
    }
   ],
   "source": [
    "# --- Canonical Baseline Huber-15 Pack + Audit v3 (PACK IS SOURCE OF TRUTH) ---\n",
    "# This cell guarantees:\n",
    "#  - the .npz pack is deterministic (same bytes given same inputs),\n",
    "#  - the audit is derived ONLY from the pack arrays (so hashes cannot drift),\n",
    "#  - optional \"repack\" mode to canonicalize an existing pack without touching raw data.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Config (must match frozen)\n",
    "# -----------------------------\n",
    "BASELINE_PROTOCOL_NAME = \"Baseline_Huber15_recency0p05_medfill\"\n",
    "RECENCY_LAMBDA = 0.05\n",
    "CURRENT_YEAR = 2021\n",
    "\n",
    "NUMERIC_COLS_15: List[str] = [\n",
    "    \"album_release_year\",\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"duration_ms\",\n",
    "    \"energy\",\n",
    "    \"instrumentalness\",\n",
    "    \"key\",\n",
    "    \"liveness\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"tempo\",\n",
    "    \"time_signature\",\n",
    "    \"total_available_markets\",\n",
    "    \"valence\",\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Hash helpers (single spec)\n",
    "# -----------------------------\n",
    "def _sha256_bytes(data: bytes) -> str:\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "\n",
    "def _hash_ndarray(arr: np.ndarray) -> str:\n",
    "    # One authoritative hashing spec for ALL arrays (X/y/idx/w/cols/stats)\n",
    "    arr_c = np.ascontiguousarray(arr)\n",
    "    payload = (\n",
    "        str(arr_c.shape).encode()\n",
    "        + str(arr_c.dtype).encode()\n",
    "        + arr_c.tobytes(order=\"C\")\n",
    "    )\n",
    "    return _sha256_bytes(payload)\n",
    "\n",
    "\n",
    "def _file_sha256(path: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def _compute_recency_weights(\n",
    "    release_year: pd.Series, current_year: int, lambda_: float\n",
    ") -> np.ndarray:\n",
    "    year = pd.to_numeric(release_year, errors=\"coerce\").fillna(current_year).astype(float)\n",
    "    age = (current_year - year).clip(lower=0.0)\n",
    "    return np.exp(-lambda_ * age.to_numpy(dtype=float)).astype(np.float64)\n",
    "\n",
    "\n",
    "def _select_15_strict(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    missing = [c for c in NUMERIC_COLS_15 if c not in df.columns]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing expected baseline columns: {missing}\")\n",
    "    out = df.loc[:, NUMERIC_COLS_15].copy()\n",
    "\n",
    "    # Critical: force deterministic numeric dtypes (prevents pandas nullable/object surprises)\n",
    "    for col in out.columns:\n",
    "        out[col] = pd.to_numeric(out[col], errors=\"coerce\").astype(np.float64)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build pack from in-memory splits (authoritative)\n",
    "# -----------------------------\n",
    "def build_huber15_pack_from_splits(\n",
    "    X_train_t: pd.DataFrame,\n",
    "    X_val_t: pd.DataFrame,\n",
    "    X_test_t: pd.DataFrame,\n",
    "    y_train_t: pd.Series,\n",
    "    y_val_t: pd.Series,\n",
    "    y_test_t: pd.Series,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    Xtr = _select_15_strict(X_train_t)\n",
    "    Xva = _select_15_strict(X_val_t)\n",
    "    Xte = _select_15_strict(X_test_t)\n",
    "\n",
    "    # y: keep purely positional arrays in the pack (no index ambiguity)\n",
    "    ytr = pd.to_numeric(pd.Series(y_train_t), errors=\"coerce\").astype(np.float64).to_numpy()\n",
    "    yva = pd.to_numeric(pd.Series(y_val_t), errors=\"coerce\").astype(np.float64).to_numpy()\n",
    "    yte = pd.to_numeric(pd.Series(y_test_t), errors=\"coerce\").astype(np.float64).to_numpy()\n",
    "\n",
    "    # idx: store raw split indices as int64 arrays (deterministic)\n",
    "    idx_train = np.asarray(Xtr.index.to_numpy(), dtype=np.int64)\n",
    "    idx_val = np.asarray(Xva.index.to_numpy(), dtype=np.int64)\n",
    "    idx_test = np.asarray(Xte.index.to_numpy(), dtype=np.int64)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    Xtr_imp = imputer.fit_transform(Xtr).astype(np.float64, copy=False)\n",
    "    Xva_imp = imputer.transform(Xva).astype(np.float64, copy=False)\n",
    "    Xte_imp = imputer.transform(Xte).astype(np.float64, copy=False)\n",
    "\n",
    "    w_train = _compute_recency_weights(\n",
    "        release_year=pd.Series(Xtr[\"album_release_year\"]),\n",
    "        current_year=CURRENT_YEAR,\n",
    "        lambda_=RECENCY_LAMBDA,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"X_train_imputed\": np.ascontiguousarray(Xtr_imp),\n",
    "        \"X_val_imputed\": np.ascontiguousarray(Xva_imp),\n",
    "        \"X_test_imputed\": np.ascontiguousarray(Xte_imp),\n",
    "        \"y_train\": np.ascontiguousarray(ytr),\n",
    "        \"y_val\": np.ascontiguousarray(yva),\n",
    "        \"y_test\": np.ascontiguousarray(yte),\n",
    "        \"w_train\": np.ascontiguousarray(w_train),\n",
    "        \"idx_train\": np.ascontiguousarray(idx_train),\n",
    "        \"idx_val\": np.ascontiguousarray(idx_val),\n",
    "        \"idx_test\": np.ascontiguousarray(idx_test),\n",
    "        \"cols\": np.asarray(NUMERIC_COLS_15, dtype=object),\n",
    "        \"imputer_statistics_\": np.ascontiguousarray(imputer.statistics_.astype(np.float64)),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Audit v3 derived ONLY from pack arrays\n",
    "# -----------------------------\n",
    "def build_audit_v3_from_pack_arrays(\n",
    "    pack_arrays: Dict[str, np.ndarray],\n",
    "    pack_npz_sha256: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    keys_expected = [\n",
    "        \"X_train_imputed\", \"X_val_imputed\", \"X_test_imputed\",\n",
    "        \"y_train\", \"y_val\", \"y_test\",\n",
    "        \"w_train\",\n",
    "        \"idx_train\", \"idx_val\", \"idx_test\",\n",
    "        \"cols\", \"imputer_statistics_\",\n",
    "    ]\n",
    "    missing = [k for k in keys_expected if k not in pack_arrays]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Pack arrays missing keys: {missing}\")\n",
    "\n",
    "    hashes = {k: _hash_ndarray(pack_arrays[k]) for k in keys_expected}\n",
    "\n",
    "    return {\n",
    "        \"baseline_protocol\": {\n",
    "            \"name\": BASELINE_PROTOCOL_NAME,\n",
    "            \"numeric_cols_15\": NUMERIC_COLS_15,\n",
    "            \"recency_lambda\": RECENCY_LAMBDA,\n",
    "            \"current_year\": CURRENT_YEAR,\n",
    "            \"imputer\": {\"strategy\": \"median\", \"fit_scope\": \"train_only\"},\n",
    "            \"hash_spec_single\": \"sha256(shape + dtype + tobytes(order='C')) applied to ALL arrays in the pack\",\n",
    "        },\n",
    "        \"pack_npz_sha256\": pack_npz_sha256,\n",
    "        \"shapes\": {k: list(pack_arrays[k].shape) for k in keys_expected},\n",
    "        \"dtypes\": {k: str(pack_arrays[k].dtype) for k in keys_expected},\n",
    "        \"hashes_from_pack_only\": hashes,\n",
    "        \"notes\": [\n",
    "            \"This audit is authoritative because it is derived only from the NPZ pack arrays.\",\n",
    "            \"Notebook 04 should validate by loading the NPZ, recomputing hashes with the same spec, and comparing to this JSON.\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Persist: pack + audit v3 (and optional repack)\n",
    "# -----------------------------\n",
    "MODELS_DIR = Path(MODELS_DIR) if \"MODELS_DIR\" in globals() else Path(\"models/cycle_02\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PACK_PATH = MODELS_DIR / \"baseline_huber15_pack.npz\"\n",
    "AUDIT_V3_PATH = MODELS_DIR / \"baseline_huber15_audit_v3_from_pack.json\"\n",
    "\n",
    "REPACK_EXISTING = True  # set True to canonicalize an existing pack without raw data\n",
    "\n",
    "if REPACK_EXISTING:\n",
    "    loaded = dict(np.load(PACK_PATH, allow_pickle=True))\n",
    "    # Canonicalize dtypes/contiguity (optional; makes future hashing stable)\n",
    "    pack_arrays = {\n",
    "        k: np.ascontiguousarray(loaded[k])\n",
    "        for k in loaded.keys()\n",
    "    }\n",
    "else:\n",
    "    required = [\"X_train_t\", \"X_val_t\", \"X_test_t\", \"y_train_t\", \"y_val_t\", \"y_test_t\"]\n",
    "    missing = [v for v in required if v not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing variables in notebook scope: {missing}\")\n",
    "\n",
    "    pack_arrays = build_huber15_pack_from_splits(\n",
    "        X_train_t=X_train_t,\n",
    "        X_val_t=X_val_t,\n",
    "        X_test_t=X_test_t,\n",
    "        y_train_t=y_train_t,\n",
    "        y_val_t=y_val_t,\n",
    "        y_test_t=y_test_t,\n",
    "    )\n",
    "\n",
    "    np.savez_compressed(PACK_PATH, **pack_arrays)\n",
    "\n",
    "pack_sha = _file_sha256(PACK_PATH)\n",
    "audit_v3 = build_audit_v3_from_pack_arrays(pack_arrays, pack_npz_sha256=pack_sha)\n",
    "AUDIT_V3_PATH.write_text(json.dumps(audit_v3, indent=2))\n",
    "\n",
    "print(f\"Saved pack:  {PACK_PATH} (sha256={pack_sha[:12]}...)\")\n",
    "print(f\"Saved audit: {AUDIT_V3_PATH}\")\n",
    "print(\"Audit v3 is PACK-derived and should match deterministically in Notebook 04.\")\n",
    "\n",
    "# json_path.write_text(json.dumps(audit, indent=2))\n",
    "# print(f\"Saved baseline pack: {npz_path}\")\n",
    "# print(f\"Saved baseline audit: {json_path}\")\n",
    "# print(\"Baseline pack ready for Notebook 04 (deterministic).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770411b-ad3d-4ca6-96e4-21162b624ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
