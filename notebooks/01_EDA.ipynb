{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0e186f-e10b-4d2c-9c98-b088e7175195",
   "metadata": {},
   "source": [
    "# 0 - PopForecast — EDA (Cycle 1 / MVP)\n",
    "\n",
    "This notebook performs a lightweight exploratory data analysis (EDA) to support the Cycle 1 MVP.\n",
    "Goals: validate the target (`song_popularity`), understand basic data quality issues, and define a first feature set.\n",
    "We will explicitly identify potential leakage/proxy columns and decide a split strategy (temporal vs random) and baseline metrics.\n",
    "Engineering-heavy transformations will be implemented later in the project scripts, not in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95ca4b-e1f6-45a6-b836-c9b7b49cc8b4",
   "metadata": {},
   "source": [
    "# 1 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8ce89-8047-49ea-9eb7-81feffdc80ca",
   "metadata": {},
   "source": [
    "## 1.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc52c0-9050-44b2-b9c6-9ac9dc3235cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f82b8a-14ac-4e58-886d-9028731dc39b",
   "metadata": {},
   "source": [
    "## 1.2 - Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3470816-3e29-4a4f-99cc-ac6a3895890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility (use only when sampling / splitting inside the notebook) ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Pandas display ---\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_colwidth\", 60)\n",
    "pd.set_option(\"display.float_format\", \"{:,.4f}\".format)\n",
    "\n",
    "# --- Matplotlib defaults (lightweight) ---\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152dd2e-28ff-4108-8ca7-4e3ecc03a02a",
   "metadata": {},
   "source": [
    "## 1.3 - Project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68e113-435d-4399-804c-bd4a61ee4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_RAW_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"spotify_tracks_metadata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9179ff-7cb0-46d5-bb9c-47a9dfe1f04e",
   "metadata": {},
   "source": [
    "# 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f742d3-b994-4712-ae04-26e3e7782fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(DATA_RAW_PATH)\n",
    "display(data_raw.head())\n",
    "print(f'Raw Dataset Shape: {data_raw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad0080-ca88-43e8-ba8c-b1d2a15c7a16",
   "metadata": {},
   "source": [
    "# 3. Schema Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33faedf-df80-4f7a-8d82-3041b27ad215",
   "metadata": {},
   "source": [
    "## 3.1 - Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c549e1-4b3f-473c-be7f-137c79c6285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818c86c-9830-4f71-a6f4-8789093a2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.memory_usage(deep=True).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef1993-1cc4-42c7-8f96-28dbba282bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82a69d-e1b1-41a7-942a-a0b5ddfe07ed",
   "metadata": {},
   "source": [
    "#### Data footprint and schema at a glance\n",
    "\n",
    "The dataset contains **439,893 rows and 26 columns** (~**84.3 MB** in memory). Most predictive signals for the MVP are already in **numeric form** (15 `float64` + 3 `int64` + 1 `bool`), which is a good fit for a first baseline model without heavy preprocessing.\n",
    "\n",
    "Two immediate data-quality flags appear in the release-date fields: `album_release_year` has **203 missing values**, and `album_release_month` has **19,334 missing values**. This suggests the release date is not consistently decomposed into year/month for all records and will require a small, explicit handling rule before using a **temporal split**.\n",
    "\n",
    "Memory usage is dominated by **string columns**, especially URL-like fields (`analysis_url`, `track_href`, `uri`) and text identifiers (`song_name`, `artist_name`, `spotify_id`, `album_release_date`). This supports an MVP strategy of keeping a **lightweight modeling view** (target + numeric features + minimal date fields) while preserving the full dataset only for **UX and diagnostics** (e.g., reporting top errors by song/artist).\n",
    "\n",
    "A quick cardinality check confirms that several fields behave like identifiers: `spotify_id` and the URL-like columns (`analysis_url`, `track_href`, `uri`) are almost entirely unique, which reinforces that they should be excluded from the MVP feature set. The target `song_popularity` is also discrete (98 unique values), so model evaluation may exhibit ties and step-like behavior. Finally, some numeric columns are low-cardinality categorical variables (`key` has 12 values, `mode` has 2, `time_signature` has 5), which is worth noting for later feature encoding decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5b07e-bb65-4349-b2b3-190ea8671a64",
   "metadata": {},
   "source": [
    "## 3.2 - Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281ad30-6c68-45b6-883e-f3c07309c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462fd37-755e-48d2-a718-bcbddad9342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.describe(include=[\"object\", 'bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710dc0c7-d070-42ea-b2cb-1c652c3e796b",
   "metadata": {},
   "source": [
    "# 4. Data Quality Checks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036618b-a011-4f20-bc2a-90480122722e",
   "metadata": {},
   "source": [
    "## 4.1 - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2e697-8cdf-49a1-899e-f3a5712c42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd1d31-9d7d-4ed6-a50e-63f925947757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.duplicated(subset=[\"spotify_id\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bcf49-8fd1-4c68-aad9-71b3381a59d6",
   "metadata": {},
   "source": [
    "No full-row duplicates were found in the dataset. However, there are **4 cases** where the same `spotify_id` appears more than once, indicating repeated track IDs with minor metadata differences (e.g., alternate titles, casing differences in `artist_name`, or additional tags such as “Trending Track”). Because the MVP baseline assumes **one row per track**, we apply a deterministic deduplication rule: **for each duplicated `spotify_id`, keep the record with the highest `song_popularity`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a9141-349e-4f29-b36d-569242cd2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_spotify_id = data_raw[data_raw.duplicated(subset=[\"spotify_id\"], keep=False)].sort_values(\"spotify_id\")\n",
    "dup_spotify_id[[\"spotify_id\", \"song_name\", \"artist_name\", \"album_release_date\", \"song_popularity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3775da7-f732-4d0c-b038-d9bac79a0503",
   "metadata": {},
   "source": [
    "This choice is pragmatic for Cycle 1: the number of duplicated IDs is negligible relative to the dataset size, and the rule prevents inconsistent targets for the same track ID (e.g., a record with `song_popularity = 0` alongside another with a higher value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8f0dd-2062-4365-b7c6-674043ea6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_raw.copy()\n",
    "data_clean = (\n",
    "    data_clean.sort_values(\"song_popularity\", ascending=False)\n",
    "    .drop_duplicates(subset=[\"spotify_id\"], keep=\"first\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "data_clean.duplicated(subset=[\"spotify_id\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf810366-6667-44e1-a70a-fa890c7bfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null spotify_id values:\", data_clean[\"spotify_id\"].isna().sum())\n",
    "print(\"Duplicated spotify_id values:\", data_clean[\"spotify_id\"].duplicated().sum())\n",
    "print(\"Is spotify_id unique?\", data_clean[\"spotify_id\"].nunique() == len(data_clean))\n",
    "print(\"Dataset shape:\", data_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4775e92-c595-4678-a1e9-62b6deb85768",
   "metadata": {},
   "source": [
    "## 4.2 - Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd9664-fcf7-43cd-8351-5b90c4da3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = data_clean.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (data_clean.isna().mean()*100).sort_values(ascending=False)\n",
    "\n",
    "missing_summary = pd.DataFrame(\n",
    "    {\"missing_count\": missing_counts, \"missing_%\": missing_pct}\n",
    ")\n",
    "\n",
    "missing_summary.query(\"missing_count > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d5a93-9241-456b-9634-c9003ff57c31",
   "metadata": {},
   "source": [
    "Missingness is almost entirely concentrated in release-date fields. The only meaningful data-quality risk for the MVP is date normalization, not audio-feature completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f93103e-cd2f-46d3-a3c4-e19e6443c7c3",
   "metadata": {},
   "source": [
    "### 4.2.1 - album_release_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d41f6-5672-484f-8fdb-679e8a239839",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.loc[data_clean[\"album_release_month\"].isna(), \"album_release_date\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a0c6c-b7bd-4ebd-8fc0-be6c6b4268b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.query('album_release_month.isna()').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2194f0-2aac-48fb-b13d-594aff0c85fb",
   "metadata": {},
   "source": [
    "#### Release date granularity and month missingness\n",
    "\n",
    "The missingness in `album_release_month` is largely explained by the granularity of `album_release_date`. For many records, `album_release_date` is provided as a **year-only string** (e.g., \"2010\", \"2011\"), which does not contain month information. In these cases, the month is not truly “missing” but **unknown by construction**.\n",
    "\n",
    "For the Cycle 1 MVP, we avoid imputing a synthetic month value. Instead, we rely primarily on `album_release_year` for temporal reasoning (including potential temporal splits). `album_release_month` can be revisited later, either by encoding an explicit “unknown month” category or by restricting its use to records where a month is explicitly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04061b3-d4ce-4ae9-a31d-608041224e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.drop(columns=[\"album_release_month\"])\n",
    "\n",
    "missing_counts = data_clean.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (data_clean.isna().mean()*100).sort_values(ascending=False)\n",
    "\n",
    "missing_summary = pd.DataFrame(\n",
    "    {\"missing_count\": missing_counts, \"missing_%\": missing_pct}\n",
    ")\n",
    "\n",
    "missing_summary.query(\"missing_count > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a48212-5146-4aa1-9f4f-7a934bbd4883",
   "metadata": {},
   "source": [
    "### 4.2.2 - Release date consistency checks (album_release_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8d3f4-bc94-4ec9-8273-3ce14fdf03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date = data_clean[\"album_release_date\"].astype(str)\n",
    "\n",
    "is_yyyy_mm_dd = release_date.str.match(r\"^\\d{4}-\\d{2}-\\d{2}$\")\n",
    "is_yyyy_mm = release_date.str.match(r\"^\\d{4}-\\d{2}$\")\n",
    "is_yyyy = release_date.str.match(r\"^\\d{4}$\")\n",
    "is_0000 = release_date.eq(\"0000\")\n",
    "\n",
    "pd.Series(\n",
    "    {\n",
    "        \"YYYY-MM-DD\": int(is_yyyy_mm_dd.sum()),\n",
    "        \"YYYY-MM\": int(is_yyyy_mm.sum()),\n",
    "        \"0000\": int(is_0000.sum()),\n",
    "        \"other\": int((~(is_yyyy_mm_dd | is_yyyy_mm | is_0000)).sum()),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608685f-76a0-4bb9-bf9d-60ac42a53c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year where the format provides it\n",
    "year_from_date = pd.to_numeric(release_date.str.slice(0, 4), errors=\"coerce\")\n",
    "\n",
    "data_clean[\"album_release_year\"] = data_clean[\"album_release_year\"].fillna(year_from_date)\n",
    "\n",
    "# Invalidate placeholders like \"0000\"\n",
    "data_clean.loc[is_0000, \"album_release_year\"] = np.nan\n",
    "\n",
    "# Drop invalid rows (Cycle 1 MVP)\n",
    "data_clean = data_clean.dropna(subset=[\"album_release_year\"]).reset_index(drop=True)\n",
    "\n",
    "# Optionally drop the raw date string to reduce memory footprint\n",
    "data_clean = data_clean.drop(columns=[\"album_release_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea13ccc-b813-4bbb-a09d-6d7372baf6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in album_release_year\n",
    "missing_years = data_clean[\"album_release_year\"].isna().sum()\n",
    "print(f\"Missing album_release_year values: {missing_years}\")\n",
    "\n",
    "# Count invalid placeholder values (year == 0)\n",
    "invalid_years = (data_clean[\"album_release_year\"] == 0).sum()\n",
    "print(f\"Invalid '0' album_release_year values: {invalid_years}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d8320-0366-491c-a1b3-5871ea7e697c",
   "metadata": {},
   "source": [
    "#### Release date consistency checks and MVP decisions\n",
    "\n",
    "`album_release_date` is non-null for all records, but it mixes multiple granularities and placeholders. Based on format counts, we observe:\n",
    "- **420,555** records with full dates (`YYYY-MM-DD`)\n",
    "- **203** records with year-month only (`YYYY-MM`)\n",
    "- **19,107** records with year-only strings (`YYYY`)\n",
    "- **24** records with an invalid placeholder (`0000`)\n",
    "\n",
    "This explains the missingness in the derived columns:\n",
    "- The **203 `YYYY-MM`** entries align with the **203 missing values in `album_release_year`**: the year exists in `album_release_date`, but the dataset does not consistently populate the derived year field for this format.\n",
    "- The missingness in `album_release_month` is largely driven by **year-only (`YYYY`)** entries. In these cases, month information is not truly “missing” but **unknown by construction**.\n",
    "\n",
    "**Cycle 1 (MVP) policy**:\n",
    "1) Treat `album_release_date` as the source of truth for temporal information.\n",
    "2) Normalize `album_release_year` deterministically by extracting the year from `album_release_date` whenever the format provides it (`YYYY-MM-DD`, `YYYY-MM`, `YYYY`), filling any missing `album_release_year` values.\n",
    "3) Do **not** impute a synthetic month for `YYYY` entries; `album_release_month` is excluded from the MVP feature set (and can be revisited later with an explicit “unknown month” encoding if needed).\n",
    "4) Treat `album_release_date == \"0000\"` as invalid; set the derived year to missing and drop these rows for the MVP (the volume is negligible).\n",
    "5) After normalization, drop `album_release_date` from the modeling dataset to reduce memory footprint and avoid carrying mixed-format strings into the pipeline (raw text/metadata remains available in `data_raw` for UX/diagnostics).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9d18b-a18f-4168-bb17-e02967e07364",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = data_clean.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (data_clean.isna().mean()*100).sort_values(ascending=False)\n",
    "\n",
    "missing_summary = pd.DataFrame(\n",
    "    {\"missing_count\": missing_counts, \"missing_%\": missing_pct}\n",
    ")\n",
    "\n",
    "missing_summary.query(\"missing_count > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e742c-0c15-4fd1-81ee-edde9d9be94e",
   "metadata": {},
   "source": [
    "After applying the MVP cleaning rules for release dates, the only remaining missing values are in text metadata: `artist_name` (9 rows) and `song_name` (3 rows). These fields are not used as predictive features in the Cycle 1 baseline model, so imputing or dropping them would not improve modeling quality and would add unnecessary manipulation at this stage.\n",
    "\n",
    "We'll keep these rare missing values unchanged for now. They will only be addressed when we implement the UX/reporting layer (e.g., filling with explicit placeholders such as “Unknown artist/title” for display purposes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7c626-95a1-4d27-abd8-dc580da21c0a",
   "metadata": {},
   "source": [
    "## 4.3 - Cardinality snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9789f-98b7-4675-89e5-e367a1c564e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardinality snapshot: focus on object/string-like columns and known categoricals\n",
    "n_rows = len(data_clean)\n",
    "\n",
    "cardinality = (\n",
    "    data_clean.nunique(dropna=False)\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name=\"n_unique\")\n",
    ")\n",
    "\n",
    "cardinality[\"unique_ratio\"] = cardinality[\"n_unique\"] / n_rows\n",
    "\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cf831-cc39-429a-92c8-7784c080193b",
   "metadata": {},
   "source": [
    "Cardinality helps classify columns by their role in the dataset. Several fields behave like identifiers: `spotify_id`, URL-like columns (`analysis_url`, `track_href`, `uri`), and `Unnamed: 0` have a ~1.0 unique ratio, indicating near-unique values per row. These columns do not generalize and are excluded from the MVP feature set (with `spotify_id` kept only as a technical key for diagnostics).\n",
    "\n",
    "Text metadata (`song_name`, `artist_name`) also has high cardinality and is not suitable for naive one-hot encoding in the MVP. We keep it for UX and error analysis but exclude it from baseline modeling.\n",
    "\n",
    "Audio features and other numeric fields show appropriate cardinality for modeling. Low-cardinality variables such as `key` (12 values), `mode` (2), `time_signature` (5), and `song_explicit` (2) are treated as categorical/discrete signals, while continuous features (e.g., `tempo`, `loudness`, `duration_ms`) remain numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d132179-c1c9-4f20-9515-ce07e4fae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_clean.drop(['Unnamed: 0', 'spotify_id', 'analysis_url', 'track_href', 'uri', 'song_name', 'artist_name'], axis=1)\n",
    "data_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2834a27-8bc4-4eeb-a132-60a1af99fece",
   "metadata": {},
   "source": [
    "<a id=\"sec-44-handling\"></a>\n",
    "## 4.4 - Handling suspicious release years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b91fb-ab3b-469e-a379-16cbbb8b7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Mark 1900 as suspect placeholder and set to missing (do not drop rows)\n",
    "suspect_1900 = data_clean[\"album_release_year\"].eq(1900)\n",
    "data_clean.loc[suspect_1900, \"album_release_year\"] = np.nan\n",
    "\n",
    "# 2) (Optional) also invalidate extreme years, if any slipped through\n",
    "max_year = int(np.nanmax(data_clean[\"album_release_year\"]))\n",
    "extreme_invalid = (data_clean[\"album_release_year\"] < 1900) | (data_clean[\"album_release_year\"] > max_year)\n",
    "data_clean.loc[extreme_invalid, \"album_release_year\"] = np.nan\n",
    "\n",
    "# 3) Flag for downstream models\n",
    "data_clean[\"release_year_missing_or_suspect\"] = data_clean[\"album_release_year\"].isna()\n",
    "\n",
    "int(suspect_1900.sum()), int(extreme_invalid.sum()), data_clean[\"release_year_missing_or_suspect\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a6862-bae0-4b23-be6c-0c9953a4be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451fd88-7227-4ba5-83d9-f5fdbda1816e",
   "metadata": {},
   "source": [
    "We observed that a small set of tracks has `album_release_year == 1900`, which is likely a placeholder value rather than a true release year. Since `album_release_year` is used as a model feature, we avoid injecting an artificial signal by converting these placeholder values to missing (`NaN`). We also invalidate clearly impossible years (e.g., < 1000).\n",
    "\n",
    "To preserve information about uncertainty, we add `release_year_missing_or_suspect`, a binary flag indicating that the original year was missing or invalid. The numeric year is then median-imputed downstream in the modeling pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aca412-d47e-4fae-8ed8-071b5fd030fb",
   "metadata": {},
   "source": [
    "## 4.5 - Dtype normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26b6ed-0205-43ba-9fa7-edc5ba004dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve dtypes for clarity and memory (MVP)\n",
    "\n",
    "# 1) Integer-like columns (currently float64)\n",
    "int_like_cols = {\n",
    "    \"album_release_year\": \"Int16\",\n",
    "    \"key\": \"int8\",\n",
    "    \"mode\": \"int8\",\n",
    "    \"time_signature\": \"int8\",\n",
    "}\n",
    "\n",
    "for col, dtype in int_like_cols.items():\n",
    "    if col in data_clean.columns:\n",
    "        data_clean[col] = data_clean[col].round().astype(dtype)\n",
    "\n",
    "# 2) Other integer columns\n",
    "data_clean[\"song_popularity\"] = data_clean[\"song_popularity\"].astype(\"int16\")\n",
    "data_clean[\"total_available_markets\"] = data_clean[\"total_available_markets\"].astype(\"int16\")\n",
    "\n",
    "# 3) Continuous audio features -> float32\n",
    "float_cols = [\n",
    "    \"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\",\n",
    "    \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\",\n",
    "]\n",
    "data_clean[float_cols] = data_clean[float_cols].astype(\"float32\")\n",
    "\n",
    "data_clean.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b5cfc-af0d-4d00-9674-1330ff7531f3",
   "metadata": {},
   "source": [
    "We normalize dtypes to better reflect the semantics of each column and reduce memory usage. Integer-like fields (e.g., `album_release_year`, `key, mode`, `time_signature`) are converted from `float64` to compact integer types or their nullable equivalents, depending on whether the column may contain missing values after cleaning. Continuous audio features are downcast to `float32`, which is sufficient for baseline modeling while improving efficiency. This step is not feature engineering; it is a schema cleanup to avoid silent type-related issues downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4167d-a688-4a24-b5d0-bdc1fe7b2726",
   "metadata": {},
   "source": [
    "# 5. Target (FACT) Understanding: `song_popularity`\n",
    "\n",
    "For the Cycle 1 MVP, the supervised learning target is `song_popularity`, a numeric score that represents track popularity. In this EDA step, we validate basic properties of the target: range, uniqueness, missingness, and distribution shape. This helps detect obvious issues (e.g., invalid values, heavy concentration, or unexpected gaps) before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6d108-35c6-468f-85e9-3537a34889eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"song_popularity\"\n",
    "\n",
    "# Basic sanity checks\n",
    "target_summary = {\n",
    "    \"n_rows\": int(len(data_clean)),\n",
    "    \"n_missing\": int(data_clean[target_col].isna().sum()),\n",
    "    \"min\": int(data_clean[target_col].min()),\n",
    "    \"max\": int(data_clean[target_col].max()),\n",
    "    \"n_unique\": int(data_clean[target_col].nunique()),\n",
    "}\n",
    "pd.DataFrame([target_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35627943-7933-41fb-a210-d45f384f365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Histogram\n",
    "sns.histplot(\n",
    "    data=data_clean,\n",
    "    x=target_col,\n",
    "    bins=50,\n",
    "    kde=False,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Target distribution: song_popularity\")\n",
    "axes[0].set_ylabel(\"count\")\n",
    "\n",
    "# Boxplot\n",
    "sns.boxplot(\n",
    "    data=data_clean,\n",
    "    x=target_col,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Target boxplot: song_popularity\")\n",
    "axes[1].set_xlabel(target_col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77712a9b-e886-4b31-9189-8d109a7e0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentration check: counts by value (useful since the target is discrete)\n",
    "pop_counts = data_clean[target_col].value_counts().sort_index()\n",
    "pop_counts.to_frame(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e892c-3394-46c4-bb9a-60b6ace3bf96",
   "metadata": {},
   "source": [
    "### Notes on target distribution (MVP)\n",
    "\n",
    "- **Range & validity:** `song_popularity` is fully populated (`n_missing = 0`) and stays within the expected **0–100** interval (`min = 0`, `max = 100`), suggesting no obvious invalid target values in the current cleaned dataset.\n",
    "\n",
    "- **Shape (highly skewed):** The distribution is strongly right-skewed, with a **very large mass at 0** (58,948 tracks) and steadily decreasing counts as popularity increases. This indicates the dataset is dominated by low-popularity tracks, while highly popular tracks are rare.\n",
    "\n",
    "- **Discrete / coarse-grained target:** The target has **98 unique values**, confirming it is an integer-like, discretized score rather than a continuous measurement. This is fine for a Cycle 1 regression baseline, but it also leaves room for later reframing (e.g., ordinal modeling or binning) if prediction stability becomes an issue.\n",
    "\n",
    "- **Extreme values are extremely sparse:** Very high popularity values are almost absent (e.g., 95: 1 record, 96: 2, 100: 1). Models and evaluation should therefore be robust to heavy imbalance in the upper tail; improvements in the high-popularity region may be difficult to learn and to validate reliably with standard metrics alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da999a3-24a3-4684-bacf-d08a78c5d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_clean[\"song_popularity\"]\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"value\": {\n",
    "        \"zero_rate\": float((target == 0).mean()),\n",
    "        \"q25\": target.quantile(0.25),\n",
    "        \"median\": target.quantile(0.50),\n",
    "        \"q75\": target.quantile(0.75),\n",
    "    }\n",
    "})\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6376a93-07cc-4670-956f-bfe36149fc21",
   "metadata": {},
   "source": [
    "### Additional target notes (zero-inflation & robust baseline metric)\n",
    "\n",
    "The target `song_popularity` is a bounded discrete score in [0, 100] with a non‑trivial point mass at zero (~13.4%). This structure introduces two practical risks for a Cycle 1 baseline:\n",
    "\n",
    "1. **Risk of “lazy” predictions near zero.**  \n",
    "   With many zeros and a strong concentration in the lower tail, a model optimized for average error can achieve a deceptively good MAE by predicting small values for most tracks, under‑serving higher‑popularity cases.\n",
    "\n",
    "2. **Boundedness + skew tension with standard regression framing.**  \n",
    "   Classical linear regression is not designed for bounded outcomes and can yield invalid predictions (<0 or >100). Even flexible ML regressors benefit from evaluation strategies that acknowledge the truncated scale.\n",
    "\n",
    "Regression theory remains useful because it provides the diagnostic lens for assessing whether zeros behave like a separate regime and for motivating **two‑part reasoning**: \n",
    "> $ \\text{i. model the probability of structural/excess zeros via a logistic component, and  } $  \n",
    "> $ \\text{ii. model the magnitude among positive outcomes via a second component. } $  \n",
    "\n",
    "This logic appears in zero‑inflated and hurdle models (Mullahy, 1986; Cameron & Trivedi, 2013) and is also discussed in applied form in Fávero et al. (2023), who emphasize the practical importance of distinguishing structural zeros and evaluating whether a single‑equation model is adequate.\n",
    "\n",
    "For Cycle 1, we adopt a pragmatic stance:\n",
    "* Use a **single baseline regressor** for simplicity.  \n",
    "* Adopt **MAE** as the primary metric, given its robustness under skew, and report **segmented MAE** to avoid degenerate solutions that simply predict low values for most samples:\n",
    "  - MAE on all samples  \n",
    "  - MAE on zero‑popularity tracks (`y = 0`)  \n",
    "  - MAE on positive‑popularity tracks (`y > 0`)\n",
    "  \n",
    "  This segmentation acts as a guardrail, ensuring that performance is not inflated by the large concentration of low‑popularity tracks.\n",
    "\n",
    "* Treat explicit two‑part modeling as a **Cycle 2 candidate** if errors concentrate on the positive tail.\n",
    "\n",
    "Alternative families exist for outcomes with a mass at zero and a continuous positive component. A common pragmatic option is **Tweedie regression** (Compound Poisson–Gamma, 1 < p < 2), implemented in standard ML toolchains (scikit‑learn, XGBoost, LightGBM).  \n",
    "For bounded fractional outcomes, **beta regression** and **zero/one‑inflated beta models** provide principled alternatives (Cribari‑Neto & Zeileis, 2010; Ospina & Ferrari, 2012). When applied to a discrete 0–100 score, they become approximations but still serve as conceptual anchors for later iterations.\n",
    "\n",
    "---\n",
    "\n",
    "**Mullahy, J.** (1986). [Specification and testing of some modified count data models. *Journal of Econometrics, 33*(3), 341–365.](https://doi.org/10.1016/0304-4076(86)90002-3)\n",
    "\n",
    "**Cameron, A. C., & Trivedi, P. K.** (2013). [*Regression analysis of count data* (2nd ed.). Cambridge University Press.](https://www.cambridge.org/core/books/regression-analysis-of-count-data/2AB83B406C5798030F7C91ECC99B1BE4)\n",
    "\n",
    "**Fávero, L. P., Belfiore, P., & Souza, R. F.** (2023). [*Data science, analytics and machine learning with R*. Academic Press.](https://www.sciencedirect.com/book/monograph/9780128242711/data-science-analytics-and-machine-learning-with-r)\n",
    "\n",
    "**scikit-learn Developers.** (2023). [*TweedieRegressor documentation*](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html\")\n",
    "\n",
    "**LightGBM Developers.** (2023). [*LightGBM documentation: Tweedie objective*](https://lightgbm.readthedocs.io/en/latest/)\n",
    "\n",
    "**Cribari-Neto, F., & Zeileis, A.** (2010). [Beta regression in R. *Journal of Statistical Software, 34*(2), 1–24. https://www.jstatsoft.org/v34/i02/](https://www.jstatsoft.org/v34/i02/)\n",
    "\n",
    "**Ospina, R., & Ferrari, S. L. P.** (2012). [A general class of zero-or-one inflated beta regression models. *Computational Statistics & Data Analysis, 56*(6), 1609–1623.](https://doi.org/10.1016/j.csda.2011.10.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339772df-30c1-4f43-8684-0272104229a4",
   "metadata": {},
   "source": [
    "# 6. Feature Candidates (DIMENSIONS)\n",
    "\n",
    "This section provides a lightweight scan of the candidate predictors currently available in `data_clean`. The goal is to:\n",
    "1. validate feature ranges and basic consistency, \n",
    "2. quantify a few obvious anomalies, and \n",
    "3. capture early signals about relationships with the target without over-investing in exhaustive cleaning during Cycle 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333126f-8682-4704-a0d1-fe5ced799030",
   "metadata": {},
   "source": [
    "## 6.1 - Range Diagnostics and Anomaly Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13196329-f955-48a2-a108-8dfed6e52d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7204450-036b-4199-9079-64aad7be50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.describe().T[['min','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531e081-7d12-4468-8e4f-f791f63342c4",
   "metadata": {},
   "source": [
    "Most bounded “audio features” remain within their expected [0, 1] range (`acousticness`, `danceability`, `energy`, `instrumentalness`, `liveness`, `speechiness`, `valence`). A few variables, however, exhibit sentinel-like or long-tail behaviors that are worth monitoring:\n",
    "\n",
    "- **tempo** spans from **0 to ~250 BPM**; the presence of zeros suggests malformed or missing tempo values encoded as 0.\n",
    "- **loudness** ranges from **–60 dB to +5.3 dB**; positive values are uncommon and will be monitored as potential edge cases.\n",
    "- **duration_ms** shows a strong long tail (up to ~100 minutes), indicating a small amount of very long content (e.g., mixes, long live sets, ambient, spoken-word).\n",
    "- **time_signature** includes 0 for some records, which is likely invalid (or a placeholder) and should be treated as an anomaly flag for later cycles.\n",
    "- **album_release_year** includes rare implausible values (e.g., far pre-1900); these cases are already tracked via `release_year_missing_or_suspect`.\n",
    "\n",
    "This scan confirms that the dataset is broadly coherent for Cycle 1 modeling, while highlighting a small set of edge cases that may require targeted handling in later iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bea7f-8254-4855-9e1c-0fa72119a516",
   "metadata": {},
   "source": [
    "## 6.2 - Quantifying a few anomalies\n",
    "\n",
    "We quantify a handful of anomalies to ensure they are limited in scale and do not block MVP modeling. These records are kept for now (unless explicitly removed later), but flagged for potential refinement in Cycle 2+ if they prove harmful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebb191-f16c-44c2-a217-fc884fa5a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_zero = data_clean.query(\"tempo == 0\").shape[0]\n",
    "loudness_pos = data_clean.query(\"loudness > 0\").shape[0]\n",
    "duration_long = (data_clean['duration_ms'] > 20*60*1000).sum()\n",
    "invalid_time_signature = data_clean.query(\"time_signature == 0\").shape[0]\n",
    "\n",
    "tempo_zero, loudness_pos, duration_long, invalid_time_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e78887-f9fa-4b2b-ac2f-10c8b95e8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[(data_raw['duration_ms'] > 20*60*1000)][['song_name', 'artist_name', 'song_popularity', 'album_release_date', 'duration_ms']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0846d0-830d-4701-8f6a-b9b38e2811d9",
   "metadata": {},
   "source": [
    " Check | Condition | Count | Interpretation |\n",
    "|-------|-----------|--------|----------------|\n",
    "| **tempo = 0** | `tempo == 0` | 968 | Likely missing or malformed tempo values encoded as zeros.|\n",
    "| **loudness > 0 dB** | `loudness > 0` | 440 | uncommon values; retained but monitored. |\n",
    "| **Very long tracks** | `duration_ms > 20 min` | 552 | Long-tail content (ambient, meditation, classical, spoken word, live performance, DJ mix, religious). retained as legitimate but potentially influential outliers. |\n",
    "| **invalid time signature** | `time_signature == 0` | 975 | likely invalid; should be treated as a special value or filtered/flagged later. |\n",
    "\n",
    "These anomalies are limited in scale and do not block Cycle 1 modeling.  \n",
    "They are flagged for later cycles where deeper cleaning or domain-specific handling may be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f4c3f-b2b4-4c55-a51b-834f8430dc74",
   "metadata": {},
   "source": [
    "## 6.3 - Univariate distributions (continuous features)\n",
    "\n",
    "We inspect the shape of key continuous predictors to understand skewness, multimodality, and long tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47714748-3ffd-410c-bd88-08627111b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'energy','danceability','valence','tempo','loudness',\n",
    "    'duration_ms','instrumentalness','acousticness'\n",
    "]\n",
    "data_clean[cols].hist(figsize=(14,10), bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe55ee-1aac-480d-99a9-e5d585779a0b",
   "metadata": {},
   "source": [
    "The continuous predictors show distribution shapes typical of large heterogeneous catalogs:\n",
    "\n",
    "| Feature | Distribution shape | Reproducible insight |\n",
    "|---------|--------------------|-----------------------|\n",
    "| **energy** | Right‑skewed toward higher values | Most tracks cluster between ~0.6–0.9 |\n",
    "| **danceability** | Right‑skewed | High-density region around ~0.6–0.8 |\n",
    "| **valence** | Broad / weakly bimodal | Mild peaks around low and mid values |\n",
    "| **tempo** | Centered around ~120–130 BPM | Clear spike at 0 (malformed entries) |\n",
    "| **loudness** | Left‑skewed | Most tracks between –30 and 0 dB |\n",
    "| **duration_ms** | Strong long tail | Majority under ~1M ms; few extreme outliers |\n",
    "| **instrumentalness** | Strongly bimodal | Many tracks near 0; secondary peak near 1 |\n",
    "| **acousticness** | Bimodal | Peaks near 0 and near 1 |\n",
    "\n",
    "These shapes suggest that, for Cycle 1, standard scaling is optional (especially for tree-based baselines), but robust evaluation and outlier-awareness remain important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e5006-3246-4529-bee6-1f2d8f268d12",
   "metadata": {},
   "source": [
    "## 6.4 - Discrete feature distributions\n",
    "\n",
    "We inspect the distribution of low-cardinality musical features to confirm coverage and spot potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f817d-7a54-4ee5-845f-9c6a15ea7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data_clean, x=\"key\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b099cd-ef62-4655-bb88-22f2c0f1d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de83fd-6f91-4162-b855-e9cb4b777f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{data_clean[\"time_signature\"].value_counts()}')\n",
    "sns.histplot(data=data_clean, x=\"time_signature\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12fb36-f499-4287-a404-8959e53321e2",
   "metadata": {},
   "source": [
    "| Feature | Value range | Distribution insight |\n",
    "|---------|-------------|----------------------|\n",
    "| **key** | 0–11 | All pitch classes present; keys 0 and 1 most frequent |\n",
    "| **mode** | 0 (minor), 1 (major) | ~57% major, ~43% minor |\n",
    "| **time_signature** | 0–5 | `time_signature = 4` (4/4) dominates (≈85%)|\n",
    "\n",
    "Discrete variables (`key`, `mode`, `time_signature`) have low cardinality and are suitable for integer treatment in the MVP. The main exception is `time_signature == 0`, which is likely invalid and should be handled explicitly in later cycles (e.g., as a separate category or excluded)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aadd3e-20ff-498a-b290-0bdbec3cd376",
   "metadata": {},
   "source": [
    "## 6.5 - Metadata feature: `total_available_markets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a4238-88c2-4c86-ae8f-3ce1a9027600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data_clean['total_available_markets'], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e30150-2d71-4916-aa13-2177a6f9de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[['total_available_markets','song_popularity']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e4003-3e97-47c6-96f4-0bd76cd8ab9d",
   "metadata": {},
   "source": [
    "| Aspect | Insight (reproducible) |\n",
    "|--------|--------------------------|\n",
    "| **Distribution shape** | Highly skewed toward the upper end, with a strong cluster near ~170 markets |\n",
    "| **Secondary clusters** | Smaller peaks around ~0, ~50, and ~100 markets |\n",
    "| **Correlation with popularity** | Very close to zero and slightly negative (≈ −0.016) |\n",
    "| **Interpretation** | In this sample, broader availability does **not** show a meaningful linear relationship with popularity |\n",
    "\n",
    "This does not rule out non-linear or interaction effects, but suggests it is not a standalone “more markets → more popularity” signal in Cycle 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bef69-7447-49b5-921b-1020d2063094",
   "metadata": {},
   "source": [
    "## 6.6 - Diagnostic flag: `release_year_missing_or_suspect`\n",
    "\n",
    "This flag was created **[earlier](#sec-44-handling)** by sanitizing `album_release_year` and marking implausible or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73194cae-fbfc-44f5-bf25-0ac284ac1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['release_year_missing_or_suspect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9728ce-58fd-4870-9d81-b9a157ba6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data_clean, x='release_year_missing_or_suspect', y='song_popularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8784930-de04-4c6a-97a1-00c9777eb7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:46:45.459438Z",
     "iopub.status.busy": "2026-01-30T20:46:45.458972Z",
     "iopub.status.idle": "2026-01-30T20:46:45.499583Z",
     "shell.execute_reply": "2026-01-30T20:46:45.490668Z",
     "shell.execute_reply.started": "2026-01-30T20:46:45.459403Z"
    }
   },
   "source": [
    "| Aspect | Insight (reproducible) |\n",
    "|--------|--------------------------|\n",
    "| **Flag frequency** | Only 19 tracks are flagged as `True` |\n",
    "| **Popularity distribution** | Flagged tracks show a noticeably lower median popularity |\n",
    "| **Spread** | Non-flagged tracks show a wider IQR and more high-popularity outliers |\n",
    "| **Interpretation** | The flag behaves as expected: tracks with implausible or missing years tend to be less popular |\n",
    "\n",
    "The diagnostic flag is extremely rare, but behaves as expected: flagged records tend to be less popular and have a narrower spread. The feature is kept in the MVP as a quality-control indicator, with the caution that it may capture dataset artifacts rather than musical signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31285f-5a96-47e9-acbe-263bde4c7d51",
   "metadata": {},
   "source": [
    "## 6.7 - Bivariate relationships with the target\n",
    "\n",
    "We inspect simple pairwise relationships between key predictors and `song_popularity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ee327-3c24-4bb6-b49b-dac483387b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'energy','danceability','valence','tempo','loudness',\n",
    "    'duration_ms','instrumentalness','acousticness',\n",
    "    'total_available_markets'\n",
    "]\n",
    "\n",
    "corrs = data_clean[cols + ['song_popularity']].corr()['song_popularity'].sort_values(ascending=False)\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132f3ae-70c8-440a-8c86-1bc562517aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = data_clean.sample(5000, random_state=42)[cols + ['song_popularity']].melt(\n",
    "    id_vars='song_popularity',\n",
    "    var_name='feature',\n",
    "    value_name='value'\n",
    ")\n",
    "\n",
    "g = sns.FacetGrid(melted, col='feature', col_wrap=3, sharex=False, sharey=True, height=3.5)\n",
    "g.map(sns.scatterplot, 'value', 'song_popularity', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce71ab9-72e4-4f79-8e9f-459fa2f1f21e",
   "metadata": {},
   "source": [
    "| Feature | Correlation with popularity | Reproducible insight |\n",
    "|---------|------------------------------|-----------------------|\n",
    "| **energy** | Weak positive | Slight upward trend in scatterplot |\n",
    "| **danceability** | Weak positive | Mild clustering of higher popularity at higher values |\n",
    "| **loudness** | Weak positive | Louder tracks tend to be marginally more popular |\n",
    "| **valence** | Near zero | No visible linear trend |\n",
    "| **tempo** | Near zero | Popularity spread uniform across tempo range |\n",
    "| **duration_ms** | Slight negative | Longer tracks slightly less popular on average |\n",
    "| **instrumentalness** | Negative | Higher instrumentalness associated with lower popularity |\n",
    "| **acousticness** | Slight negative | Acoustic-heavy tracks slightly less popular |\n",
    "| **total_available_markets** | Near zero | No meaningful linear relationship |\n",
    "\n",
    "Most relationships between audio features and `song_popularity` are weak, which is expected: popularity is influenced by many non-audio factors not present in this dataset. Still, mild monotonic tendencies appear for a subset of predictors (e.g., `energy`, `danceability`, `loudness`), while others remain near-zero in linear correlation (e.g., `tempo`, `valence`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b544b-a8f5-4c6d-bcda-a74565e93ce6",
   "metadata": {},
   "source": [
    "## 6.8 - Pairwise correlations between predictors\n",
    "\n",
    "We inspect the correlation structure among the main audio features to identify redundancy and potential multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdf54d-a68e-40c3-aa8e-a838a0f19505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    data_clean[cols].corr(),\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    annot=False,\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Correlation matrix of audio features\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deabb2e-7659-4b11-8b9e-99a1c8adece9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:44:54.344446Z",
     "iopub.status.busy": "2026-01-30T21:44:54.344093Z",
     "iopub.status.idle": "2026-01-30T21:44:54.515887Z",
     "shell.execute_reply": "2026-01-30T21:44:54.513208Z",
     "shell.execute_reply.started": "2026-01-30T21:44:54.344418Z"
    }
   },
   "source": [
    "A short list of |corr| ≥ 0.30 highlights intuitive associations (e.g., `energy`–`loudness`, `energy`–`acousticness`, `danceability`–`valence`). Overall, this is a pairwise view and **does not fully characterize multicollinearity**, but it supports retaining the full feature set for the Cycle 1 baseline without dimensionality reduction.\n",
    "\n",
    "| Feature A | Feature B | Corr | Interpretation |\n",
    "|-----------|-----------|------|----------------|\n",
    "| **Energy** | **Loudness** | **0.78** | High‑energy tracks tend to be louder |\n",
    "| **Energy** | **Acousticness** | **–0.64** | Acoustic tracks are typically less energetic |\n",
    "| **Loudness** | **Acousticness** | **–0.53** | Acoustic tracks are quieter |\n",
    "| **Danceability** | **Valence** | **0.41** | Danceable songs tend to be happier |\n",
    "| **Energy** | **Valence** | **0.29** | Slight tendency for energetic songs to sound “happier” |\n",
    "| **Valence** | **Instrumentalness** | **–0.28** | Instrumental tracks tend to have lower valence |\n",
    "| **Danceability** | **Instrumentalness** | **–0.24** | Instrumental tracks are less danceable |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61c9a4-aaec-4e79-ada0-043537b26668",
   "metadata": {},
   "source": [
    "# 7. Leakage & non-usable columns (MVP rules)\n",
    "\n",
    "Cycle 1 enforces a strict separation between:\n",
    "\n",
    "- **Predictors available at inference time**, and  \n",
    "- **Any information that could directly or indirectly reveal the target (`song_popularity`) or contaminate evaluation**.\n",
    "\n",
    "This section documents which columns are excluded from modeling, why they are excluded, and performs a reproducible audit to ensure that the modeling dataset respects MVP anti‑leakage rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d14e42-e4e0-4e3a-b789-65b6af498fd4",
   "metadata": {},
   "source": [
    "## 7.1 - What counts as leakage in this project\n",
    "\n",
    "We treat the following as leakage risks:\n",
    "\n",
    "* **Evaluation leakage (preprocessing leakage):** any transformation that learns parameters from the full dataset before splitting (e.g., scaling, imputation, feature selection). This can inflate validation scores and fail in production. The safe rule is: **split first, then fit transforms on train only**, preferably via a pipeline ([Scikit-learn](https://scikit-learn.org/stable/common_pitfalls.html)).\n",
    "* **Identifier/memorization leakage:** columns that uniquely identify a track (IDs, URLs). Even if they don’t encode the label, they enable memorization and do not generalize.\n",
    "* **Non-MVP external enrichment:** fields that require API calls or joining external tables at inference time (not acceptable for Cycle 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef4a1f-92ae-430a-a957-aa62ca90f12b",
   "metadata": {},
   "source": [
    "## 7.2 - Columns explicitly excluded from modeling (and why)\n",
    "\n",
    "The following raw columns are treated as **non-usable** for the MVP:\n",
    "\n",
    "| Category | Columns | Reason |\n",
    "|---------|---------|--------|\n",
    "| **Track identifiers / URLs** | `spotify_id`, `uri`, `track_href`, `analysis_url` | High-cardinality identifiers; enable memorization; not musical content |\n",
    "| **Text fields** | `song_name`, `artist_name` | Would require NLP or entity resolution; introduces lookup-based leakage risks |\n",
    "| **Row index artifact** | `Unnamed: 0` | Dataset artifact; not a feature |\n",
    "\n",
    "These exclusions are deliberate: the Cycle 1 baseline focuses on **audio features + minimal metadata**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227831d1-0c4f-4936-bde1-5a872968fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: ensure none of the disallowed columns remain in data_clean\n",
    "disallowed = {\n",
    "    \"spotify_id\", \"uri\", \"track_href\", \"analysis_url\",\n",
    "    \"song_name\", \"artist_name\", \"Unnamed: 0\"\n",
    "}\n",
    "\n",
    "present_disallowed = disallowed.intersection(data_clean.columns)\n",
    "\n",
    "if present_disallowed:\n",
    "    print(\"⚠️ Disallowed columns still present:\", present_disallowed)\n",
    "else:\n",
    "    print(\"✓ No disallowed columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff9b5f-3a10-4c5a-be14-d08ad21116e1",
   "metadata": {},
   "source": [
    "The check above confirms whether any excluded columns are still present in the modeling dataset.  \n",
    "If the output shows an empty set (or the ✓ message), the dataset is compliant with the MVP rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb49e4b-5ac9-4eda-bf0d-e62e95b1dc7b",
   "metadata": {},
   "source": [
    "## 7.3 - Allowed features in Cycle 1\n",
    "\n",
    "Cycle 1 predictors are limited to:\n",
    "\n",
    "* **Audio features** (Spotify audio feature space): `acousticness`, `danceability`, `energy`, `instrumentalness`, `liveness`, `speechiness`, `valence`, `loudness`, `tempo`, `duration_ms`, plus discrete descriptors like `key`, `mode`, `time_signature`.\n",
    "* **Availability proxy:** `total_available_markets` (kept as low-cost metadata).\n",
    "* **Release timing:** `album_release_year` (kept for temporal context and potential time-aware splitting).\n",
    "* **Diagnostic flag:** `release_year_missing_or_suspect` (allowed because it is derived only from release-date consistency checks, not from popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae63fb-dff4-4821-a707-dd32c6328b61",
   "metadata": {},
   "source": [
    "## 7.4 - MVP anti-leakage rules (operational)\n",
    "\n",
    "To keep modeling and evaluation clean:\n",
    "\n",
    "1. **No global `fit` before splitting.** Any scaler/imputer/selector must be trained on `train` only (use a pipeline) ([Scikit-learn](https://scikit-learn.org/stable/common_pitfalls.html)).\n",
    "2. **No joins or API enrichment in Cycle 1.** If a feature requires calling Spotify or any external service at inference time, it is out-of-scope for the MVP.\n",
    "3. **Keep high-cardinality identifiers out of the model.** They are retained only for debugging/auditing, never as predictors.\n",
    "4. **Document every derived feature.** Each new feature must specify whether it uses only information available at inference time.\n",
    "\n",
    "These rules govern *how* modeling is performed rather than *what* is in the dataset, so no code is required here. The enforcement happens naturally through the pipeline design in Section 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92062c8b-f98e-4d97-b88c-46579be34554",
   "metadata": {},
   "source": [
    "# 8. Baseline Evaluation Plan (no heavy modeling)\n",
    "\n",
    "This section defines how the Cycle 1 baseline will be evaluated: **task framing**, **data splits**, and **metrics**. \n",
    "\n",
    "The goal is to establish a **clean, reproducible, leakage‑free evaluation protocol** without introducing heavy modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## 8.1 - Task type\n",
    "\n",
    "The target `song_popularity` is a **bounded discrete score** in **[0, 100]**.\n",
    "\n",
    "For Cycle 1 (MVP), we treat this as a **regression task**:\n",
    "\n",
    "* Predicting a numeric score preserves the full information content (no arbitrary binning).\n",
    "* Errors remain interpretable in the original units (“popularity points”).\n",
    "\n",
    "**Decision:** Regression baseline.\n",
    "\n",
    "---\n",
    "\n",
    "## 8.2 - Split strategy\n",
    "\n",
    "Cycle 1 adopts a **Dual Split Strategy** to balance. This is necessary because music metadata often contains **ambiguous release dates** (original vs. remaster vs. digital re‑issue), making a purely temporal split unreliable as the sole evaluation method.\n",
    "\n",
    "### **A. Primary Benchmark — Random Split (i.i.d.)**\n",
    "\n",
    "**Purpose:**  \n",
    "A stable baseline unaffected by release‑year inconsistencies. A shuffled holdout split provides a stable split that does not depend on release-date semantics.\n",
    "\n",
    "**Protocol:**  \n",
    "- Test = 20% (held out until the end)  \n",
    "- Validation = 10%  \n",
    "- Train = 70%\n",
    "\n",
    "**Implementation rules (data hygiene):**\n",
    "\n",
    "* The temporal split uses a **specific integer year** as cutoff (no float quantiles).\n",
    "* Rows flagged as `release_year_missing_or_suspect` are **excluded from the temporal test set** to reduce noise and avoid spurious conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391a4f0-b06a-4c73-b739-9c40eec88945",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_clean.drop(columns=[\"song_popularity\"])\n",
    "y = data_clean[\"song_popularity\"]\n",
    "\n",
    "# Step 1: test split (20%)\n",
    "x_trainval, x_test_r, y_trainval, y_test_r = train_test_split(\n",
    "    x, y, test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Step 2: validation split (10% overall → 12.5% of remaining)\n",
    "x_train_r, x_val_r, y_train_r, y_val_r = train_test_split(\n",
    "    x_trainval, y_trainval, test_size=0.125, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"split\": [\"train\", \"val\", \"test\"],\n",
    "    \"rows\": [len(y_train_r), len(y_val_r), len(y_test_r)],\n",
    "    \"zero_rate\": [\n",
    "        y_train_r.eq(0).mean(),\n",
    "        y_val_r.eq(0).mean(),\n",
    "        y_test_r.eq(0).mean(),\n",
    "    ],\n",
    "    \"median_popularity\": [\n",
    "        y_train_r.median(),\n",
    "        y_val_r.median(),\n",
    "        y_test_r.median(),\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7497597-50d4-4559-b219-0d19079e0ca1",
   "metadata": {},
   "source": [
    "### **B. Secondary Diagnostic — Temporal Split (Best Effort)**\n",
    "\n",
    "**Purpose:**  \n",
    "Probe whether the model generalizes to “nominally newer” tracks. If performance drops substantially relative to the random holdout, it suggests either:\n",
    "    * a temporal distribution shift (concept drift), or\n",
    "    * that the year metadata is too noisy to support temporal evaluation reliably.\n",
    "\n",
    "**Temporal hygiene rules:**\n",
    "\n",
    "- Use **explicit integer years** (no quantiles).  \n",
    "- Remove all rows flagged as `release_year_missing_or_suspect` from the **entire temporal experiment** (train/val/test).  \n",
    "  This avoids timeline contamination and prevents any appearance of cherry‑picking.\n",
    "\n",
    "**Cycle 1 temporal protocol (based on dataset distribution):**\n",
    "\n",
    "- **Train:** `album_release_year ≤ 2019`  \n",
    "- **Validation:** `album_release_year == 2020`  \n",
    "- **Test:** `album_release_year == 2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c965958-e0f2-470d-b18b-f8fe50991390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove suspect years entirely from the temporal experiment\n",
    "df_temp = data_clean.loc[~data_clean[\"release_year_missing_or_suspect\"]].copy()\n",
    "\n",
    "train_mask = df_temp[\"album_release_year\"] <= 2019\n",
    "val_mask   = df_temp[\"album_release_year\"] == 2020\n",
    "test_mask  = df_temp[\"album_release_year\"] == 2021\n",
    "\n",
    "x_train_t = df_temp.loc[train_mask].drop(columns=[\"song_popularity\"])\n",
    "y_train_t = df_temp.loc[train_mask][\"song_popularity\"]\n",
    "\n",
    "x_val_t = df_temp.loc[val_mask].drop(columns=[\"song_popularity\"])\n",
    "y_val_t = df_temp.loc[val_mask][\"song_popularity\"]\n",
    "\n",
    "x_test_t = df_temp.loc[test_mask].drop(columns=[\"song_popularity\"])\n",
    "y_test_t = df_temp.loc[test_mask][\"song_popularity\"]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"split\": [\"train_t\", \"val_t\", \"test_t\"],\n",
    "    \"rows\": [\n",
    "        len(y_train_t),\n",
    "        len(y_val_t),\n",
    "        len(y_test_t),\n",
    "    ],\n",
    "    \"zero_rate\": [\n",
    "        y_train_t.eq(0).mean(),\n",
    "        y_val_t.eq(0).mean(),\n",
    "        y_test_t.eq(0).mean(),\n",
    "    ],\n",
    "    \"median_popularity\": [\n",
    "        y_train_t.median(),\n",
    "        y_val_t.median(),\n",
    "        y_test_t.median(),\n",
    "    ],\n",
    "    \"min_year\": [\n",
    "        df_temp.loc[train_mask, \"album_release_year\"].min(),\n",
    "        df_temp.loc[val_mask,   \"album_release_year\"].min(),\n",
    "        df_temp.loc[test_mask,  \"album_release_year\"].min(),\n",
    "    ],\n",
    "    \"max_year\": [\n",
    "        df_temp.loc[train_mask, \"album_release_year\"].max(),\n",
    "        df_temp.loc[val_mask,   \"album_release_year\"].max(),\n",
    "        df_temp.loc[test_mask,  \"album_release_year\"].max(),\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725b63b-b30b-41d5-aea6-bcc4bf2829f6",
   "metadata": {},
   "source": [
    "**Decision:** Dual split (Random as primary, Temporal as diagnostic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a493a1-3525-4c5b-82a3-46fb27dfccc8",
   "metadata": {},
   "source": [
    "## 8.3 Metrics\n",
    "\n",
    "All metrics are reported in **popularity points**.\n",
    "\n",
    "### **Primary metric**\n",
    "- **MAE** — robust under skew; directly interpretable as “average error in points”.\n",
    "\n",
    "### **Secondary metrics**\n",
    "- **RMSE** — highlights large errors (useful to detect occasional severe errors.  \n",
    "- **R²** — context only (bounded/skewed targets can distort interpretation, reported only as a reference statistic).\n",
    "\n",
    "### **Segment‑Aware Diagnostics (Zero Inflation)**\n",
    "\n",
    "Because the target has a **non-trivial mass at zero** (~13.4%), we also report:\n",
    "\n",
    "- MAE on `y == 0`  \n",
    "- MAE on `y > 0`  \n",
    "\n",
    "This prevents a baseline from appearing “good” by predicting near-zero values for most tracks.\n",
    "\n",
    "**Decision:** *MAE + segmented MAE* (zeros vs positives), with RMSE and R² as complements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582f5c0-d6eb-4842-9f0a-853f066816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"mae\":  mean_absolute_error(y_true, y_pred),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"r2\":   r2_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def segmented_mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    zero_mask = y_true == 0\n",
    "    pos_mask  = y_true > 0\n",
    "\n",
    "    return {\n",
    "        \"mae_zero\": mean_absolute_error(y_true[zero_mask], y_pred[zero_mask]) if zero_mask.any() else np.nan,\n",
    "        \"mae_pos\":  mean_absolute_error(y_true[pos_mask],  y_pred[pos_mask])  if pos_mask.any()  else np.nan,\n",
    "    }\n",
    "\n",
    "# Baseline: median predictor for each split\n",
    "\n",
    "# Random split baseline\n",
    "y_pred_r = np.full_like(y_test_r, y_train_r.median())\n",
    "\n",
    "# Temporal split baseline\n",
    "y_pred_t = np.full_like(y_test_t, y_train_t.median())\n",
    "\n",
    "# Metrics\n",
    "metrics_random = {\n",
    "    **regression_metrics(y_test_r, y_pred_r),\n",
    "    **segmented_mae(y_test_r, y_pred_r),\n",
    "}\n",
    "\n",
    "metrics_temporal = {\n",
    "    **regression_metrics(y_test_t, y_pred_t),\n",
    "    **segmented_mae(y_test_t, y_pred_t),\n",
    "}\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"split\": \"random\", **metrics_random},\n",
    "    {\"split\": \"temporal\", **metrics_temporal},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c815b83-0a90-4001-a437-adbe59863364",
   "metadata": {},
   "source": [
    "## 8.4 - Leakage Prevention Rule\n",
    "\n",
    "To enforce the principles defined in Section 7:\n",
    "\n",
    "- All preprocessing (scaling, imputation, encoding) must be **fitted on the training split only**.  \n",
    "- Validation and test sets must be transformed using the **same fitted pipeline**.  \n",
    "- No statistics from validation/test may influence training.\n",
    "\n",
    "This ensures the baseline is **leakage‑free** and reproducible.\n",
    "\n",
    "## 8.5 Baseline Interpretation (Random vs Temporal)\n",
    "\n",
    "- **MAE:** slightly higher on the temporal split, consistent with the larger share of zero‑popularity tracks in 2021.  \n",
    "- **RMSE:** slightly lower on the temporal split, reflecting fewer extreme values among recent releases.  \n",
    "- **R²:** negative for both splits, as expected from a constant baseline.  \n",
    "- **Segmented MAE:**  \n",
    "  - **MAE_zero** is high because a constant predictor performs poorly on zero‑popularity tracks.  \n",
    "  - **MAE_pos** is lower, indicating that positive‑popularity tracks are closer to the median baseline.\n",
    "\n",
    "The baseline behaves as expected:  \n",
    "- the random split provides a stable i.i.d. reference  \n",
    "- the temporal split shows mild distribution shift and higher zero‑inflation  \n",
    "- no signs of leakage or anomalies  \n",
    "- the evaluation protocol is validated for Cycle 1 modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b7bd3-9e79-471f-8f69-75f91e0f97a2",
   "metadata": {},
   "source": [
    "# 9. Decisions & Next Steps (Compact Edition)\n",
    "\n",
    "This notebook establishes the **Cycle 1 EDA and evaluation protocol**.  \n",
    "All methodological decisions for the MVP are now finalized.\n",
    "\n",
    "---\n",
    "\n",
    "## 9.1 - Final MVP Decisions\n",
    "\n",
    "- **Task type:** Regression on a bounded discrete target (`song_popularity ∈ [0,100]`).  \n",
    "- **Evaluation protocol:**  \n",
    "  - **Random split (primary)** — i.i.d. benchmark.  \n",
    "  - **Temporal split (diagnostic)** — generalization to newer releases.  \n",
    "- **Temporal hygiene:**  \n",
    "  - Rows with `release_year_missing_or_suspect = True` are excluded from the entire temporal experiment.  \n",
    "  - Temporal boundaries: **Train ≤ 2019**, **Val = 2020**, **Test = 2021**.  \n",
    "- **Metrics:** MAE (primary), RMSE and R² (secondary), plus segment‑aware MAE (`y==0`, `y>0`).  \n",
    "- **Leakage prevention:** All preprocessing is fit on **train only** and applied to val/test via the same pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## 9.2 - Next Steps (Cycle 1)\n",
    "\n",
    "These steps belong to the **next notebook**, not this one:\n",
    "\n",
    "- Implement preprocessing inside a scikit‑learn `Pipeline`.  \n",
    "- Train and evaluate the **median baseline** on both splits.  \n",
    "- Produce the consolidated metrics table (random vs temporal).  \n",
    "- Begin Cycle 1 error analysis (zero vs positive segments).\n",
    "\n",
    "---\n",
    "\n",
    "## **9.3 - Transition to Cycle 1**\n",
    "\n",
    "With the EDA complete and the evaluation protocol validated, the project is ready to move to the **Cycle 1 baseline training notebook**, where modeling and diagnostics will begin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7560646-2fdb-4ed5-9a35-12ae9b055366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .to_json(indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
